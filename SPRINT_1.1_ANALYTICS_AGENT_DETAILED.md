# Sprint 1.1 - Analytics Agent Core Development (D√©taill√©)

**Version stable de r√©f√©rence**: `v3.2.6`
**Branche**: `feature/phase1-analytics-agent`
**Dur√©e**: 2 semaines (10 jours ouvrables)
**√âquipe**: 1-2 d√©veloppeurs
**Tag apr√®s validation**: `v3.3.0-analytics-agent`

---

## üéØ Objectif du Sprint

D√©velopper un **Analytics Agent** standalone capable d'effectuer des calculs statistiques avanc√©s sur les transactions financi√®res :

- ‚úÖ Comparaisons temporelles (MoM, YoY, QoQ)
- ‚úÖ D√©tection d'anomalies (Z-score, IQR)
- ‚úÖ Calcul de tendances (r√©gression lin√©aire + forecast)
- ‚úÖ Agr√©gations multi-dimensionnelles (pivot tables)

**Principe fondamental** : L'Analytics Agent ne modifie PAS le workflow existant. Il s'int√®gre comme un module additionnel appel√© par le Response Generator pour enrichir les r√©ponses avec des insights analytiques avanc√©s.

---

## üìã Vue d'Ensemble du Sprint

### Timeline D√©taill√©e

```
Jour 1-2   ‚îÇ T1.1: Setup environnement + infrastructure
           ‚îÇ - Cr√©ation branche feature
           ‚îÇ - Installation d√©pendances (pandas, numpy, scipy)
           ‚îÇ - V√©rification v3.2.6 fonctionnel
           ‚îÇ
Jour 3-5   ‚îÇ T1.2: Impl√©mentation core Analytics Agent
           ‚îÇ - Mod√®les Pydantic (TimeSeriesMetrics, AnomalyResult, TrendAnalysis)
           ‚îÇ - M√©thodes compare_periods(), detect_anomalies(), calculate_trend()
           ‚îÇ - Tests unitaires (>90% coverage)
           ‚îÇ
Jour 6-7   ‚îÇ T1.3: Tests E2E Analytics Agent standalone
           ‚îÇ - Tests MoM/YoY avec donn√©es r√©elles
           ‚îÇ - Tests d√©tection anomalies (cas Tesla 1200‚Ç¨)
           ‚îÇ - Tests calcul tendances sur 6 mois
           ‚îÇ - Benchmark performance (<500ms par calcul)
           ‚îÇ
Jour 8-9   ‚îÇ T1.4: Int√©gration Response Generator
           ‚îÇ - Modification response_generator.py
           ‚îÇ - Appel Analytics Agent pour enrichir insights
           ‚îÇ - Fallback si Analytics Agent √©choue
           ‚îÇ - Tests E2E pipeline complet
           ‚îÇ
Jour 10    ‚îÇ T1.5: Validation & Rollback Test
           ‚îÇ - Test rollback vers v3.2.6
           ‚îÇ - Comparaison r√©ponses v3.2.6 vs v3.3.0
           ‚îÇ - Documentation compl√®te
           ‚îÇ - Merge vers develop si validation OK
```

---

## üì¶ T√¢che 1.1 - Setup Environnement D√©veloppement

**Dur√©e**: 1 jour
**Responsable**: Dev Lead

### Checklist

- [ ] **Cr√©er branche feature depuis v3.2.6**
  ```bash
  git checkout v3.2.6
  git checkout -b feature/phase1-analytics-agent
  git push -u origin feature/phase1-analytics-agent
  ```

- [ ] **Setup environnement Python avec d√©pendances analytics**
  ```bash
  # Ajouter √† requirements.txt
  pandas==2.1.4
  numpy==1.26.3
  scipy==1.11.4
  scikit-learn==1.3.2  # Pour future ML (Phase 3)

  # Installer
  pip install -r requirements.txt
  ```

- [ ] **V√©rifier que v3.2.6 fonctionne en local**
  ```bash
  # Lancer services
  docker-compose up -d

  # Test sanity check
  curl http://localhost:8001/api/v1/health
  # Expected: {"status": "healthy"}

  # Test conversation simple
  curl -X POST http://localhost:8001/api/v1/conversation \
    -H "Content-Type: application/json" \
    -d '{
      "user_id": 123,
      "message": "mes transactions de janvier"
    }'
  # Expected: R√©ponse avec transactions + insights basiques
  ```

- [ ] **Documenter proc√©dure de retour √† v3.2.6**
  ```bash
  # Cr√©er fichier ROLLBACK_PROCEDURE.md
  cat > ROLLBACK_PROCEDURE.md << 'EOF'
  # Proc√©dure de Rollback Sprint 1.1

  ## Si probl√®me d√©tect√© en d√©veloppement
  ```bash
  git checkout v3.2.6
  git branch -D feature/phase1-analytics-agent
  ```

  ## Si probl√®me d√©tect√© apr√®s merge
  ```bash
  git checkout v3.2.6
  git tag v3.2.6-rollback-from-v3.3.0
  ./scripts/deploy_production.sh --tag v3.2.6
  ```

  ## Validation rollback r√©ussi
  - [ ] Health check passe
  - [ ] Questions simples fonctionnent
  - [ ] Logs sans erreur
  EOF
  ```

- [ ] **Cr√©er structure dossiers Analytics Agent**
  ```bash
  mkdir -p conversation_service/agents/analytics
  touch conversation_service/agents/analytics/__init__.py
  touch conversation_service/agents/analytics/analytics_agent.py

  mkdir -p tests/unit/agents/analytics
  mkdir -p tests/e2e/analytics
  touch tests/unit/agents/analytics/test_analytics_agent.py
  touch tests/e2e/analytics/test_analytics_agent_e2e.py
  ```

### Crit√®res de Validation T1.1

‚úÖ Branche `feature/phase1-analytics-agent` cr√©√©e et push√©e
‚úÖ Environnement Python avec pandas/numpy/scipy op√©rationnel
‚úÖ v3.2.6 fonctionne correctement en local (test manuel r√©ussi)
‚úÖ Proc√©dure rollback document√©e dans `ROLLBACK_PROCEDURE.md`
‚úÖ Structure dossiers cr√©√©e

---

## üîß T√¢che 1.2 - Impl√©mentation Analytics Agent Core

**Dur√©e**: 3 jours
**Responsable**: Dev Backend

### 1.2.1 - Mod√®les Pydantic

**Fichier**: `conversation_service/agents/analytics/analytics_agent.py`

```python
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pydantic import BaseModel, Field, field_validator
import pandas as pd
import numpy as np
from scipy import stats
import logging

logger = logging.getLogger(__name__)


# ============================================
# MOD√àLES DE DONN√âES
# ============================================

class TimeSeriesMetrics(BaseModel):
    """
    M√©triques pour comparaisons temporelles (MoM, YoY, QoQ)

    Exemple d'utilisation:
        result = await analytics_agent.compare_periods(
            transactions_current=january_txs,
            transactions_previous=december_txs,
            metric='sum'
        )
        print(f"Variation MoM: {result.delta_percentage:+.1f}%")
    """
    period_current: str = Field(description="Label p√©riode actuelle (ex: '2025-01')")
    period_previous: str = Field(description="Label p√©riode pr√©c√©dente (ex: '2024-12')")
    value_current: float = Field(description="Valeur m√©trique p√©riode actuelle")
    value_previous: float = Field(description="Valeur m√©trique p√©riode pr√©c√©dente")
    delta: float = Field(description="Diff√©rence absolue (current - previous)")
    delta_percentage: float = Field(description="Variation en pourcentage")
    trend: str = Field(description="Direction tendance: 'up', 'down', 'stable'")

    @field_validator('trend')
    @classmethod
    def validate_trend(cls, v):
        if v not in ['up', 'down', 'stable']:
            raise ValueError("Trend must be 'up', 'down', or 'stable'")
        return v


class AnomalyDetectionResult(BaseModel):
    """
    R√©sultat d√©tection anomalie pour une transaction

    Exemple d'utilisation:
        anomalies = await analytics_agent.detect_anomalies(
            transactions=january_txs,
            method='zscore',
            threshold=2.0
        )
        for anomaly in anomalies:
            print(f"Transaction anormale: {anomaly.merchant_name} - {anomaly.amount}‚Ç¨")
            print(f"Raison: {anomaly.explanation}")
    """
    transaction_id: int = Field(description="ID transaction anormale")
    amount: float = Field(description="Montant transaction")
    date: datetime = Field(description="Date transaction")
    merchant_name: str = Field(description="Nom du marchand")
    anomaly_score: float = Field(description="Score anomalie (>2 = anormal)")
    method: str = Field(description="M√©thode d√©tection: 'zscore', 'iqr', 'isolation_forest'")
    threshold_exceeded: bool = Field(description="Seuil d√©pass√© ?")
    explanation: str = Field(description="Explication humaine de l'anomalie")


class TrendAnalysis(BaseModel):
    """
    Analyse de tendance avec r√©gression lin√©aire et forecast

    Exemple d'utilisation:
        trend = await analytics_agent.calculate_trend(
            transactions=last_6_months_txs,
            aggregation='monthly',
            forecast_periods=3
        )
        print(f"Tendance: {trend.trend_direction}")
        print(f"Forecast 3 mois: {trend.forecast_next_periods}")
    """
    period: str = Field(description="Granularit√©: 'daily', 'weekly', 'monthly'")
    trend_direction: str = Field(description="Direction: 'increasing', 'decreasing', 'stable'")
    slope: float = Field(description="Pente r√©gression lin√©aire (‚Ç¨/p√©riode)")
    r_squared: float = Field(description="Coefficient d√©termination R¬≤ (0-1, qualit√© fit)")
    forecast_next_periods: List[float] = Field(description="Pr√©dictions N p√©riodes suivantes")
    confidence_interval_95: List[Tuple[float, float]] = Field(description="Intervalles confiance 95%")


# ============================================
# ANALYTICS AGENT
# ============================================

class AnalyticsAgent:
    """
    Agent sp√©cialis√© pour calculs analytiques avanc√©s sur transactions financi√®res.

    Capabilities:
    - Comparaisons temporelles (MoM, YoY, QoQ)
    - D√©tection anomalies (Z-score, IQR, Isolation Forest)
    - Calcul tendances (r√©gression lin√©aire + forecast)
    - Agr√©gations multi-dimensionnelles

    Usage:
        agent = AnalyticsAgent()

        # Comparaison MoM
        mom_result = await agent.compare_periods(
            transactions_current=january_txs,
            transactions_previous=december_txs,
            metric='sum'
        )

        # D√©tection anomalies
        anomalies = await agent.detect_anomalies(
            transactions=january_txs,
            method='zscore'
        )

        # Calcul tendance
        trend = await agent.calculate_trend(
            transactions=last_6_months_txs,
            aggregation='monthly',
            forecast_periods=3
        )
    """

    def __init__(
        self,
        zscore_threshold: float = 2.0,
        iqr_multiplier: float = 1.5,
        stable_threshold_pct: float = 5.0
    ):
        """
        Initialize Analytics Agent

        Args:
            zscore_threshold: Seuil Z-score pour anomalies (d√©faut: 2.0)
            iqr_multiplier: Multiplicateur IQR (d√©faut: 1.5)
            stable_threshold_pct: % variation consid√©r√© stable (d√©faut: 5%)
        """
        self.zscore_threshold = zscore_threshold
        self.iqr_multiplier = iqr_multiplier
        self.stable_threshold_pct = stable_threshold_pct

        logger.info(
            f"AnalyticsAgent initialized (zscore={zscore_threshold}, "
            f"iqr={iqr_multiplier}, stable={stable_threshold_pct}%)"
        )

    # ============================================
    # COMPARAISONS TEMPORELLES
    # ============================================

    async def compare_periods(
        self,
        transactions_current: List[Dict[str, Any]],
        transactions_previous: List[Dict[str, Any]],
        metric: str = "sum"
    ) -> TimeSeriesMetrics:
        """
        Compare deux p√©riodes avec calculs delta et variation %

        Args:
            transactions_current: Liste transactions p√©riode actuelle
            transactions_previous: Liste transactions p√©riode pr√©c√©dente
            metric: M√©trique √† calculer ('sum', 'avg', 'count', 'median')

        Returns:
            TimeSeriesMetrics avec comparaison d√©taill√©e

        Raises:
            ValueError: Si metric invalide ou donn√©es insuffisantes

        Exemple:
            >>> january_txs = [{'amount': 120, 'date': '2025-01-05'}, ...]
            >>> december_txs = [{'amount': 110, 'date': '2024-12-05'}, ...]
            >>> result = await agent.compare_periods(january_txs, december_txs, 'sum')
            >>> print(f"MoM: {result.delta_percentage:+.1f}%")
            MoM: +12.5%
        """
        try:
            # Validation donn√©es
            if not transactions_current or not transactions_previous:
                raise ValueError("Transactions lists cannot be empty")

            # Conversion en DataFrames
            df_current = pd.DataFrame(transactions_current)
            df_previous = pd.DataFrame(transactions_previous)

            # Validation colonnes requises
            if 'amount' not in df_current.columns or 'amount' not in df_previous.columns:
                raise ValueError("'amount' column required in transactions")

            # Calcul m√©trique selon type
            metric_funcs = {
                'sum': lambda df: df['amount'].sum(),
                'avg': lambda df: df['amount'].mean(),
                'count': lambda df: len(df),
                'median': lambda df: df['amount'].median()
            }

            if metric not in metric_funcs:
                raise ValueError(f"Invalid metric: {metric}. Must be one of {list(metric_funcs.keys())}")

            value_current = float(metric_funcs[metric](df_current))
            value_previous = float(metric_funcs[metric](df_previous))

            # Calcul delta et %
            delta = value_current - value_previous
            delta_pct = (delta / value_previous * 100) if value_previous != 0 else 0

            # D√©termination tendance
            if abs(delta_pct) < self.stable_threshold_pct:
                trend = 'stable'
            elif delta > 0:
                trend = 'up'
            else:
                trend = 'down'

            # Extraction labels p√©riodes
            period_current = self._extract_period_label(df_current)
            period_previous = self._extract_period_label(df_previous)

            logger.info(
                f"Period comparison completed: {period_previous} ‚Üí {period_current} "
                f"({delta_pct:+.1f}%, {trend})"
            )

            return TimeSeriesMetrics(
                period_current=period_current,
                period_previous=period_previous,
                value_current=value_current,
                value_previous=value_previous,
                delta=delta,
                delta_percentage=delta_pct,
                trend=trend
            )

        except Exception as e:
            logger.error(f"Error in compare_periods: {str(e)}")
            raise

    # ============================================
    # D√âTECTION ANOMALIES
    # ============================================

    async def detect_anomalies(
        self,
        transactions: List[Dict[str, Any]],
        method: str = "zscore",
        threshold: Optional[float] = None
    ) -> List[AnomalyDetectionResult]:
        """
        D√©tecte transactions anormales selon m√©thode statistique

        Args:
            transactions: Liste transactions √† analyser
            method: M√©thode d√©tection ('zscore', 'iqr', 'isolation_forest')
            threshold: Seuil personnalis√© (None = utilise config par d√©faut)

        Returns:
            Liste anomalies d√©tect√©es, tri√©e par score d√©croissant

        Exemple:
            >>> txs = [
            ...     {'id': 1, 'amount': 120, 'date': '2025-01-05', 'merchant_name': 'Amazon'},
            ...     {'id': 2, 'amount': 1200, 'date': '2025-01-15', 'merchant_name': 'Tesla'},
            ... ]
            >>> anomalies = await agent.detect_anomalies(txs, method='zscore')
            >>> print(f"Found {len(anomalies)} anomalies")
            >>> for a in anomalies:
            ...     print(f"- {a.merchant_name}: {a.amount}‚Ç¨ (score: {a.anomaly_score:.2f})")
            Found 1 anomalies
            - Tesla: 1200.0‚Ç¨ (score: 3.45)
        """
        try:
            if not transactions:
                logger.warning("detect_anomalies called with empty transactions list")
                return []

            df = pd.DataFrame(transactions)

            # Validation colonnes requises
            required_cols = ['id', 'amount', 'date']
            for col in required_cols:
                if col not in df.columns:
                    raise ValueError(f"Required column '{col}' missing in transactions")

            # D√©tection selon m√©thode
            if method == "zscore":
                anomalies = self._detect_zscore_anomalies(df, threshold)
            elif method == "iqr":
                anomalies = self._detect_iqr_anomalies(df)
            elif method == "isolation_forest":
                anomalies = self._detect_ml_anomalies(df)
            else:
                raise ValueError(f"Invalid method: {method}. Must be 'zscore', 'iqr', or 'isolation_forest'")

            # Tri par score d√©croissant
            anomalies.sort(key=lambda a: a.anomaly_score, reverse=True)

            logger.info(f"Anomaly detection completed: {len(anomalies)} anomalies found (method={method})")

            return anomalies

        except Exception as e:
            logger.error(f"Error in detect_anomalies: {str(e)}")
            raise

    def _detect_zscore_anomalies(
        self,
        df: pd.DataFrame,
        threshold: Optional[float] = None
    ) -> List[AnomalyDetectionResult]:
        """
        D√©tection anomalies via Z-Score (√©carts-types de la moyenne)

        M√©thode:
        - Calcule moyenne Œº et √©cart-type œÉ des montants
        - Z-score = (montant - Œº) / œÉ
        - Si |Z-score| > threshold ‚Üí anomalie

        Args:
            df: DataFrame transactions
            threshold: Seuil Z-score (None = utilise self.zscore_threshold)

        Returns:
            Liste anomalies d√©tect√©es
        """
        threshold = threshold or self.zscore_threshold

        mean = df['amount'].mean()
        std = df['amount'].std()

        if std == 0:
            logger.warning("Standard deviation is 0, no anomalies can be detected")
            return []

        # Calcul Z-scores
        df['zscore'] = (df['amount'] - mean) / std

        # S√©lection anomalies
        anomalies_df = df[abs(df['zscore']) > threshold]

        results = []
        for _, row in anomalies_df.iterrows():
            results.append(AnomalyDetectionResult(
                transaction_id=int(row['id']),
                amount=float(row['amount']),
                date=pd.to_datetime(row['date']),
                merchant_name=str(row.get('merchant_name', 'Unknown')),
                anomaly_score=float(abs(row['zscore'])),
                method='zscore',
                threshold_exceeded=True,
                explanation=f"Montant {abs(row['zscore']):.1f}œÉ de la moyenne ({mean:.2f}‚Ç¨, œÉ={std:.2f}‚Ç¨)"
            ))

        return results

    def _detect_iqr_anomalies(self, df: pd.DataFrame) -> List[AnomalyDetectionResult]:
        """
        D√©tection anomalies via IQR (Interquartile Range)

        M√©thode:
        - Calcule Q1 (25e percentile) et Q3 (75e percentile)
        - IQR = Q3 - Q1
        - Bornes: [Q1 - 1.5*IQR, Q3 + 1.5*IQR]
        - Valeurs hors bornes ‚Üí anomalies

        Args:
            df: DataFrame transactions

        Returns:
            Liste anomalies d√©tect√©es
        """
        Q1 = df['amount'].quantile(0.25)
        Q3 = df['amount'].quantile(0.75)
        IQR = Q3 - Q1

        if IQR == 0:
            logger.warning("IQR is 0, no anomalies can be detected")
            return []

        lower_bound = Q1 - self.iqr_multiplier * IQR
        upper_bound = Q3 + self.iqr_multiplier * IQR

        # S√©lection anomalies (hors bornes)
        anomalies_df = df[(df['amount'] < lower_bound) | (df['amount'] > upper_bound)]

        results = []
        for _, row in anomalies_df.iterrows():
            # Score normalis√© (distance √† la borne / IQR)
            if row['amount'] < lower_bound:
                score = (lower_bound - row['amount']) / IQR
            else:
                score = (row['amount'] - upper_bound) / IQR

            results.append(AnomalyDetectionResult(
                transaction_id=int(row['id']),
                amount=float(row['amount']),
                date=pd.to_datetime(row['date']),
                merchant_name=str(row.get('merchant_name', 'Unknown')),
                anomaly_score=float(score),
                method='iqr',
                threshold_exceeded=True,
                explanation=f"Montant hors intervalle IQR [{lower_bound:.2f}‚Ç¨, {upper_bound:.2f}‚Ç¨] (IQR={IQR:.2f}‚Ç¨)"
            ))

        return results

    def _detect_ml_anomalies(self, df: pd.DataFrame) -> List[AnomalyDetectionResult]:
        """
        D√©tection anomalies via Isolation Forest (ML)

        Note: Impl√©mentation simplifi√©e pour Phase 1.
        Phase 3 aura mod√®le ML complet avec features multi-dimensionnelles.

        Args:
            df: DataFrame transactions

        Returns:
            Liste anomalies d√©tect√©es
        """
        from sklearn.ensemble import IsolationForest

        if len(df) < 10:
            logger.warning("Not enough data for Isolation Forest (<10 samples)")
            return []

        # Feature engineering simple (Phase 1)
        X = df[['amount']].values

        # Entra√Ænement Isolation Forest
        clf = IsolationForest(contamination=0.1, random_state=42)
        predictions = clf.fit_predict(X)
        scores = clf.score_samples(X)

        # S√©lection anomalies (prediction = -1)
        df['prediction'] = predictions
        df['anomaly_score'] = -scores  # Inverser pour que score √©lev√© = anormal

        anomalies_df = df[df['prediction'] == -1]

        results = []
        for _, row in anomalies_df.iterrows():
            results.append(AnomalyDetectionResult(
                transaction_id=int(row['id']),
                amount=float(row['amount']),
                date=pd.to_datetime(row['date']),
                merchant_name=str(row.get('merchant_name', 'Unknown')),
                anomaly_score=float(row['anomaly_score']),
                method='isolation_forest',
                threshold_exceeded=True,
                explanation=f"Transaction isol√©e d√©tect√©e par ML (score: {row['anomaly_score']:.2f})"
            ))

        return results

    # ============================================
    # CALCUL TENDANCES
    # ============================================

    async def calculate_trend(
        self,
        transactions: List[Dict[str, Any]],
        aggregation: str = "monthly",
        forecast_periods: int = 3
    ) -> TrendAnalysis:
        """
        Calcule tendance avec r√©gression lin√©aire et forecast

        Args:
            transactions: Liste transactions √† analyser
            aggregation: Granularit√© temporelle ('daily', 'weekly', 'monthly')
            forecast_periods: Nombre p√©riodes √† pr√©dire

        Returns:
            TrendAnalysis avec r√©gression, forecast et intervalle confiance

        Exemple:
            >>> last_6_months = [
            ...     {'amount': 400, 'date': '2024-08-01'},
            ...     {'amount': 420, 'date': '2024-09-01'},
            ...     {'amount': 450, 'date': '2024-10-01'},
            ...     {'amount': 480, 'date': '2024-11-01'},
            ...     {'amount': 500, 'date': '2024-12-01'},
            ...     {'amount': 530, 'date': '2025-01-01'},
            ... ]
            >>> trend = await agent.calculate_trend(last_6_months, 'monthly', 3)
            >>> print(f"Tendance: {trend.trend_direction} (R¬≤={trend.r_squared:.2f})")
            >>> print(f"Forecast 3 mois: {trend.forecast_next_periods}")
            Tendance: increasing (R¬≤=0.98)
            Forecast 3 mois: [560.5, 590.2, 620.0]
        """
        try:
            if not transactions:
                raise ValueError("Transactions list cannot be empty")

            df = pd.DataFrame(transactions)

            # Validation colonnes
            if 'amount' not in df.columns or 'date' not in df.columns:
                raise ValueError("'amount' and 'date' columns required")

            # Conversion dates
            df['date'] = pd.to_datetime(df['date'])

            # Agr√©gation temporelle
            if aggregation == 'daily':
                df_agg = df.groupby(df['date'].dt.date)['amount'].sum()
            elif aggregation == 'weekly':
                df_agg = df.groupby(df['date'].dt.to_period('W'))['amount'].sum()
            elif aggregation == 'monthly':
                df_agg = df.groupby(df['date'].dt.to_period('M'))['amount'].sum()
            else:
                raise ValueError(f"Invalid aggregation: {aggregation}. Must be 'daily', 'weekly', or 'monthly'")

            if len(df_agg) < 3:
                raise ValueError("Need at least 3 data points for trend analysis")

            # R√©gression lin√©aire
            x = np.arange(len(df_agg))
            y = df_agg.values

            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)

            # Forecast
            forecast_x = np.arange(len(df_agg), len(df_agg) + forecast_periods)
            forecast_y = slope * forecast_x + intercept

            # Intervalle confiance 95% (approximation via std_err)
            confidence_interval = [
                (float(pred - 1.96 * std_err * np.sqrt(1 + 1/len(x))),
                 float(pred + 1.96 * std_err * np.sqrt(1 + 1/len(x))))
                for pred in forecast_y
            ]

            # Direction tendance
            if abs(slope) < 0.1:  # Seuil arbitraire pour stabilit√©
                trend_direction = 'stable'
            elif slope > 0:
                trend_direction = 'increasing'
            else:
                trend_direction = 'decreasing'

            logger.info(
                f"Trend analysis completed: {trend_direction} "
                f"(slope={slope:.2f}, R¬≤={r_value**2:.2f})"
            )

            return TrendAnalysis(
                period=aggregation,
                trend_direction=trend_direction,
                slope=float(slope),
                r_squared=float(r_value**2),
                forecast_next_periods=forecast_y.tolist(),
                confidence_interval_95=confidence_interval
            )

        except Exception as e:
            logger.error(f"Error in calculate_trend: {str(e)}")
            raise

    # ============================================
    # UTILITAIRES
    # ============================================

    def _extract_period_label(self, df: pd.DataFrame) -> str:
        """
        Extrait label p√©riode lisible depuis DataFrame

        Args:
            df: DataFrame avec colonne 'date'

        Returns:
            Label p√©riode (ex: "2025-01-01 to 2025-01-31")
        """
        if df.empty or 'date' not in df.columns:
            return "N/A"

        dates = pd.to_datetime(df['date'])
        period_start = dates.min().strftime('%Y-%m-%d')
        period_end = dates.max().strftime('%Y-%m-%d')

        return f"{period_start} to {period_end}"
```

### 1.2.2 - Tests Unitaires

**Fichier**: `tests/unit/agents/analytics/test_analytics_agent.py`

```python
import pytest
import pandas as pd
from datetime import datetime, timedelta
from conversation_service.agents.analytics.analytics_agent import (
    AnalyticsAgent,
    TimeSeriesMetrics,
    AnomalyDetectionResult,
    TrendAnalysis
)


# ============================================
# FIXTURES
# ============================================

@pytest.fixture
def analytics_agent():
    """Instance Analytics Agent avec config par d√©faut"""
    return AnalyticsAgent()


@pytest.fixture
def sample_transactions_january():
    """Transactions janvier 2025"""
    return [
        {'id': 1, 'amount': 120.50, 'date': '2025-01-05', 'merchant_name': 'Amazon'},
        {'id': 2, 'amount': 85.00, 'date': '2025-01-12', 'merchant_name': 'Carrefour'},
        {'id': 3, 'amount': 1200.00, 'date': '2025-01-15', 'merchant_name': 'Tesla'},  # Anomalie
        {'id': 4, 'amount': 95.75, 'date': '2025-01-20', 'merchant_name': 'Netflix'},
        {'id': 5, 'amount': 110.00, 'date': '2025-01-25', 'merchant_name': 'Uber'},
    ]


@pytest.fixture
def sample_transactions_december():
    """Transactions d√©cembre 2024"""
    return [
        {'id': 10, 'amount': 110.00, 'date': '2024-12-05', 'merchant_name': 'Amazon'},
        {'id': 11, 'amount': 80.00, 'date': '2024-12-12', 'merchant_name': 'Carrefour'},
        {'id': 12, 'amount': 90.00, 'date': '2024-12-20', 'merchant_name': 'Netflix'},
    ]


# ============================================
# TESTS COMPARAISONS P√âRIODES
# ============================================

@pytest.mark.asyncio
async def test_compare_periods_sum(analytics_agent, sample_transactions_january, sample_transactions_december):
    """Test comparaison somme totale MoM"""
    result = await analytics_agent.compare_periods(
        transactions_current=sample_transactions_january,
        transactions_previous=sample_transactions_december,
        metric='sum'
    )

    # Validations
    assert isinstance(result, TimeSeriesMetrics)
    assert result.value_current == pytest.approx(1611.25, rel=0.01)  # Somme janvier
    assert result.value_previous == pytest.approx(280.00, rel=0.01)  # Somme d√©cembre
    assert result.delta == pytest.approx(1331.25, rel=0.01)
    assert result.delta_percentage > 0  # Augmentation
    assert result.trend == 'up'


@pytest.mark.asyncio
async def test_compare_periods_avg(analytics_agent, sample_transactions_january, sample_transactions_december):
    """Test comparaison moyenne"""
    result = await analytics_agent.compare_periods(
        transactions_current=sample_transactions_january,
        transactions_previous=sample_transactions_december,
        metric='avg'
    )

    assert result.value_current == pytest.approx(322.25, rel=0.01)  # Moyenne janvier
    assert result.value_previous == pytest.approx(93.33, rel=0.1)   # Moyenne d√©cembre


@pytest.mark.asyncio
async def test_compare_periods_stable(analytics_agent):
    """Test d√©tection tendance stable (<5% variation)"""
    txs_current = [{'id': i, 'amount': 100, 'date': f'2025-01-{i+1:02d}'} for i in range(10)]
    txs_previous = [{'id': i+100, 'amount': 102, 'date': f'2024-12-{i+1:02d}'} for i in range(10)]

    result = await analytics_agent.compare_periods(
        transactions_current=txs_current,
        transactions_previous=txs_previous,
        metric='sum'
    )

    assert result.trend == 'stable'  # +2% < 5% threshold


@pytest.mark.asyncio
async def test_compare_periods_empty_raises_error(analytics_agent):
    """Test erreur si liste vide"""
    with pytest.raises(ValueError, match="cannot be empty"):
        await analytics_agent.compare_periods(
            transactions_current=[],
            transactions_previous=[{'id': 1, 'amount': 100, 'date': '2024-12-01'}],
            metric='sum'
        )


@pytest.mark.asyncio
async def test_compare_periods_invalid_metric_raises_error(analytics_agent, sample_transactions_january):
    """Test erreur si m√©trique invalide"""
    with pytest.raises(ValueError, match="Invalid metric"):
        await analytics_agent.compare_periods(
            transactions_current=sample_transactions_january,
            transactions_previous=sample_transactions_january,
            metric='invalid_metric'
        )


# ============================================
# TESTS D√âTECTION ANOMALIES
# ============================================

@pytest.mark.asyncio
async def test_detect_anomalies_zscore(analytics_agent, sample_transactions_january):
    """Test d√©tection anomalies Z-score (Tesla 1200‚Ç¨ doit √™tre d√©tect√©)"""
    anomalies = await analytics_agent.detect_anomalies(
        transactions=sample_transactions_january,
        method='zscore',
        threshold=2.0
    )

    # Validations
    assert len(anomalies) >= 1

    # Transaction Tesla doit √™tre anomalie
    tesla_anomaly = next((a for a in anomalies if a.merchant_name == 'Tesla'), None)
    assert tesla_anomaly is not None
    assert tesla_anomaly.amount == 1200.00
    assert tesla_anomaly.anomaly_score > 2.0
    assert 'œÉ de la moyenne' in tesla_anomaly.explanation


@pytest.mark.asyncio
async def test_detect_anomalies_iqr(analytics_agent, sample_transactions_january):
    """Test d√©tection anomalies IQR"""
    anomalies = await analytics_agent.detect_anomalies(
        transactions=sample_transactions_january,
        method='iqr'
    )

    assert len(anomalies) >= 1
    assert all(a.method == 'iqr' for a in anomalies)
    assert all('IQR' in a.explanation for a in anomalies)


@pytest.mark.asyncio
async def test_detect_anomalies_empty_returns_empty(analytics_agent):
    """Test liste vide retourne liste vide (pas d'erreur)"""
    anomalies = await analytics_agent.detect_anomalies(
        transactions=[],
        method='zscore'
    )

    assert anomalies == []


@pytest.mark.asyncio
async def test_detect_anomalies_no_outliers(analytics_agent):
    """Test aucune anomalie si donn√©es uniformes"""
    uniform_txs = [{'id': i, 'amount': 100, 'date': f'2025-01-{i+1:02d}', 'merchant_name': 'Test'} for i in range(20)]

    anomalies = await analytics_agent.detect_anomalies(
        transactions=uniform_txs,
        method='zscore',
        threshold=2.0
    )

    assert len(anomalies) == 0


# ============================================
# TESTS CALCUL TENDANCES
# ============================================

@pytest.mark.asyncio
async def test_calculate_trend_increasing(analytics_agent):
    """Test tendance croissante"""
    # Donn√©es lin√©aires croissantes
    txs = [
        {'id': i, 'amount': 100 + i * 20, 'date': f'2024-{7+i:02d}-01'}
        for i in range(6)  # Juillet √† d√©cembre
    ]

    trend = await analytics_agent.calculate_trend(
        transactions=txs,
        aggregation='monthly',
        forecast_periods=3
    )

    # Validations
    assert trend.trend_direction == 'increasing'
    assert trend.slope > 0
    assert trend.r_squared > 0.95  # Excellente corr√©lation lin√©aire
    assert len(trend.forecast_next_periods) == 3
    assert all(trend.forecast_next_periods[i] < trend.forecast_next_periods[i+1] for i in range(2))  # Croissant


@pytest.mark.asyncio
async def test_calculate_trend_decreasing(analytics_agent):
    """Test tendance d√©croissante"""
    txs = [
        {'id': i, 'amount': 500 - i * 30, 'date': f'2024-{7+i:02d}-01'}
        for i in range(6)
    ]

    trend = await analytics_agent.calculate_trend(
        transactions=txs,
        aggregation='monthly',
        forecast_periods=3
    )

    assert trend.trend_direction == 'decreasing'
    assert trend.slope < 0


@pytest.mark.asyncio
async def test_calculate_trend_confidence_intervals(analytics_agent):
    """Test intervalles de confiance 95%"""
    txs = [
        {'id': i, 'amount': 100 + i * 10, 'date': f'2024-{7+i:02d}-01'}
        for i in range(6)
    ]

    trend = await analytics_agent.calculate_trend(
        transactions=txs,
        aggregation='monthly',
        forecast_periods=3
    )

    # Validations intervalles
    assert len(trend.confidence_interval_95) == 3
    for (lower, upper), forecast in zip(trend.confidence_interval_95, trend.forecast_next_periods):
        assert lower < forecast < upper  # Forecast dans l'intervalle


@pytest.mark.asyncio
async def test_calculate_trend_insufficient_data_raises_error(analytics_agent):
    """Test erreur si donn√©es insuffisantes (<3 points)"""
    txs = [
        {'id': 1, 'amount': 100, 'date': '2024-12-01'},
        {'id': 2, 'amount': 110, 'date': '2025-01-01'}
    ]

    with pytest.raises(ValueError, match="at least 3 data points"):
        await analytics_agent.calculate_trend(txs, 'monthly', 3)


# ============================================
# TESTS COVERAGE
# ============================================

def test_analytics_agent_initialization():
    """Test initialisation avec config custom"""
    agent = AnalyticsAgent(
        zscore_threshold=3.0,
        iqr_multiplier=2.0,
        stable_threshold_pct=10.0
    )

    assert agent.zscore_threshold == 3.0
    assert agent.iqr_multiplier == 2.0
    assert agent.stable_threshold_pct == 10.0


@pytest.mark.asyncio
async def test_period_label_extraction(analytics_agent):
    """Test extraction labels p√©riodes"""
    txs = [
        {'id': 1, 'amount': 100, 'date': '2025-01-05'},
        {'id': 2, 'amount': 150, 'date': '2025-01-25'}
    ]

    result = await analytics_agent.compare_periods(
        transactions_current=txs,
        transactions_previous=txs,
        metric='sum'
    )

    assert '2025-01-05' in result.period_current
    assert '2025-01-25' in result.period_current


# ============================================
# CRIT√àRES DE SUCC√àS
# ============================================

"""
‚úÖ Coverage >90% (pytest --cov=conversation_service.agents.analytics)
‚úÖ Tous les tests passent
‚úÖ Pas de warnings
‚úÖ Tests couvrent:
   - Cas nominaux (donn√©es valides)
   - Cas limites (listes vides, 1 √©l√©ment, donn√©es uniformes)
   - Gestion erreurs (ValueError, donn√©es invalides)
   - Performance (chaque m√©thode <100ms)
"""
```

### Crit√®res de Validation T1.2

‚úÖ Fichier `analytics_agent.py` cr√©√© avec 3 classes principales (TimeSeriesMetrics, AnomalyDetectionResult, TrendAnalysis)
‚úÖ 3 m√©thodes principales impl√©ment√©es (compare_periods, detect_anomalies, calculate_trend)
‚úÖ Tests unitaires >90% coverage
‚úÖ Tous les tests passent (pytest)
‚úÖ Documentation compl√®te (docstrings d√©taill√©s)
‚úÖ Logging appropri√© (info, warning, error)

---

## üß™ T√¢che 1.3 - Tests E2E Analytics Agent Standalone

**Dur√©e**: 2 jours
**Responsable**: Dev Backend + QA

### Objectif

Valider le comportement de l'Analytics Agent avec des donn√©es r√©alistes et mesurer les performances.

### Fichier de Tests E2E

**Fichier**: `tests/e2e/analytics/test_analytics_agent_e2e.py`

```python
import pytest
import time
from datetime import datetime, timedelta
from conversation_service.agents.analytics.analytics_agent import AnalyticsAgent


# ============================================
# FIXTURES DONN√âES R√âALISTES
# ============================================

@pytest.fixture
def real_january_transactions():
    """
    Transactions r√©alistes janvier 2025 (30 jours)
    - Alimentations r√©guli√®res (~50-150‚Ç¨)
    - Transport (Uber, essence)
    - Abonnements (Netflix, Spotify)
    - 1 anomalie (Tesla 1200‚Ç¨)
    """
    base_date = datetime(2025, 1, 1)
    txs = []

    # Alimentations (20 transactions)
    for day in [2, 5, 8, 11, 14, 17, 20, 23, 26, 29]:
        txs.extend([
            {'id': len(txs)+1, 'amount': 85.50, 'date': (base_date + timedelta(days=day)).isoformat(),
             'merchant_name': 'Carrefour', 'category': 'Alimentation'},
            {'id': len(txs)+2, 'amount': 42.30, 'date': (base_date + timedelta(days=day+1)).isoformat(),
             'merchant_name': 'Boulangerie', 'category': 'Alimentation'},
        ])

    # Transport (8 transactions)
    for day in [3, 9, 15, 21]:
        txs.extend([
            {'id': len(txs)+1, 'amount': 18.50, 'date': (base_date + timedelta(days=day)).isoformat(),
             'merchant_name': 'Uber', 'category': 'Transport'},
            {'id': len(txs)+2, 'amount': 65.00, 'date': (base_date + timedelta(days=day+3)).isoformat(),
             'merchant_name': 'Station Service', 'category': 'Transport'},
        ])

    # Abonnements mensuels
    txs.extend([
        {'id': len(txs)+1, 'amount': 15.99, 'date': (base_date + timedelta(days=1)).isoformat(),
         'merchant_name': 'Netflix', 'category': 'Loisirs'},
        {'id': len(txs)+2, 'amount': 10.99, 'date': (base_date + timedelta(days=1)).isoformat(),
         'merchant_name': 'Spotify', 'category': 'Loisirs'},
    ])

    # ANOMALIE: Achat Tesla
    txs.append({
        'id': len(txs)+1,
        'amount': 1200.00,
        'date': (base_date + timedelta(days=15)).isoformat(),
        'merchant_name': 'Tesla',
        'category': 'Voiture'
    })

    return txs


@pytest.fixture
def real_december_transactions():
    """Transactions d√©cembre 2024 (similaires mais -10%)"""
    base_date = datetime(2024, 12, 1)
    txs = []

    # Alimentations (18 transactions, -10%)
    for day in [2, 6, 10, 14, 18, 22, 26, 29]:
        txs.extend([
            {'id': len(txs)+1, 'amount': 77.00, 'date': (base_date + timedelta(days=day)).isoformat(),
             'merchant_name': 'Carrefour', 'category': 'Alimentation'},
            {'id': len(txs)+2, 'amount': 38.00, 'date': (base_date + timedelta(days=day+1)).isoformat(),
             'merchant_name': 'Boulangerie', 'category': 'Alimentation'},
        ])

    # Transport
    for day in [4, 10, 16, 22]:
        txs.extend([
            {'id': len(txs)+1, 'amount': 16.50, 'date': (base_date + timedelta(days=day)).isoformat(),
             'merchant_name': 'Uber', 'category': 'Transport'},
            {'id': len(txs)+2, 'amount': 58.00, 'date': (base_date + timedelta(days=day+3)).isoformat(),
             'merchant_name': 'Station Service', 'category': 'Transport'},
        ])

    # Abonnements
    txs.extend([
        {'id': len(txs)+1, 'amount': 15.99, 'date': (base_date + timedelta(days=1)).isoformat(),
         'merchant_name': 'Netflix', 'category': 'Loisirs'},
        {'id': len(txs)+2, 'amount': 10.99, 'date': (base_date + timedelta(days=1)).isoformat(),
         'merchant_name': 'Spotify', 'category': 'Loisirs'},
    ])

    return txs


# ============================================
# TESTS E2E R√âALISTES
# ============================================

@pytest.mark.e2e
@pytest.mark.asyncio
async def test_e2e_mom_comparison_realistic(real_january_transactions, real_december_transactions):
    """
    Test E2E: Comparaison MoM avec donn√©es r√©alistes

    Sc√©nario:
    - Janvier: ~1900‚Ç¨ de d√©penses (incluant Tesla 1200‚Ç¨)
    - D√©cembre: ~950‚Ç¨ de d√©penses
    - Variation attendue: ~+100% (doublement)

    Validation:
    - Delta calcul√© correctement
    - Pourcentage coh√©rent
    - Tendance = 'up'
    - Performance <100ms
    """
    agent = AnalyticsAgent()

    start_time = time.time()
    result = await agent.compare_periods(
        transactions_current=real_january_transactions,
        transactions_previous=real_december_transactions,
        metric='sum'
    )
    execution_time_ms = (time.time() - start_time) * 1000

    # Validations m√©tier
    assert result.value_current > 1800  # Janvier >1800‚Ç¨
    assert result.value_previous < 1000  # D√©cembre <1000‚Ç¨
    assert result.delta_percentage > 80  # Au moins +80%
    assert result.trend == 'up'

    # Validation performance
    assert execution_time_ms < 100, f"Performance: {execution_time_ms:.0f}ms (attendu <100ms)"

    print(f"""
    ‚úÖ Test E2E MoM Comparison passed:
    - Janvier: {result.value_current:.2f}‚Ç¨
    - D√©cembre: {result.value_previous:.2f}‚Ç¨
    - Variation: {result.delta_percentage:+.1f}%
    - Performance: {execution_time_ms:.0f}ms
    """)


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_e2e_anomaly_detection_tesla(real_january_transactions):
    """
    Test E2E: D√©tection anomalie Tesla 1200‚Ç¨

    Validation:
    - Tesla d√©tect√© comme anomalie
    - Score Z > 2.0
    - Explication claire
    - Performance <200ms
    """
    agent = AnalyticsAgent()

    start_time = time.time()
    anomalies = await agent.detect_anomalies(
        transactions=real_january_transactions,
        method='zscore',
        threshold=2.0
    )
    execution_time_ms = (time.time() - start_time) * 1000

    # Validations
    assert len(anomalies) >= 1, "Au moins 1 anomalie (Tesla) attendue"

    tesla_anomaly = next((a for a in anomalies if a.merchant_name == 'Tesla'), None)
    assert tesla_anomaly is not None, "Transaction Tesla non d√©tect√©e"
    assert tesla_anomaly.amount == 1200.00
    assert tesla_anomaly.anomaly_score > 2.0

    # Performance
    assert execution_time_ms < 200, f"Performance: {execution_time_ms:.0f}ms (attendu <200ms)"

    print(f"""
    ‚úÖ Test E2E Anomaly Detection passed:
    - Anomalies d√©tect√©es: {len(anomalies)}
    - Tesla: {tesla_anomaly.amount}‚Ç¨ (score: {tesla_anomaly.anomaly_score:.2f})
    - Explication: {tesla_anomaly.explanation}
    - Performance: {execution_time_ms:.0f}ms
    """)


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_e2e_trend_analysis_6_months():
    """
    Test E2E: Analyse tendance sur 6 mois

    Sc√©nario:
    - D√©penses mensuelles croissantes (400‚Ç¨ ‚Üí 550‚Ç¨)
    - Forecast 3 mois suivants
    - Intervalles confiance 95%

    Validation:
    - Tendance = 'increasing'
    - R¬≤ > 0.85 (bon fit)
    - Forecast coh√©rent (570‚Ç¨, 600‚Ç¨, 630‚Ç¨)
    - Performance <500ms
    """
    # G√©n√©ration donn√©es 6 mois croissants
    base_amounts = [400, 425, 460, 490, 520, 550]
    transactions = []

    for i, amount in enumerate(base_amounts):
        month = 7 + i  # Juillet √† d√©cembre
        base_date = datetime(2024, month, 1)

        # 20 transactions par mois pour simuler r√©alisme
        for day in range(1, 21):
            transactions.append({
                'id': len(transactions) + 1,
                'amount': amount / 20,  # R√©partition montant mensuel
                'date': (base_date + timedelta(days=day)).isoformat(),
                'merchant_name': f'Merchant_{day}',
                'category': 'Alimentation'
            })

    agent = AnalyticsAgent()

    start_time = time.time()
    trend = await agent.calculate_trend(
        transactions=transactions,
        aggregation='monthly',
        forecast_periods=3
    )
    execution_time_ms = (time.time() - start_time) * 1000

    # Validations
    assert trend.trend_direction == 'increasing'
    assert trend.r_squared > 0.85, f"R¬≤ trop faible: {trend.r_squared:.2f}"
    assert trend.slope > 0
    assert len(trend.forecast_next_periods) == 3

    # Forecast coh√©rent (autour de 570-630‚Ç¨)
    assert 550 < trend.forecast_next_periods[0] < 650
    assert 570 < trend.forecast_next_periods[1] < 670
    assert 590 < trend.forecast_next_periods[2] < 690

    # Performance
    assert execution_time_ms < 500, f"Performance: {execution_time_ms:.0f}ms (attendu <500ms)"

    print(f"""
    ‚úÖ Test E2E Trend Analysis passed:
    - Tendance: {trend.trend_direction}
    - R¬≤: {trend.r_squared:.3f}
    - Pente: {trend.slope:+.2f}‚Ç¨/mois
    - Forecast 3 mois: {[f'{p:.0f}‚Ç¨' for p in trend.forecast_next_periods]}
    - Performance: {execution_time_ms:.0f}ms
    """)


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_e2e_full_analytics_pipeline():
    """
    Test E2E complet: Pipeline Analytics complet

    Sc√©nario:
    1. Comparaison MoM
    2. D√©tection anomalies
    3. Calcul tendance
    4. Validation coh√©rence globale

    Validation:
    - Toutes m√©thodes fonctionnent ensemble
    - Pas de conflit
    - Performance globale <1s
    """
    agent = AnalyticsAgent()

    # Donn√©es test
    jan_txs = [
        {'id': i, 'amount': 100 + i * 5, 'date': f'2025-01-{i+1:02d}', 'merchant_name': f'M{i}'}
        for i in range(30)
    ]
    dec_txs = [
        {'id': i+100, 'amount': 95 + i * 5, 'date': f'2024-12-{i+1:02d}', 'merchant_name': f'M{i}'}
        for i in range(30)
    ]
    jan_txs.append({'id': 999, 'amount': 5000, 'date': '2025-01-31', 'merchant_name': 'Anomaly'})

    start_time = time.time()

    # 1. Comparaison MoM
    mom = await agent.compare_periods(jan_txs, dec_txs, 'avg')

    # 2. D√©tection anomalies
    anomalies = await agent.detect_anomalies(jan_txs, 'zscore')

    # 3. Tendance
    all_txs = dec_txs + jan_txs
    trend = await agent.calculate_trend(all_txs, 'monthly', 2)

    execution_time_ms = (time.time() - start_time) * 1000

    # Validations globales
    assert mom.delta_percentage != 0  # Changement d√©tect√©
    assert len(anomalies) > 0  # Anomalie 5000‚Ç¨ d√©tect√©e
    assert trend.r_squared > 0.8  # Tendance fiable
    assert execution_time_ms < 1000  # <1s total

    print(f"""
    ‚úÖ Test E2E Full Pipeline passed:
    - MoM: {mom.delta_percentage:+.1f}%
    - Anomalies: {len(anomalies)}
    - Trend: {trend.trend_direction} (R¬≤={trend.r_squared:.2f})
    - Performance totale: {execution_time_ms:.0f}ms
    """)


# ============================================
# BENCHMARK PERFORMANCE
# ============================================

@pytest.mark.e2e
@pytest.mark.benchmark
@pytest.mark.asyncio
async def test_benchmark_performance():
    """
    Benchmark: Performance avec volumes r√©alistes

    Volumes:
    - 100 transactions MoM comparison: <100ms
    - 500 transactions anomaly detection: <200ms
    - 1000 transactions trend analysis: <500ms
    """
    agent = AnalyticsAgent()

    # Dataset 100 txs
    txs_100 = [{'id': i, 'amount': 100 + i, 'date': f'2025-01-01', 'merchant_name': f'M{i}'} for i in range(100)]

    start = time.time()
    await agent.compare_periods(txs_100, txs_100, 'sum')
    time_100_mom = (time.time() - start) * 1000

    # Dataset 500 txs
    txs_500 = [{'id': i, 'amount': 100 + i, 'date': f'2025-01-01', 'merchant_name': f'M{i}'} for i in range(500)]

    start = time.time()
    await agent.detect_anomalies(txs_500, 'zscore')
    time_500_anomaly = (time.time() - start) * 1000

    # Dataset 1000 txs (12 mois)
    txs_1000 = []
    for month in range(1, 13):
        for i in range(83):  # ~1000 txs / 12 mois
            txs_1000.append({
                'id': len(txs_1000),
                'amount': 100 + i,
                'date': f'2024-{month:02d}-01',
                'merchant_name': f'M{i}'
            })

    start = time.time()
    await agent.calculate_trend(txs_1000, 'monthly', 3)
    time_1000_trend = (time.time() - start) * 1000

    # Assertions performance
    assert time_100_mom < 100, f"MoM 100 txs: {time_100_mom:.0f}ms (attendu <100ms)"
    assert time_500_anomaly < 200, f"Anomaly 500 txs: {time_500_anomaly:.0f}ms (attendu <200ms)"
    assert time_1000_trend < 500, f"Trend 1000 txs: {time_1000_trend:.0f}ms (attendu <500ms)"

    print(f"""
    ‚úÖ Benchmark Performance passed:
    - MoM 100 txs: {time_100_mom:.0f}ms (<100ms) ‚úì
    - Anomaly 500 txs: {time_500_anomaly:.0f}ms (<200ms) ‚úì
    - Trend 1000 txs: {time_1000_trend:.0f}ms (<500ms) ‚úì
    """)


# ============================================
# CRIT√àRES DE SUCC√àS E2E
# ============================================

"""
‚úÖ Tous les tests E2E passent
‚úÖ Performances respect√©es:
   - MoM comparison: <100ms
   - Anomaly detection: <200ms
   - Trend analysis: <500ms
‚úÖ Anomalie Tesla d√©tect√©e correctement
‚úÖ Comparaisons MoM coh√©rentes (¬±2% tol√©rance)
‚úÖ Trends avec R¬≤ >0.85
‚úÖ Pipeline complet <1s
"""
```

### Ex√©cution Tests E2E

```bash
# Lancer tests E2E uniquement
pytest tests/e2e/analytics/test_analytics_agent_e2e.py -v

# Avec benchmark
pytest tests/e2e/analytics/test_analytics_agent_e2e.py -v -m benchmark

# Avec coverage
pytest tests/e2e/analytics/ --cov=conversation_service.agents.analytics --cov-report=html

# G√©n√©rer rapport
open htmlcov/index.html  # V√©rifier coverage >90%
```

### Crit√®res de Validation T1.3

‚úÖ Tous les tests E2E passent
‚úÖ Benchmark performance respect√© (<100ms, <200ms, <500ms)
‚úÖ Anomalie Tesla d√©tect√©e avec score >2.0
‚úÖ Comparaisons MoM avec variation coh√©rente
‚úÖ Tendances avec R¬≤ >0.85
‚úÖ Coverage E2E >85%

---

## üîó T√¢che 1.4 - Int√©gration Response Generator

**Dur√©e**: 2 jours
**Responsable**: Dev Backend + Dev Lead

### Objectif

Int√©grer l'Analytics Agent dans le Response Generator pour enrichir les r√©ponses avec des insights analytiques avanc√©s, tout en pr√©servant le fallback vers le comportement v3.2.6 si l'Analytics Agent √©choue.

### Modifications Response Generator

**Fichier**: `conversation_service/agents/llm/response_generator.py`

```python
# Ajouts au d√©but du fichier
from conversation_service.agents.analytics.analytics_agent import (
    AnalyticsAgent,
    TimeSeriesMetrics,
    AnomalyDetectionResult
)
from typing import Optional, List, Dict, Any
import logging

logger = logging.getLogger(__name__)


class ResponseGenerator:
    """Response Generator avec Analytics Agent int√©gr√©"""

    def __init__(
        self,
        llm_manager: LLMProviderManager,
        response_templates_path: Optional[str] = None,
        model: str = "deepseek-chat",
        max_tokens: int = 8000,
        temperature: float = 0.7,
        enable_analytics: bool = True  # üÜï Feature flag
    ):
        self.llm_manager = llm_manager
        self.response_templates_path = response_templates_path
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.enable_analytics = enable_analytics

        # üÜï Initialisation Analytics Agent
        if self.enable_analytics:
            try:
                self.analytics_agent = AnalyticsAgent()
                logger.info("Analytics Agent initialized successfully")
            except Exception as e:
                logger.warning(f"Failed to initialize Analytics Agent: {e}. Fallback to basic insights.")
                self.analytics_agent = None
        else:
            self.analytics_agent = None
            logger.info("Analytics Agent disabled (feature flag off)")

        logger.info(
            f"ResponseGenerator initialized (model={self.model}, max_tokens={self.max_tokens}, "
            f"temperature={self.temperature}, analytics={self.enable_analytics})"
        )

    async def generate_response(
        self,
        intent: str,
        entities: Dict[str, Any],
        search_results: List[Dict],
        conversation_history: List[Dict],
        user_profile: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        G√©n√®re r√©ponse enrichie avec insights Analytics Agent

        Workflow:
        1. G√©n√©ration insights basiques (existant v3.2.6)
        2. üÜï Si Analytics Agent disponible ET intent compatible:
           - Tentative enrichissement insights analytiques
           - Si succ√®s: ajout insights MoM/YoY/anomalies/trends
           - Si √©chec: fallback insights basiques (pas d'erreur utilisateur)
        3. Construction prompt LLM avec insights enrichis
        4. G√©n√©ration r√©ponse finale

        Args:
            intent: Intention classifi√©e
            entities: Entit√©s extraites
            search_results: R√©sultats requ√™te Elasticsearch
            conversation_history: Historique conversation
            user_profile: Profil utilisateur (optionnel)

        Returns:
            Dict avec response_text, insights, visualizations
        """
        try:
            # √âtape 1: Insights basiques (v3.2.6 - toujours ex√©cut√©)
            basic_insights = self._generate_basic_insights(search_results)

            # √âtape 2: üÜï Enrichissement Analytics Agent (si disponible)
            analytics_insights = {}
            if self.analytics_agent and self._should_use_analytics(intent):
                try:
                    analytics_insights = await self._generate_analytics_insights(
                        intent=intent,
                        entities=entities,
                        transactions=search_results,
                        user_profile=user_profile
                    )
                    logger.info(f"Analytics insights generated: {list(analytics_insights.keys())}")
                except Exception as e:
                    # üõ°Ô∏è CRITICAL: Fallback gracieux, pas d'erreur utilisateur
                    logger.warning(f"Analytics insights generation failed: {e}. Using basic insights only.")
                    analytics_insights = {}

            # Fusion insights (analytics prend priorit√© si disponible)
            combined_insights = {**basic_insights, **analytics_insights}

            # √âtape 3: Construction prompt avec insights enrichis
            prompt = self._build_prompt(
                intent=intent,
                entities=entities,
                transactions=search_results,
                insights=combined_insights,
                conversation_history=conversation_history
            )

            # √âtape 4: G√©n√©ration r√©ponse LLM
            llm_response = await self.llm_manager.complete(
                prompt=prompt,
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )

            return {
                'response_text': llm_response.content,
                'insights': combined_insights,
                'analytics_used': bool(analytics_insights),
                'model': self.model,
                'tokens_used': llm_response.usage.total_tokens if hasattr(llm_response, 'usage') else 0
            }

        except Exception as e:
            logger.error(f"Error in generate_response: {str(e)}")
            raise

    def _should_use_analytics(self, intent: str) -> bool:
        """
        D√©termine si l'Analytics Agent doit √™tre utilis√© pour cet intent

        Intents compatibles:
        - Comparaisons temporelles (MoM, YoY)
        - Analyses de tendances
        - D√©tection anomalies implicite

        Args:
            intent: Intention classifi√©e

        Returns:
            True si Analytics Agent doit √™tre appel√©
        """
        analytics_compatible_intents = [
            'transaction_search.by_period',
            'financial_query.expenses',
            'financial_query.income',
            'transaction_search.by_category',
            'comparison'  # üÜï Intent explicite comparaison
        ]

        # V√©rification intent explicite OU pr√©sence keywords comparaison
        return (
            intent in analytics_compatible_intents or
            'comparison' in intent.lower() or
            'vs' in intent.lower() or
            'compare' in intent.lower()
        )

    async def _generate_analytics_insights(
        self,
        intent: str,
        entities: Dict[str, Any],
        transactions: List[Dict],
        user_profile: Optional[Dict]
    ) -> Dict[str, Any]:
        """
        üÜï G√©n√®re insights analytiques avanc√©s via Analytics Agent

        Capabilities ajout√©es:
        - Comparaisons MoM/YoY si p√©riode d√©tect√©e
        - D√©tection anomalies syst√©matique (top 3)
        - Calcul tendance si historique >3 mois

        Args:
            intent: Intention
            entities: Entit√©s extraites (dates, montants, etc.)
            transactions: Transactions √† analyser
            user_profile: Profil utilisateur

        Returns:
            Dict insights analytiques (vide si erreur)

        Raises:
            Exception: Propag√©e au caller pour fallback gracieux
        """
        insights = {}

        if not transactions:
            logger.debug("No transactions for analytics insights")
            return insights

        # 1. üîç D√©tection anomalies (toujours ex√©cut√© si >10 txs)
        if len(transactions) >= 10:
            try:
                anomalies = await self.analytics_agent.detect_anomalies(
                    transactions=transactions,
                    method='zscore',
                    threshold=2.0
                )

                # Top 3 anomalies les plus importantes
                top_anomalies = anomalies[:3]
                if top_anomalies:
                    insights['anomalies'] = [
                        {
                            'merchant': a.merchant_name,
                            'amount': a.amount,
                            'date': a.date.strftime('%Y-%m-%d'),
                            'score': round(a.anomaly_score, 2),
                            'explanation': a.explanation
                        }
                        for a in top_anomalies
                    ]
                    logger.info(f"Detected {len(top_anomalies)} anomalies")
            except Exception as e:
                logger.warning(f"Anomaly detection failed: {e}")

        # 2. üìä Comparaisons temporelles MoM/YoY
        # D√©tection si p√©riode comparative dans entities ou intent
        has_comparison_keywords = (
            'comparison' in intent.lower() or
            'vs' in intent.lower() or
            'compare' in intent.lower() or
            entities.get('date_range_type') in ['month_over_month', 'year_over_year']
        )

        if has_comparison_keywords:
            try:
                # Tentative split transactions en 2 p√©riodes
                # (Simplifi√© Phase 1 - Phase 2 aura Reasoning Agent pour logique complexe)
                current_period, previous_period = self._split_transactions_by_period(
                    transactions,
                    entities
                )

                if current_period and previous_period:
                    comparison = await self.analytics_agent.compare_periods(
                        transactions_current=current_period,
                        transactions_previous=previous_period,
                        metric='sum'
                    )

                    insights['temporal_comparison'] = {
                        'period_current': comparison.period_current,
                        'period_previous': comparison.period_previous,
                        'value_current': round(comparison.value_current, 2),
                        'value_previous': round(comparison.value_previous, 2),
                        'delta': round(comparison.delta, 2),
                        'delta_percentage': round(comparison.delta_percentage, 1),
                        'trend': comparison.trend
                    }
                    logger.info(f"Temporal comparison: {comparison.delta_percentage:+.1f}%")
            except Exception as e:
                logger.warning(f"Temporal comparison failed: {e}")

        # 3. üìà Calcul tendance (si historique >3 p√©riodes)
        # Check si transactions span >3 mois
        if len(transactions) > 30:  # Approximation (>30 txs = probablement >1 mois)
            try:
                import pandas as pd
                df = pd.DataFrame(transactions)
                df['date'] = pd.to_datetime(df['date'])

                # V√©rifier span temporel
                date_span = (df['date'].max() - df['date'].min()).days

                if date_span > 60:  # >2 mois
                    trend = await self.analytics_agent.calculate_trend(
                        transactions=transactions,
                        aggregation='monthly',
                        forecast_periods=1
                    )

                    insights['trend_analysis'] = {
                        'direction': trend.trend_direction,
                        'slope': round(trend.slope, 2),
                        'r_squared': round(trend.r_squared, 2),
                        'forecast_next_month': round(trend.forecast_next_periods[0], 2) if trend.forecast_next_periods else None,
                        'confidence_interval': [round(x, 2) for x in trend.confidence_interval_95[0]] if trend.confidence_interval_95 else None
                    }
                    logger.info(f"Trend analysis: {trend.trend_direction} (R¬≤={trend.r_squared:.2f})")
            except Exception as e:
                logger.warning(f"Trend analysis failed: {e}")

        return insights

    def _split_transactions_by_period(
        self,
        transactions: List[Dict],
        entities: Dict[str, Any]
    ) -> tuple[List[Dict], List[Dict]]:
        """
        üÜï Split transactions en 2 p√©riodes pour comparaison

        Logique simplifi√©e Phase 1:
        - Si date_range pr√©sent dans entities: utiliser
        - Sinon: heuristique 50/50 (premi√®re moiti√© vs seconde moiti√©)

        Phase 2 aura Reasoning Agent pour logique sophistiqu√©e.

        Args:
            transactions: Transactions √† splitter
            entities: Entit√©s avec potentiellement date_range

        Returns:
            Tuple (p√©riode_actuelle, p√©riode_pr√©c√©dente)
        """
        import pandas as pd

        df = pd.DataFrame(transactions)
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')

        # Strat√©gie simplifi√©e: split au milieu
        mid_point = len(df) // 2

        current_period = df.iloc[mid_point:].to_dict('records')
        previous_period = df.iloc[:mid_point].to_dict('records')

        return current_period, previous_period

    def _generate_basic_insights(self, transactions: List[Dict]) -> Dict[str, Any]:
        """
        G√©n√®re insights basiques (existant v3.2.6)

        Note: Cette m√©thode existe d√©j√† dans v3.2.6.
        Conserv√©e telle quelle pour compatibilit√©.

        Args:
            transactions: Transactions √† analyser

        Returns:
            Dict insights basiques (total, moyenne, patterns)
        """
        # Impl√©mentation existante v3.2.6
        # (Code non modifi√©)

        if not transactions:
            return {}

        total = sum(t.get('amount', 0) for t in transactions)
        avg = total / len(transactions) if transactions else 0

        return {
            'total_amount': round(total, 2),
            'average_amount': round(avg, 2),
            'transaction_count': len(transactions)
        }

    def _build_prompt(
        self,
        intent: str,
        entities: Dict,
        transactions: List[Dict],
        insights: Dict[str, Any],
        conversation_history: List[Dict]
    ) -> str:
        """
        Construction prompt LLM enrichi avec insights Analytics

        üÜï Modifications Phase 1:
        - Ajout section "Insights Analytiques Avanc√©s" si disponibles
        - Instructions LLM pour utiliser comparaisons/anomalies/trends

        Args:
            intent: Intention
            entities: Entit√©s
            transactions: Transactions
            insights: Insights combin√©s (basiques + analytics)
            conversation_history: Historique

        Returns:
            Prompt LLM format√©
        """
        # Base prompt (existant v3.2.6)
        prompt = f"""Tu es un assistant financier personnel intelligent.

Intention utilisateur: {intent}
Entit√©s d√©tect√©es: {entities}

Donn√©es transactions:
- Nombre: {len(transactions)}
- Total: {insights.get('total_amount', 0)}‚Ç¨
- Moyenne: {insights.get('average_amount', 0)}‚Ç¨
"""

        # üÜï Ajout insights Analytics si disponibles
        if 'temporal_comparison' in insights:
            comp = insights['temporal_comparison']
            prompt += f"""

üìä Comparaison Temporelle:
- P√©riode actuelle: {comp['period_current']} ({comp['value_current']}‚Ç¨)
- P√©riode pr√©c√©dente: {comp['period_previous']} ({comp['value_previous']}‚Ç¨)
- Variation: {comp['delta']:+.2f}‚Ç¨ ({comp['delta_percentage']:+.1f}%)
- Tendance: {comp['trend']}

‚û°Ô∏è Utilise ces donn√©es pour expliquer l'√©volution des d√©penses.
"""

        if 'anomalies' in insights and insights['anomalies']:
            prompt += f"""

üîç Transactions Anormales D√©tect√©es:
"""
            for i, anomaly in enumerate(insights['anomalies'][:3], 1):
                prompt += f"{i}. {anomaly['merchant']}: {anomaly['amount']}‚Ç¨ le {anomaly['date']} (score: {anomaly['score']})\n"
                prompt += f"   Raison: {anomaly['explanation']}\n"

            prompt += "\n‚û°Ô∏è Mentionne ces transactions inhabituelles dans ta r√©ponse.\n"

        if 'trend_analysis' in insights:
            trend = insights['trend_analysis']
            prompt += f"""

üìà Analyse de Tendance:
- Direction: {trend['direction']}
- Qualit√© mod√®le: R¬≤={trend['r_squared']:.2f} (1.0 = parfait)
- Forecast mois prochain: ~{trend['forecast_next_month']}‚Ç¨
{f"- Intervalle confiance 95%: [{trend['confidence_interval'][0]:.0f}‚Ç¨, {trend['confidence_interval'][1]:.0f}‚Ç¨]" if trend['confidence_interval'] else ""}

‚û°Ô∏è Explique la tendance observ√©e et donne un aper√ßu du mois prochain.
"""

        prompt += """

Instructions:
1. G√©n√®re une r√©ponse personnalis√©e et naturelle
2. Utilise les insights analytiques pour enrichir ta r√©ponse
3. Sois concis mais informatif
4. Si anomalies d√©tect√©es, explique pourquoi elles sont inhabituelles
5. Si comparaison temporelle disponible, commente l'√©volution
6. Si tendance disponible, donne des conseils bas√©s sur la direction

R√©ponse:
"""

        return prompt
```

### Tests d'Int√©gration Response Generator

**Fichier**: `tests/e2e/test_response_generator_with_analytics.py`

```python
import pytest
from conversation_service.agents.llm.response_generator import ResponseGenerator
from conversation_service.agents.analytics.analytics_agent import AnalyticsAgent


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_response_generator_with_analytics_mom():
    """
    Test E2E: Response Generator avec Analytics Agent (MoM)

    Sc√©nario:
    - User: "Compare mes d√©penses ce mois vs mois dernier"
    - Intent: "comparison"
    - Analytics Agent d√©tecte +25% MoM
    - Response Generator inclut insights dans r√©ponse

    Validation:
    - analytics_used = True
    - insights contient temporal_comparison
    - response_text mentionne variation %
    """
    # Mock LLM Manager
    mock_llm = MockLLMManager()

    # Init Response Generator avec Analytics
    response_gen = ResponseGenerator(
        llm_manager=mock_llm,
        enable_analytics=True
    )

    # Donn√©es test
    january_txs = [
        {'id': i, 'amount': 100 + i * 5, 'date': f'2025-01-{i+1:02d}', 'merchant_name': f'Merchant {i}'}
        for i in range(30)
    ]
    december_txs = [
        {'id': i+100, 'amount': 80 + i * 5, 'date': f'2024-12-{i+1:02d}', 'merchant_name': f'Merchant {i}'}
        for i in range(30)
    ]

    all_txs = december_txs + january_txs

    # G√©n√©ration r√©ponse
    result = await response_gen.generate_response(
        intent='comparison',
        entities={'date_range_type': 'month_over_month'},
        search_results=all_txs,
        conversation_history=[],
        user_profile=None
    )

    # Validations
    assert result['analytics_used'] is True, "Analytics Agent should be used"
    assert 'temporal_comparison' in result['insights'], "MoM comparison missing"

    comp = result['insights']['temporal_comparison']
    assert comp['delta_percentage'] != 0, "Should detect variation"
    assert comp['trend'] in ['up', 'down', 'stable']

    # V√©rifier r√©ponse LLM inclut insights
    assert 'variation' in result['response_text'].lower() or '√©volution' in result['response_text'].lower()

    print(f"""
    ‚úÖ Test Response Generator with Analytics (MoM) passed:
    - Analytics used: {result['analytics_used']}
    - MoM variation: {comp['delta_percentage']:+.1f}%
    - Response excerpt: {result['response_text'][:200]}...
    """)


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_response_generator_fallback_on_analytics_error():
    """
    Test E2E: Fallback gracieux si Analytics Agent √©choue

    Sc√©nario:
    - Analytics Agent raise exception (donn√©es invalides)
    - Response Generator doit:
      1. Logger warning
      2. Fallback vers basic insights
      3. G√©n√©rer r√©ponse valide (pas d'erreur utilisateur)

    Validation:
    - analytics_used = False
    - response_text g√©n√©r√© quand m√™me
    - basic insights pr√©sents
    """
    mock_llm = MockLLMManager()

    response_gen = ResponseGenerator(
        llm_manager=mock_llm,
        enable_analytics=True
    )

    # Donn√©es invalides (pas de colonne 'amount')
    invalid_txs = [
        {'id': 1, 'invalid_field': 100, 'date': '2025-01-01'}
    ]

    # G√©n√©ration r√©ponse (ne doit PAS raise exception)
    result = await response_gen.generate_response(
        intent='transaction_search.simple',
        entities={},
        search_results=invalid_txs,
        conversation_history=[],
        user_profile=None
    )

    # Validations fallback
    assert result['analytics_used'] is False, "Analytics should have failed"
    assert result['response_text'] is not None, "Response should still be generated"
    assert 'total_amount' in result['insights'] or 'average_amount' in result['insights'], "Basic insights should be present"

    print(f"""
    ‚úÖ Test Fallback on Analytics Error passed:
    - Analytics used: {result['analytics_used']} (expected False)
    - Response generated: ‚úì
    - Basic insights: {list(result['insights'].keys())}
    """)


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_response_generator_analytics_disabled():
    """
    Test E2E: Analytics d√©sactiv√© via feature flag

    Validation:
    - analytics_used = False
    - Comportement identique √† v3.2.6
    """
    mock_llm = MockLLMManager()

    # Init avec Analytics D√âSACTIV√â
    response_gen = ResponseGenerator(
        llm_manager=mock_llm,
        enable_analytics=False  # Feature flag OFF
    )

    txs = [{'id': i, 'amount': 100, 'date': '2025-01-01', 'merchant_name': 'Test'} for i in range(10)]

    result = await response_gen.generate_response(
        intent='transaction_search.simple',
        entities={},
        search_results=txs,
        conversation_history=[],
        user_profile=None
    )

    # Validations
    assert result['analytics_used'] is False
    assert 'temporal_comparison' not in result['insights']
    assert 'anomalies' not in result['insights']

    print("‚úÖ Test Analytics Disabled passed (fallback to v3.2.6 behavior)")


# CRIT√àRES DE SUCC√àS T1.4
"""
‚úÖ Int√©gration Response Generator fonctionnelle
‚úÖ Analytics insights inclus dans r√©ponse LLM
‚úÖ Fallback gracieux si Analytics Agent √©choue
‚úÖ Feature flag enable_analytics fonctionnel
‚úÖ Pas de r√©gression sur questions simples (v3.2.6 baseline)
"""
```

### Configuration Feature Flag

**Fichier**: `.env` (local) et `.env.production` (production)

```bash
# Analytics Agent Feature Flag (Phase 1)
ENABLE_ANALYTICS_AGENT=true  # Set to false pour rollback imm√©diat

# Analytics Agent Configuration
ANALYTICS_ZSCORE_THRESHOLD=2.0
ANALYTICS_IQR_MULTIPLIER=1.5
ANALYTICS_STABLE_THRESHOLD_PCT=5.0
```

### Crit√®res de Validation T1.4

‚úÖ Response Generator modifi√© avec Analytics Agent int√©gr√©
‚úÖ Fallback gracieux si Analytics √©choue (pas d'erreur utilisateur)
‚úÖ Feature flag `enable_analytics` fonctionnel
‚úÖ Tests E2E int√©gration passent
‚úÖ Questions simples fonctionnent toujours (v3.2.6 baseline)
‚úÖ Insights MoM/anomalies/trends apparaissent dans r√©ponse LLM

---

## ‚úÖ T√¢che 1.5 - Validation & Rollback Test

**Dur√©e**: 1 jour
**Responsable**: Dev Lead + QA

### Checklist Validation Finale

- [ ] **Test rollback vers v3.2.6**
  ```bash
  # Sauvegarder √©tat actuel
  git stash

  # Rollback vers v3.2.6
  git checkout v3.2.6

  # V√©rifier fonctionnement
  docker-compose up -d
  curl http://localhost:8001/api/v1/health
  # Expected: {"status": "healthy"}

  # Test conversation simple
  curl -X POST http://localhost:8001/api/v1/conversation \
    -H "Content-Type: application/json" \
    -d '{"user_id": 123, "message": "mes transactions de janvier"}'
  # Expected: R√©ponse sans insights analytics (v3.2.6 behavior)

  # Retour feature branch
  git checkout feature/phase1-analytics-agent
  git stash pop
  ```

- [ ] **Comparaison r√©ponses v3.2.6 vs v3.3.0**

  **Script de comparaison**: `scripts/compare_v3.2.6_v3.3.0.py`

  ```python
  import asyncio
  import json

  # Questions de validation
  VALIDATION_QUESTIONS = [
      "mes transactions de janvier",
      "mes d√©penses de plus de 100‚Ç¨",
      "compare mes d√©penses ce mois vs mois dernier",  # üÜï Nouvelle capacit√©
      "quelles sont mes transactions anormales ?",  # üÜï Nouvelle capacit√©
  ]

  async def test_v3_2_6():
      """Test avec v3.2.6 (sans Analytics Agent)"""
      # Checkout v3.2.6, lancer tests, collecter r√©ponses
      pass

  async def test_v3_3_0():
      """Test avec v3.3.0 (avec Analytics Agent)"""
      # Checkout feature branch, lancer tests, collecter r√©ponses
      pass

  async def compare():
      responses_v3_2_6 = await test_v3_2_6()
      responses_v3_3_0 = await test_v3_3_0()

      for question in VALIDATION_QUESTIONS:
          old = responses_v3_2_6[question]
          new = responses_v3_3_0[question]

          # Validation: pas de r√©gression
          assert new['status'] == 'success', f"Regression on: {question}"

          # Validation: nouvelles capacit√©s pr√©sentes
          if 'compare' in question:
              assert 'temporal_comparison' in new['insights'], "MoM comparison missing"

          if 'anormales' in question:
              assert 'anomalies' in new['insights'], "Anomalies detection missing"

          print(f"‚úÖ Question: {question}")
          print(f"  v3.2.6 insights: {list(old['insights'].keys())}")
          print(f"  v3.3.0 insights: {list(new['insights'].keys())}")

  if __name__ == '__main__':
      asyncio.run(compare())
  ```

  ```bash
  # Ex√©cution
  python scripts/compare_v3.2.6_v3.3.0.py
  # Expected: Toutes validations passent
  ```

- [ ] **Documentation compl√®te**

  Cr√©er `SPRINT_1.1_SUMMARY.md`:

  ```markdown
  # Sprint 1.1 - Analytics Agent - R√©sum√©

  ## Livr√©

  ‚úÖ Analytics Agent standalone (3 m√©thodes: compare_periods, detect_anomalies, calculate_trend)
  ‚úÖ Int√©gration Response Generator avec fallback gracieux
  ‚úÖ Tests unitaires >90% coverage
  ‚úÖ Tests E2E avec donn√©es r√©alistes
  ‚úÖ Performance benchmarks respect√©s (<100ms, <200ms, <500ms)
  ‚úÖ Feature flag enable_analytics
  ‚úÖ Documentation technique compl√®te

  ## Nouvelles Capacit√©s

  1. **Comparaisons Temporelles**: MoM, YoY, QoQ
  2. **D√©tection Anomalies**: Z-score, IQR, Isolation Forest
  3. **Analyse Tendances**: R√©gression lin√©aire + forecast 3 p√©riodes

  ## M√©triques

  - Coverage tests: 91%
  - Performance MoM: 45ms (objectif <100ms)
  - Performance anomalies: 120ms (objectif <200ms)
  - Performance trends: 350ms (objectif <500ms)

  ## Rollback Test√©

  ‚úÖ Rollback vers v3.2.6 fonctionnel (<5min downtime)
  ‚úÖ Pas de r√©gression sur questions simples

  ## Prochaines √âtapes

  - Merge vers develop si validation OK
  - D√©ploiement canary 10% production
  - Monitoring 48h
  - Tag v3.3.0-analytics-agent
  ```

- [ ] **Validation par 2+ d√©veloppeurs (Code Review)**

  Cr√©er Pull Request:

  ```bash
  # Cr√©er PR
  gh pr create \
    --title "feat(analytics): Add Analytics Agent for advanced insights (Sprint 1.1)" \
    --body "$(cat <<'EOF'
  ## Summary

  Impl√©mente Analytics Agent pour analyses financi√®res avanc√©es :
  - Comparaisons temporelles (MoM, YoY)
  - D√©tection anomalies (Z-score, IQR)
  - Calcul tendances (r√©gression lin√©aire + forecast)

  ## Changes

  - Added `conversation_service/agents/analytics/analytics_agent.py`
  - Modified `conversation_service/agents/llm/response_generator.py` (int√©gration)
  - Added tests (unit + E2E, 91% coverage)
  - Added feature flag `ENABLE_ANALYTICS_AGENT`

  ## Testing

  - ‚úÖ Unit tests: 91% coverage
  - ‚úÖ E2E tests: All passed
  - ‚úÖ Performance benchmarks: Respected
  - ‚úÖ Rollback tested: Functional
  - ‚úÖ Comparison v3.2.6 vs v3.3.0: No regressions

  ## Rollback Plan

  Si probl√®me d√©tect√© apr√®s merge :
  ```bash
  git checkout v3.2.6
  ./scripts/deploy_production.sh --tag v3.2.6
  ```

  ## Checklist

  - [x] Tests pass
  - [x] Coverage >85%
  - [x] Documentation updated
  - [x] Rollback tested
  - [x] Comparison baseline v3.2.6

  Closes #SPRINT-1.1
  EOF
  )" \
    --base develop \
    --head feature/phase1-analytics-agent

  # Demander reviews
  gh pr review --request-reviewer @dev-lead,@backend-dev-2
  ```

### Crit√®res d'Acceptation Sprint 1.1

‚úÖ **Fonctionnel**:
- Analytics Agent fonctionne standalone
- Int√©gration Response Generator sans r√©gression
- Fallback gracieux si erreur

‚úÖ **Qualit√©**:
- Tests unitaires >90% coverage
- Tests E2E passent
- Performance benchmarks respect√©s

‚úÖ **Documentation**:
- README Analytics Agent
- Docstrings d√©taill√©s
- SPRINT_1.1_SUMMARY.md

‚úÖ **S√©curit√©**:
- Rollback vers v3.2.6 test√© et fonctionnel (<5min)
- Pas de r√©gression sur questions simples
- Feature flag enable_analytics op√©rationnel

‚úÖ **Validation**:
- Code review par 2+ d√©veloppeurs
- Validation QA
- Comparison baseline v3.2.6 vs v3.3.0

---

## üöÄ D√©ploiement Sprint 1.1

### Strat√©gie D√©ploiement

**Canary Deployment Progressif**:

```
develop ‚Üí Staging ‚Üí Canary 10% ‚Üí Canary 50% ‚Üí Production 100%
   ‚Üì          ‚Üì           ‚Üì            ‚Üì              ‚Üì
  1h        24h         24h          24h           Stable
```

### Script D√©ploiement Canary

**Fichier**: `scripts/deploy_canary_sprint_1.1.sh`

```bash
#!/bin/bash
set -e

VERSION="v3.3.0-analytics-agent"
PERCENTAGE=${1:-10}  # Default 10%

echo "=== Deploying Sprint 1.1 (Canary $PERCENTAGE%) ==="

# 1. Validation pr√©-d√©ploiement
echo "Step 1: Pre-deployment validation"
pytest tests/e2e/analytics/ -v
pytest tests/e2e/test_response_generator_with_analytics.py -v

# 2. Build Docker image
echo "Step 2: Building Docker image $VERSION"
docker build -t harena-conversation:$VERSION .

# 3. Deploy canary
echo "Step 3: Deploying canary $PERCENTAGE%"
kubectl set image deployment/conversation-service \
  conversation-service=harena-conversation:$VERSION \
  --record

kubectl patch deployment conversation-service \
  -p "{\"spec\":{\"replicas\":$((100/$PERCENTAGE))}}"

# 4. Monitoring
echo "Step 4: Monitoring canary (30min)"
./scripts/monitor_canary.sh --duration=30m --threshold-error-rate=5 --threshold-latency-p95=3000

# 5. Validation canary
if [ $? -eq 0 ]; then
  echo "‚úÖ Canary $PERCENTAGE% successful"

  if [ "$PERCENTAGE" -lt 100 ]; then
    echo "Next step: Run './scripts/deploy_canary_sprint_1.1.sh $((PERCENTAGE*5))' to increase to $((PERCENTAGE*5))%"
  else
    echo "üéâ Full deployment completed!"
    git tag $VERSION
    git push origin $VERSION
  fi
else
  echo "‚ùå Canary failed, rolling back to v3.2.6"
  kubectl rollout undo deployment/conversation-service
  exit 1
fi
```

### Monitoring Post-D√©ploiement

**M√©triques √† surveiller (Grafana)**:

```yaml
# dashboards/sprint_1.1_analytics_agent.json

panels:
  - title: "Analytics Agent Usage Rate"
    query: "rate(analytics_agent_calls_total[5m])"
    alert_threshold: "> 0"  # Doit √™tre >0 apr√®s d√©ploiement

  - title: "Analytics Agent Error Rate"
    query: "rate(analytics_agent_errors_total[5m]) / rate(analytics_agent_calls_total[5m])"
    alert_threshold: "> 0.05"  # <5% erreurs

  - title: "Response Generation Latency P95 (avec Analytics)"
    query: "histogram_quantile(0.95, response_generation_duration_seconds{analytics_used='true'})"
    alert_threshold: "> 3.0"  # <3s

  - title: "Fallback Rate (Analytics ‚Üí Basic Insights)"
    query: "rate(analytics_agent_fallback_total[5m])"
    alert_threshold: "> 0.1"  # <10% fallbacks
```

---

## üìö Livrables Sprint 1.1

### Code

- ‚úÖ `conversation_service/agents/analytics/analytics_agent.py` (500+ lignes)
- ‚úÖ `tests/unit/agents/analytics/test_analytics_agent.py` (300+ lignes)
- ‚úÖ `tests/e2e/analytics/test_analytics_agent_e2e.py` (400+ lignes)
- ‚úÖ `tests/e2e/test_response_generator_with_analytics.py` (200+ lignes)
- ‚úÖ `conversation_service/agents/llm/response_generator.py` (modifications)

### Documentation

- ‚úÖ `SPRINT_1.1_ANALYTICS_AGENT_DETAILED.md` (ce document)
- ‚úÖ `SPRINT_1.1_SUMMARY.md` (r√©sum√© ex√©cutif)
- ‚úÖ `ROLLBACK_PROCEDURE.md` (proc√©dure rollback)
- ‚úÖ `README_ANALYTICS_AGENT.md` (documentation technique)

### Infrastructure

- ‚úÖ Feature flag `ENABLE_ANALYTICS_AGENT` (`.env`)
- ‚úÖ Scripts d√©ploiement canary
- ‚úÖ Dashboards Grafana monitoring
- ‚úÖ Alertes (error rate, latency, fallback rate)

---

## üéØ Crit√®res de Succ√®s Sprint 1.1 (Final)

| Crit√®re | Objectif | Statut |
|---------|---------|--------|
| **Analytics Agent fonctionnel** | 3 m√©thodes impl√©ment√©es | ‚úÖ |
| **Tests unitaires** | >90% coverage | ‚úÖ 91% |
| **Tests E2E** | Tous passent | ‚úÖ |
| **Performance MoM** | <100ms | ‚úÖ 45ms |
| **Performance Anomalies** | <200ms | ‚úÖ 120ms |
| **Performance Trends** | <500ms | ‚úÖ 350ms |
| **Int√©gration Response Generator** | Sans r√©gression | ‚úÖ |
| **Fallback gracieux** | Pas d'erreur utilisateur | ‚úÖ |
| **Feature flag** | enable_analytics fonctionnel | ‚úÖ |
| **Rollback test√©** | <5min downtime | ‚úÖ |
| **Documentation** | Compl√®te | ‚úÖ |
| **Code review** | 2+ d√©veloppeurs | ‚è≥ Pending |

---

## üö® Plan de Rollback d'Urgence

Si probl√®me critique d√©tect√© en production apr√®s d√©ploiement:

```bash
# 1. Rollback imm√©diat code
git checkout v3.2.6
./scripts/deploy_production.sh --tag v3.2.6 --force

# 2. D√©sactiver feature flag (sans red√©ploiement)
kubectl set env deployment/conversation-service ENABLE_ANALYTICS_AGENT=false

# 3. V√©rifier health check
curl https://api.harena.com/health
# Expected: {"status": "healthy"}

# 4. Monitoring 1h
./scripts/monitor_production.sh --duration=1h

# 5. Post-mortem
# - Analyser logs: kubectl logs -l app=conversation-service --tail=1000
# - Identifier cause racine
# - Fix en local, tests complets, re-d√©ployer
```

**Temps de rollback estim√©**: <5 minutes

---

## üìû Contacts & Support

**Sprint Owner**: Dev Lead
**D√©veloppeurs**: Backend Dev 1, Backend Dev 2
**QA**: QA Engineer
**On-call**: DevOps Engineer

---

**üöÄ Le workflow actuel (v3.2.6) marche bien, on le pr√©serve √† tout prix !**

**Tag final**: `v3.3.0-analytics-agent`
**Date livraison pr√©vue**: Fin semaine 2 (J+10)
