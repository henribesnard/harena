"""
üåê Routes API - Endpoints de D√©tection d'Intention

Routes FastAPI pour l'API de d√©tection d'intention avec tous les endpoints
n√©cessaires : d√©tection, m√©triques, sant√©, batch processing.
"""

import time
import logging
from typing import Dict, Any
from fastapi import APIRouter, Depends, HTTPException, Query, Request
from fastapi.responses import PlainTextResponse, JSONResponse
from conversation_service.models.intent import (
    IntentRequest, IntentResponse, BatchIntentRequest, BatchIntentResponse,
    HealthResponse, MetricsResponse, ErrorResponse
)
from conversation_service.models.exceptions import IntentDetectionError, ValidationError
from conversation_service.services.intent_detection.detector import OptimizedIntentService
from conversation_service.clients.cache.memory_cache import IntelligentMemoryCache
from conversation_service.utils.monitoring.intent_metrics import IntentMetricsCollector, record_intent_request
from conversation_service.api.dependencies import (
    get_intent_service, get_cache_manager, get_metrics_manager,
    get_user_context, public_endpoint_validator, admin_endpoint_validator,
    get_configuration
)

logger = logging.getLogger(__name__)

# Cr√©ation du router
router = APIRouter(prefix="/api/v1", tags=["intent-detection"])


def create_error_response(
    error_type: str,
    message: str,
    details: Dict[str, Any] = None,
    request_id: str = None
) -> ErrorResponse:
    """
    Cr√©e une r√©ponse d'erreur structur√©e
    
    Args:
        error_type: Type d'erreur
        message: Message d'erreur
        details: D√©tails techniques optionnels
        request_id: ID de la requ√™te
        
    Returns:
        ErrorResponse structur√©e
    """
    return ErrorResponse(  # ‚úÖ UTILIS√â
        error=error_type,
        message=message,
        details=details or {},
        timestamp=time.time(),
        request_id=request_id
    )


@router.post("/detect-intent", response_model=IntentResponse)
async def detect_intent_endpoint(
    request: IntentRequest,
    http_request: Request,
    intent_service: OptimizedIntentService = Depends(get_intent_service),
    user_context: Dict[str, Any] = Depends(get_user_context),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager),  # ‚úÖ UTILIS√â
    validation: Dict[str, Any] = Depends(public_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üéØ Endpoint principal : D√©tection d'intention
    
    D√©tecte l'intention d'une requ√™te utilisateur avec extraction d'entit√©s
    et suggestions contextuelles.
    
    - **query**: Texte utilisateur √† analyser (1-500 caract√®res)
    - **user_id**: Identifiant utilisateur optionnel pour analytics
    - **use_deepseek_fallback**: Autoriser fallback DeepSeek si r√®gles insuffisantes
    - **force_method**: Forcer utilisation m√©thode sp√©cifique (debug)
    - **enable_cache**: Utiliser cache si disponible
    
    Returns:
        IntentResponse avec intention, confiance, entit√©s et suggestions
    """
    start_time = time.time()
    request_id = validation.get("request_id", f"req_{int(time.time())}")  # ‚úÖ UTILIS√â
    
    try:
        # Validation des donn√©es d'entr√©e
        if not validation.get("is_valid", True):  # ‚úÖ UTILIS√â
            error_response = create_error_response(
                "VALIDATION_ERROR",
                "Validation de la requ√™te √©chou√©e",
                details=validation.get("errors", {}),
                request_id=request_id
            )
            return JSONResponse(
                status_code=400,
                content=error_response.dict()
            )
        
        # Ajout contexte utilisateur √† la requ√™te
        if user_context.get("user_id") and not request.user_id:
            request.user_id = user_context["user_id"]
        
        # D√©tection d'intention
        result = await intent_service.detect_intent(request)
        
        # Cr√©ation r√©ponse
        response = IntentResponse(**result)
        
        # Enregistrement m√©triques avec collecteur  # ‚úÖ UTILIS√â
        await metrics_collector.record_request(
            query=request.query,
            intent=response.intent,
            confidence=response.confidence,
            processing_time_ms=response.processing_time_ms,
            method_used=response.method_used,
            user_id=str(request.user_id) if request.user_id else None,
            request_id=request_id,
            cached=response.cached,
            entities_count=len(response.entities)
        )
        
        # Enregistrement m√©triques legacy (background)
        record_intent_request(
            query=request.query,
            result=result,
            user_id=str(request.user_id) if request.user_id else None
        )
        
        # Logging pour audit avec validation info  # ‚úÖ UTILIS√â
        logger.info(
            f"Intent detected: {response.intent} "
            f"(confidence: {response.confidence:.3f}, "
            f"method: {response.method_used}, "
            f"time: {response.processing_time_ms:.1f}ms) "
            f"for user {user_context.get('user_id', 'anonymous')} "
            f"[req_id: {request_id}, validation: {validation.get('validation_time_ms', 0):.1f}ms]"
        )
        
        return response
        
    except ValidationError as e:
        logger.warning(f"Validation error: {e}")
        
        # M√©triques d'erreur  # ‚úÖ UTILIS√â
        await metrics_collector.record_error(
            error_type="validation_error",
            query=request.query,
            user_id=str(request.user_id) if request.user_id else None,
            request_id=request_id
        )
        
        error_response = create_error_response(
            "VALIDATION_ERROR",
            str(e),
            details={"field": getattr(e, 'field_name', None)},
            request_id=request_id
        )
        
        return JSONResponse(
            status_code=400,
            content=error_response.dict()
        )
    
    except IntentDetectionError as e:
        logger.error(f"Intent detection error: {e}")
        
        # M√©triques d'erreur  # ‚úÖ UTILIS√â
        await metrics_collector.record_error(
            error_type="intent_detection_error",
            query=request.query,
            user_id=str(request.user_id) if request.user_id else None,
            request_id=request_id,
            error_details={"attempted_methods": getattr(e, 'attempted_methods', [])}
        )
        
        error_response = create_error_response(
            "INTENT_DETECTION_ERROR",
            str(e),
            details={
                "query_truncated": request.query[:50] + "..." if len(request.query) > 50 else request.query,
                "attempted_methods": getattr(e, 'attempted_methods', [])
            },
            request_id=request_id
        )
        
        return JSONResponse(
            status_code=422,
            content=error_response.dict()
        )
    
    except Exception as e:
        logger.error(f"Unexpected error in intent detection: {e}")
        
        # M√©triques d'erreur syst√®me  # ‚úÖ UTILIS√â
        await metrics_collector.record_error(
            error_type="system_error",
            query=request.query,
            user_id=str(request.user_id) if request.user_id else None,
            request_id=request_id,
            error_details={"exception_type": type(e).__name__}
        )
        
        error_response = create_error_response(
            "INTERNAL_SERVER_ERROR",
            "Une erreur inattendue s'est produite",
            details={"exception_type": type(e).__name__},
            request_id=request_id
        )
        
        return JSONResponse(
            status_code=500,
            content=error_response.dict()
        )


@router.post("/batch-detect", response_model=BatchIntentResponse)
async def batch_detect_intent_endpoint(
    request: BatchIntentRequest,
    http_request: Request,
    intent_service: OptimizedIntentService = Depends(get_intent_service),
    user_context: Dict[str, Any] = Depends(get_user_context),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager),  # ‚úÖ UTILIS√â
    validation: Dict[str, Any] = Depends(public_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üì¶ Endpoint batch : D√©tection d'intention multiple
    
    Traite plusieurs requ√™tes en parall√®le pour optimiser le d√©bit.
    Maximum 100 requ√™tes par batch.
    
    - **queries**: Liste des textes √† analyser
    - **user_id**: Identifiant utilisateur pour toutes les requ√™tes
    - **use_deepseek_fallback**: Autoriser fallback DeepSeek
    - **parallel_processing**: Traitement parall√®le (recommand√©)
    
    Returns:
        BatchIntentResponse avec r√©sultats et m√©triques batch
    """
    start_time = time.time()
    request_id = validation.get("request_id", f"batch_{int(time.time())}")  # ‚úÖ UTILIS√â
    
    try:
        # Validation sp√©cifique batch  # ‚úÖ UTILIS√â
        if not validation.get("is_valid", True):
            error_response = create_error_response(
                "BATCH_VALIDATION_ERROR",
                "Validation du batch √©chou√©e",
                details={
                    "errors": validation.get("errors", {}),
                    "batch_size": len(request.queries) if request.queries else 0
                },
                request_id=request_id
            )
            return JSONResponse(
                status_code=400,
                content=error_response.dict()
            )
        
        # Validation taille batch
        if len(request.queries) > 100:
            error_response = create_error_response(
                "BATCH_TOO_LARGE",
                "Maximum 100 requ√™tes par batch",
                details={"received": len(request.queries), "maximum": 100},
                request_id=request_id
            )
            return JSONResponse(
                status_code=400,
                content=error_response.dict()
            )
        
        logger.info(f"Starting batch processing: {len(request.queries)} queries [req_id: {request_id}]")
        
        # Enregistrement d√©but batch  # ‚úÖ UTILIS√â
        await metrics_collector.record_batch_start(
            batch_size=len(request.queries),
            user_id=str(request.user_id) if request.user_id else user_context.get("user_id"),
            request_id=request_id
        )
        
        # Traitement batch
        results = await intent_service.batch_detect_intent(
            queries=request.queries,
            user_id=str(request.user_id) if request.user_id else user_context.get("user_id"),
            use_deepseek_fallback=request.use_deepseek_fallback
        )
        
        # Conversion en IntentResponse objects
        intent_responses = []
        successful_requests = 0
        failed_requests = 0
        
        for result in results:
            try:
                if "error" not in result:
                    intent_responses.append(IntentResponse(**result))
                    successful_requests += 1
                else:
                    # Cr√©er r√©ponse d'erreur
                    error_response_item = IntentResponse(
                        intent="UNKNOWN",
                        intent_code="UNKNOWN", 
                        confidence=0.0,
                        processing_time_ms=0.0,
                        method_used="error",
                        query=result.get("query", ""),
                        entities={},
                        suggestions=[],
                        cost_estimate=0.0
                    )
                    intent_responses.append(error_response_item)
                    failed_requests += 1
            except Exception as e:
                logger.warning(f"Error creating response for batch item: {e}")
                failed_requests += 1
        
        total_processing_time = (time.time() - start_time) * 1000
        
        # M√©triques batch
        batch_metrics = {
            "total_queries": len(request.queries),
            "avg_processing_time_ms": round(
                sum(r.processing_time_ms for r in intent_responses) / len(intent_responses), 2
            ) if intent_responses else 0,
            "total_cost": sum(r.cost_estimate for r in intent_responses),
            "method_distribution": {},
            "intent_distribution": {},
            "validation_time_ms": validation.get("validation_time_ms", 0)  # ‚úÖ UTILIS√â
        }
        
        # Distribution m√©thodes et intentions
        for response in intent_responses:
            method = response.method_used
            batch_metrics["method_distribution"][method] = batch_metrics["method_distribution"].get(method, 0) + 1
            
            intent = response.intent
            batch_metrics["intent_distribution"][intent] = batch_metrics["intent_distribution"].get(intent, 0) + 1
        
        # Enregistrement fin batch  # ‚úÖ UTILIS√â
        await metrics_collector.record_batch_completion(
            batch_size=len(request.queries),
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            total_processing_time_ms=total_processing_time,
            request_id=request_id
        )
        
        # R√©ponse batch
        batch_response = BatchIntentResponse(
            results=intent_responses,
            batch_metrics=batch_metrics,
            total_processing_time_ms=total_processing_time,
            successful_requests=successful_requests,
            failed_requests=failed_requests
        )
        
        logger.info(
            f"Batch completed: {successful_requests}/{len(request.queries)} successful "
            f"in {total_processing_time:.1f}ms [req_id: {request_id}]"
        )
        
        return batch_response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Batch processing error: {e}")
        
        # M√©triques d'erreur batch  # ‚úÖ UTILIS√â
        await metrics_collector.record_error(
            error_type="batch_processing_error",
            user_id=str(request.user_id) if request.user_id else user_context.get("user_id"),
            request_id=request_id,
            error_details={
                "batch_size": len(request.queries) if request.queries else 0,
                "exception_type": type(e).__name__
            }
        )
        
        error_response = create_error_response(
            "BATCH_PROCESSING_ERROR",
            str(e),
            details={
                "batch_size": len(request.queries) if request.queries else 0,
                "exception_type": type(e).__name__
            },
            request_id=request_id
        )
        
        return JSONResponse(
            status_code=500,
            content=error_response.dict()
        )


@router.get("/health", response_model=HealthResponse)
async def health_check_endpoint(
    intent_service: OptimizedIntentService = Depends(get_intent_service),
    cache_manager: IntelligentMemoryCache = Depends(get_cache_manager),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager)  # ‚úÖ UTILIS√â
):
    """
    üè• Endpoint sant√© : V√©rification √©tat du service
    
    V√©rifie l'√©tat de tous les composants du service et retourne
    les m√©triques de base pour monitoring.
    
    Returns:
        HealthResponse avec statut et m√©triques essentielles
    """
    try:
        # V√©rification sant√© compl√®te
        health_status = await intent_service.health_check()
        
        # M√©triques de base
        service_metrics = intent_service.get_metrics()
        cache_stats = cache_manager.get_stats()
        
        # M√©triques collecteur  # ‚úÖ UTILIS√â
        collector_stats = await metrics_collector.get_health_metrics()
        
        # Construction r√©ponse sant√©
        response = HealthResponse(
            status=health_status["status"],
            service_name="conversation-service",
            version="2.0.0",
            timestamp=time.time(),
            
            # Statuts composants
            rule_engine_status=health_status["components"]["rule_engine"],
            deepseek_client_status=health_status["components"]["deepseek_client"],
            cache_status=health_status["components"]["cache"],
            
            # M√©triques de base avec collecteur
            total_requests=max(
                service_metrics.get("total_requests", 0),
                collector_stats.get("total_requests", 0)
            ),
            average_latency_ms=service_metrics.get("avg_latency_ms", 0.0),
            cache_hit_rate=cache_stats["cache_performance"]["hit_rate"],
            
            # Configuration
            deepseek_fallback_enabled=health_status["configuration"]["deepseek_enabled"],
            cache_enabled=health_status["configuration"]["cache_enabled"]
        )
        
        # Log statut sant√© avec m√©triques collecteur  # ‚úÖ UTILIS√â
        if health_status["status"] != "healthy":
            logger.warning(
                f"Service health status: {health_status['status']} "
                f"(collector metrics: {collector_stats.get('status', 'unknown')})"
            )
        
        return response
        
    except Exception as e:
        logger.error(f"Health check error: {e}")
        
        # R√©ponse d'erreur minimale
        return HealthResponse(
            status="error",
            service_name="conversation-service",
            version="2.0.0",
            timestamp=time.time(),
            rule_engine_status="unknown",
            deepseek_client_status="unknown",
            cache_status="unknown"
        )


@router.get("/metrics", response_model=MetricsResponse)
async def metrics_endpoint(
    detailed: bool = Query(False, description="Inclure m√©triques d√©taill√©es"),
    intent_service: OptimizedIntentService = Depends(get_intent_service),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager),  # ‚úÖ UTILIS√â
    validation: Dict[str, Any] = Depends(admin_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üìä Endpoint m√©triques : Analytics et performance
    
    Retourne m√©triques compl√®tes du service pour monitoring
    et optimisation des performances.
    
    - **detailed**: Inclure analytics d√©taill√©es (admin seulement)
    
    Returns:
        MetricsResponse avec m√©triques compl√®tes ou basiques
    """
    try:
        # V√©rification permissions admin  # ‚úÖ UTILIS√â
        if detailed and not validation.get("is_admin", False):
            error_response = create_error_response(
                "INSUFFICIENT_PERMISSIONS",
                "M√©triques d√©taill√©es r√©serv√©es aux administrateurs",
                details={"required_role": "admin", "current_role": validation.get("user_role", "user")},
                request_id=validation.get("request_id")
            )
            return JSONResponse(
                status_code=403,
                content=error_response.dict()
            )
        
        # M√©triques service principal
        service_metrics = intent_service.get_metrics()
        
        if detailed:
            # M√©triques d√©taill√©es (admin)  # ‚úÖ UTILIS√â
            comprehensive_report = await metrics_collector.get_comprehensive_report()
            
            response = MetricsResponse(
                **service_metrics,
                **comprehensive_report.get("historical_analysis", {}),
                component_metrics=service_metrics.get("component_metrics", {}),
                detailed_analytics={
                    "intent_analytics": comprehensive_report.get("intent_analytics", {}),
                    "method_analytics": comprehensive_report.get("method_analytics", {}),
                    "user_analytics": comprehensive_report.get("user_analytics", {}),
                    "real_time_performance": comprehensive_report.get("real_time_performance", {}),
                    "admin_access_time": time.time(),
                    "access_validated_by": validation.get("validator_id", "unknown")
                }
            )
        else:
            # M√©triques basiques (public) avec donn√©es collecteur  # ‚úÖ UTILIS√â
            basic_collector_metrics = await metrics_collector.get_basic_metrics()
            
            response = MetricsResponse(
                **service_metrics,
                collector_metrics=basic_collector_metrics
            )
        
        return response
        
    except Exception as e:
        logger.error(f"Metrics endpoint error: {e}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Metrics unavailable",
                "message": "Impossible de r√©cup√©rer les m√©triques"
            }
        )


@router.get("/supported-intents")
async def supported_intents_endpoint(
    config_data: Dict[str, Any] = Depends(get_configuration),
    validation: Dict[str, Any] = Depends(public_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üìã Endpoint intentions : Liste des intentions support√©es
    
    Retourne la liste compl√®te des intentions financi√®res support√©es
    avec leurs m√©tadonn√©es.
    
    Returns:
        Dict avec intentions support√©es et configuration
    """
    from ...config import get_supported_intents
    
    supported_intents = get_supported_intents()
    
    return {
        "supported_intents": list(supported_intents.keys()),
        "intent_details": supported_intents,
        "total_intents": len(supported_intents),
        "categories": {
            "financial": [
                "ACCOUNT_BALANCE", "SEARCH_BY_CATEGORY", "BUDGET_ANALYSIS",
                "TRANSFER", "SEARCH_BY_DATE", "CARD_MANAGEMENT"
            ],
            "conversational": ["GREETING", "HELP", "GOODBYE"],
            "fallback": ["UNKNOWN"]
        },
        "service_info": {
            "version": config_data["version"],
            "deepseek_enabled": config_data["deepseek_enabled"],
            "request_validated": validation.get("is_valid", False),  # ‚úÖ UTILIS√â
            "validation_time_ms": validation.get("validation_time_ms", 0)  # ‚úÖ UTILIS√â
        }
    }


@router.post("/cache/clear")
async def clear_cache_endpoint(
    cache_manager: IntelligentMemoryCache = Depends(get_cache_manager),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager),  # ‚úÖ UTILIS√â
    validation: Dict[str, Any] = Depends(admin_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üóëÔ∏è Endpoint admin : Vider le cache
    
    Vide compl√®tement le cache m√©moire. Utile pour maintenance
    ou apr√®s mise √† jour de mod√®les.
    
    Returns:
        Statistiques de nettoyage
    """
    try:
        # V√©rification permissions  # ‚úÖ UTILIS√â
        if not validation.get("is_admin", False):
            error_response = create_error_response(
                "INSUFFICIENT_PERMISSIONS",
                "Op√©ration r√©serv√©e aux administrateurs",
                details={"required_role": "admin"},
                request_id=validation.get("request_id")
            )
            return JSONResponse(
                status_code=403,
                content=error_response.dict()
            )
        
        entries_removed = cache_manager.clear()
        
        # Enregistrement action admin  # ‚úÖ UTILIS√â
        await metrics_collector.record_admin_action(
            action="cache_clear",
            admin_user=validation.get("user_id", "unknown"),
            details={"entries_removed": entries_removed},
            request_id=validation.get("request_id")
        )
        
        logger.info(
            f"Cache cleared by admin {validation.get('user_id', 'unknown')}: "
            f"{entries_removed} entries removed"
        )
        
        return {
            "status": "success",
            "message": "Cache vid√© avec succ√®s",
            "entries_removed": entries_removed,
            "timestamp": time.time(),
            "admin_user": validation.get("user_id", "unknown")  # ‚úÖ UTILIS√â
        }
        
    except Exception as e:
        logger.error(f"Cache clear error: {e}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Cache clear failed",
                "message": str(e)
            }
        )


@router.post("/cache/optimize")
async def optimize_cache_endpoint(
    cache_manager: IntelligentMemoryCache = Depends(get_cache_manager),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager),  # ‚úÖ UTILIS√â
    validation: Dict[str, Any] = Depends(admin_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    ‚ö° Endpoint admin : Optimiser le cache
    
    Lance l'optimisation du cache : supprime entr√©es expir√©es
    et peu utilis√©es pour am√©liorer performance.
    
    Returns:
        Statistiques d'optimisation
    """
    try:
        # V√©rification permissions  # ‚úÖ UTILIS√â
        if not validation.get("is_admin", False):
            error_response = create_error_response(
                "INSUFFICIENT_PERMISSIONS",
                "Op√©ration r√©serv√©e aux administrateurs",
                request_id=validation.get("request_id")
            )
            return JSONResponse(
                status_code=403,
                content=error_response.dict()
            )
        
        optimization_stats = cache_manager.optimize_cache()
        
        # Enregistrement action admin  # ‚úÖ UTILIS√â
        await metrics_collector.record_admin_action(
            action="cache_optimize",
            admin_user=validation.get("user_id", "unknown"),
            details=optimization_stats,
            request_id=validation.get("request_id")
        )
        
        logger.info(
            f"Cache optimized by admin {validation.get('user_id', 'unknown')}: "
            f"{optimization_stats['total_removed']} entries removed"
        )
        
        return {
            "status": "success",
            "message": "Cache optimis√© avec succ√®s",
            "optimization_stats": optimization_stats,
            "timestamp": time.time(),
            "admin_user": validation.get("user_id", "unknown")  # ‚úÖ UTILIS√â
        }
        
    except Exception as e:
        logger.error(f"Cache optimization error: {e}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Cache optimization failed",
                "message": str(e)
            }
        )


@router.get("/metrics/export", response_class=PlainTextResponse)
async def export_metrics_csv_endpoint(
    hours: int = Query(24, description="Nombre d'heures √† exporter", ge=1, le=168),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager),  # ‚úÖ UTILIS√â
    validation: Dict[str, Any] = Depends(admin_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üì§ Endpoint admin : Export m√©triques CSV
    
    Exporte les m√©triques d√©taill√©es en format CSV pour analyse
    externe ou archivage.
    
    - **hours**: Nombre d'heures d'historique √† exporter (1-168)
    
    Returns:
        CSV des m√©triques avec headers
    """
    try:
        # V√©rification permissions admin  # ‚úÖ UTILIS√â
        if not validation.get("is_admin", False):
            return PlainTextResponse(
                content="ERROR: Insufficient permissions for metrics export",
                status_code=403
            )
        
        csv_content = await metrics_collector.export_metrics_csv(hours)  # ‚úÖ UTILIS√â
        
        # Enregistrement export  # ‚úÖ UTILIS√â
        await metrics_collector.record_admin_action(
            action="metrics_export",
            admin_user=validation.get("user_id", "unknown"),
            details={"hours_exported": hours},
            request_id=validation.get("request_id")
        )
        
        logger.info(
            f"Metrics exported by admin {validation.get('user_id', 'unknown')}: "
            f"{hours}h of data"
        )
        
        return PlainTextResponse(
            content=csv_content,
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=intent_metrics_{hours}h.csv",
                "X-Exported-By": validation.get("user_id", "unknown")  # ‚úÖ UTILIS√â
            }
        )
        
    except Exception as e:
        logger.error(f"Metrics export error: {e}")
        return PlainTextResponse(
            content=f"ERROR: Metrics export failed - {str(e)}",
            status_code=500
        )


@router.post("/test-comprehensive")
async def comprehensive_test_endpoint(
    intent_service: OptimizedIntentService = Depends(get_intent_service),
    metrics_collector: IntentMetricsCollector = Depends(get_metrics_manager),  # ‚úÖ UTILIS√â
    validation: Dict[str, Any] = Depends(admin_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üß™ Endpoint test : Test complet avec m√©triques
    
    Lance une s√©rie de tests complets pour valider le fonctionnement
    du service et g√©n√©rer m√©triques de performance.
    
    Returns:
        R√©sultats de tests avec statistiques d√©taill√©es
    """
    
    # V√©rification permissions  # ‚úÖ UTILIS√â
    if not validation.get("is_admin", False):
        error_response = create_error_response(
            "INSUFFICIENT_PERMISSIONS",
            "Tests complets r√©serv√©s aux administrateurs",
            request_id=validation.get("request_id")
        )
        return JSONResponse(
            status_code=403,
            content=error_response.dict()
        )
    
    # Cases de test (reprises du fichier original)
    test_cases = [
        ("bonjour comment √ßa va", "GREETING"),
        ("quel est mon solde compte courant", "ACCOUNT_BALANCE"), 
        ("mes d√©penses restaurant ce mois", "SEARCH_BY_CATEGORY"),
        ("faire un virement de 100 euros", "TRANSFER"),
        ("au revoir merci", "GOODBYE"),
        ("mes courses chez carrefour en janvier", "SEARCH_BY_CATEGORY"),
        ("virer 250 euros √† Marie", "TRANSFER"),
        ("combien j'ai d√©pens√© en transport", "BUDGET_ANALYSIS"),
        ("bloquer ma carte visa", "CARD_MANAGEMENT"),
        ("historique des transactions de d√©cembre", "SEARCH_BY_DATE"),
        ("aide moi", "HELP"),
        ("quelque chose de tr√®s complexe et ambigu", "UNKNOWN")
    ]
    
    results = []
    start_test = time.time()
    test_id = f"test_{int(time.time())}"
    
    # Enregistrement d√©but test  # ‚úÖ UTILIS√â
    await metrics_collector.record_test_start(
        test_id=test_id,
        test_type="comprehensive",
        admin_user=validation.get("user_id", "unknown"),
        test_cases_count=len(test_cases)
    )
    
    for i, (query, expected) in enumerate(test_cases):
        request = IntentRequest(query=query, user_id="test_user")
        result = await intent_service.detect_intent(request)
        
        is_correct = result["intent"] == expected or (expected == "UNKNOWN" and result["confidence"] < 0.5)
        
        test_result = {
            "query": query,
            "expected": expected,
            "detected": result["intent"],
            "confidence": result["confidence"],
            "correct": is_correct,
            "latency_ms": result["processing_time_ms"],
            "method": result["method_used"],
            "entities": result["entities"]
        }
        results.append(test_result)
        
        # Enregistrement r√©sultat individuel  # ‚úÖ UTILIS√â
        await metrics_collector.record_test_case_result(
            test_id=test_id,
            case_index=i,
            query=query,
            expected_intent=expected,
            detected_intent=result["intent"],
            confidence=result["confidence"],
            correct=is_correct,
            processing_time_ms=result["processing_time_ms"]
        )
    
    total_test_time = (time.time() - start_test) * 1000
    
    # Statistiques (logique exacte fichier original)
    correct_count = sum(1 for r in results if r["correct"])
    accuracy = correct_count / len(results)
    avg_latency = sum(r["latency_ms"] for r in results) / len(results)
    fast_responses = sum(1 for r in results if r["latency_ms"] < 50)  # Target latency
    
    # Enregistrement fin test  # ‚úÖ UTILIS√â
    await metrics_collector.record_test_completion(
        test_id=test_id,
        total_cases=len(test_cases),
        correct_count=correct_count,
        accuracy=accuracy,
        avg_latency_ms=avg_latency,
        total_test_time_ms=total_test_time,
        admin_user=validation.get("user_id", "unknown")
    )
    
    test_response = {
        "test_results": results,
        "statistics": {
            "total_tests": len(results),
            "correct_predictions": correct_count,
            "accuracy_rate": round(accuracy, 3),
            "avg_latency_ms": round(avg_latency, 2),
            "fast_responses": fast_responses,
            "fast_response_rate": round(fast_responses / len(results), 3),
            "total_test_time_ms": round(total_test_time, 2),
            "meets_targets": {
                "latency": avg_latency <= 50,  # Target from config
                "accuracy": accuracy >= 0.85   # Target from config
            }
        },
        "service_metrics": intent_service.get_metrics(),
        "test_metadata": {
            "test_id": test_id,
            "admin_user": validation.get("user_id", "unknown"),  # ‚úÖ UTILIS√â
            "timestamp": time.time(),
            "validation_time_ms": validation.get("validation_time_ms", 0)  # ‚úÖ UTILIS√â
        }
    }
    
    logger.info(
        f"Comprehensive test completed by admin {validation.get('user_id', 'unknown')}: "
        f"{accuracy:.1%} accuracy, {avg_latency:.1f}ms avg latency [test_id: {test_id}]"
    )
    
    return test_response


# Middleware d'erreur global pour utiliser ErrorResponse
@router.middleware("http")
async def error_handling_middleware(request: Request, call_next):
    """
    Middleware de gestion d'erreurs utilisant ErrorResponse
    """
    try:
        response = await call_next(request)
        return response
    except Exception as e:
        logger.error(f"Unhandled error in {request.url.path}: {e}")
        
        error_response = create_error_response(  # ‚úÖ UTILIS√â
            "UNHANDLED_ERROR",
            "Erreur non g√©r√©e dans l'API",
            details={
                "path": str(request.url.path),
                "method": request.method,
                "exception_type": type(e).__name__
            },
            request_id=f"middleware_{int(time.time())}"
        )
        
        return JSONResponse(
            status_code=500,
            content=error_response.dict()
        )


# Endpoint de diagnostic utilisant ErrorResponse
@router.get("/debug/error-test")
async def error_test_endpoint(
    error_type: str = Query("validation", description="Type d'erreur √† tester"),
    validation: Dict[str, Any] = Depends(admin_endpoint_validator)  # ‚úÖ UTILIS√â
):
    """
    üîß Endpoint debug : Test des r√©ponses d'erreur
    
    Endpoint de test pour valider le fonctionnement des ErrorResponse.
    R√©serv√© aux administrateurs pour debugging.
    
    Args:
        error_type: Type d'erreur √† simuler
        
    Returns:
        ErrorResponse selon le type demand√©
    """
    # V√©rification permissions  # ‚úÖ UTILIS√â
    if not validation.get("is_admin", False):
        error_response = create_error_response(
            "INSUFFICIENT_PERMISSIONS",
            "Endpoint de debug r√©serv√© aux administrateurs",
            request_id=validation.get("request_id")
        )
        return JSONResponse(
            status_code=403,
            content=error_response.dict()
        )
    
    # Simulation diff√©rents types d'erreurs  # ‚úÖ UTILIS√â
    if error_type == "validation":
        error_response = create_error_response(
            "VALIDATION_ERROR",
            "Erreur de validation simul√©e",
            details={"field": "test_field", "value": "invalid_value"},
            request_id=validation.get("request_id")
        )
        return JSONResponse(status_code=400, content=error_response.dict())
    
    elif error_type == "intent_detection":
        error_response = create_error_response(
            "INTENT_DETECTION_ERROR",
            "Erreur de d√©tection d'intention simul√©e",
            details={"query": "test query", "attempted_methods": ["rules", "llm"]},
            request_id=validation.get("request_id")
        )
        return JSONResponse(status_code=422, content=error_response.dict())
    
    elif error_type == "system":
        error_response = create_error_response(
            "SYSTEM_ERROR",
            "Erreur syst√®me simul√©e",
            details={"component": "test_component", "exception_type": "TestException"},
            request_id=validation.get("request_id")
        )
        return JSONResponse(status_code=500, content=error_response.dict())
    
    else:
        error_response = create_error_response(
            "INVALID_ERROR_TYPE",
            f"Type d'erreur '{error_type}' non support√©",
            details={
                "supported_types": ["validation", "intent_detection", "system"],
                "received": error_type
            },
            request_id=validation.get("request_id")
        )
        return JSONResponse(status_code=400, content=error_response.dict())


# Export du router
__all__ = ["router"]