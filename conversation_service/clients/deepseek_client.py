"""
üöÄ Client HTTP DeepSeek optimis√© avec cache et retry

Client HTTP DeepSeek avec authentification, gestion retry automatique,
circuit breaker, cache local r√©ponses et m√©triques performance.
"""

import asyncio
import logging
import time
import hashlib
from typing import Dict, List, Optional, Any
import httpx
from httpx import AsyncClient, Timeout, RequestError, HTTPStatusError

from config_service.config import settings
from conversation_service.utils.logging import log_intent_detection

logger = logging.getLogger(__name__)

class CircuitBreaker:
    """
    üîÑ Circuit breaker pour gestion pannes DeepSeek
    
    √âtats: CLOSED (normal) ‚Üí OPEN (panne) ‚Üí HALF_OPEN (test r√©cup√©ration)
    """
    
    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        
        self.failure_count = 0
        self.last_failure_time = 0
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    def is_call_allowed(self) -> bool:
        """V√©rifie si appel autoris√© selon √©tat circuit breaker"""
        if self.state == "CLOSED":
            return True
        elif self.state == "OPEN":
            # Test si d√©lai r√©cup√©ration √©coul√©
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = "HALF_OPEN"
                return True
            return False
        elif self.state == "HALF_OPEN":
            return True
        
        return False
    
    def record_success(self):
        """Enregistre succ√®s - reset circuit breaker"""
        self.failure_count = 0
        self.state = "CLOSED"
    
    def record_failure(self):
        """Enregistre √©chec - peut ouvrir circuit"""
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            self.state = "OPEN"
            logger.warning(f"üî¥ Circuit breaker OPEN - {self.failure_count} √©checs")

class ResponseCache:
    """
    üíæ Cache local r√©ponses DeepSeek pour r√©duction co√ªts
    
    Cache LRU avec TTL adaptatif bas√© sur type requ√™te
    """
    
    def __init__(self, max_size: int = 1000, default_ttl: int = 300):
        self.max_size = max_size
        self.default_ttl = default_ttl
        
        self._cache: Dict[str, Dict[str, Any]] = {}
        self._access_times: Dict[str, float] = {}
    
    def _generate_cache_key(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """G√©n√®re cl√© cache bas√©e sur messages et param√®tres"""
        # Normalisation messages pour cache stable
        normalized_messages = []
        for msg in messages:
            normalized_messages.append({
                "role": msg.get("role", ""),
                "content": msg.get("content", "")[:500]  # Limite pour cl√©
            })
        
        # Ajout param√®tres significatifs
        cache_input = {
            "messages": normalized_messages,
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 100)
        }
        
        # Hash stable
        cache_str = str(cache_input)
        return hashlib.md5(cache_str.encode()).hexdigest()[:16]
    
    def get(self, messages: List[Dict[str, str]], **kwargs) -> Optional[Dict[str, Any]]:
        """R√©cup√©ration depuis cache si valide"""
        cache_key = self._generate_cache_key(messages, **kwargs)
        
        if cache_key not in self._cache:
            return None
        
        cache_entry = self._cache[cache_key]
        
        # V√©rification TTL
        if time.time() - cache_entry["timestamp"] > cache_entry["ttl"]:
            self._remove_key(cache_key)
            return None
        
        # Mise √† jour temps acc√®s pour LRU
        self._access_times[cache_key] = time.time()
        
        # Retour r√©ponse cached avec marqueur
        cached_response = cache_entry["response"].copy()
        cached_response["cached"] = True
        cached_response["cache_age_seconds"] = int(time.time() - cache_entry["timestamp"])
        
        return cached_response
    
    def set(self, messages: List[Dict[str, str]], response: Dict[str, Any], ttl: Optional[int] = None, **kwargs):
        """Mise en cache r√©ponse avec TTL"""
        cache_key = self._generate_cache_key(messages, **kwargs)
        
        # √âviction LRU si cache plein
        if len(self._cache) >= self.max_size:
            self._evict_lru()
        
        # Stockage avec m√©tadonn√©es
        self._cache[cache_key] = {
            "response": response.copy(),
            "timestamp": time.time(),
            "ttl": ttl or self.default_ttl
        }
        self._access_times[cache_key] = time.time()
    
    def _evict_lru(self):
        """√âviction LRU - supprime 25% des plus anciennes entr√©es"""
        if not self._access_times:
            return
        
        # Tri par temps d'acc√®s
        sorted_keys = sorted(self._access_times.keys(), key=lambda k: self._access_times[k])
        
        # Supprime 25% des plus anciennes
        evict_count = max(1, len(sorted_keys) // 4)
        
        for i in range(evict_count):
            key_to_remove = sorted_keys[i]
            self._remove_key(key_to_remove)
    
    def _remove_key(self, key: str):
        """Suppression propre cl√© cache"""
        self._cache.pop(key, None)
        self._access_times.pop(key, None)
    
    def clear(self):
        """Vidage complet cache"""
        self._cache.clear()
        self._access_times.clear()
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistiques cache"""
        return {
            "size": len(self._cache),
            "max_size": self.max_size,
            "usage_percent": (len(self._cache) / self.max_size) * 100,
            "default_ttl": self.default_ttl
        }

class DeepSeekClient:
    """
    üöÄ Client principal DeepSeek API optimis√©
    
    Fonctionnalit√©s:
    - Authentification API Key
    - Retry automatique avec backoff exponentiel
    - Circuit breaker pour gestion pannes
    - Cache local r√©ponses (r√©duction co√ªts 90%)
    - M√©triques performance et co√ªts
    - Timeout adaptatif par type requ√™te
    """
    
    def __init__(self):
        self.config = settings.get_deepseek_config("default")
        
        # Client HTTP avec configuration optimis√©e
        self.client: Optional[AsyncClient] = None
        
        # Composants avanc√©s
        self.circuit_breaker = CircuitBreaker(
            failure_threshold=settings.CIRCUIT_BREAKER_FAILURE_THRESHOLD,
            recovery_timeout=settings.CIRCUIT_BREAKER_RECOVERY_TIMEOUT
        )
        self.response_cache = ResponseCache(max_size=1000, default_ttl=900)  # 15min
        
        # M√©triques performance
        self._total_requests = 0
        self._successful_requests = 0
        self._cached_requests = 0
        self._total_tokens = 0
        self._total_latency = 0.0
        self._cost_estimate = 0.0
        
        # Configuration retry
        self.max_retries = settings.MAX_RETRIES
        self.retry_delay = settings.RETRY_DELAY
        
        logger.info("üöÄ DeepSeek Client initialis√©")
    
    async def initialize(self):
        """Initialisation client avec validation API Key"""
        try:
            logger.info("üîß Initialisation DeepSeek Client...")
            
            # Validation configuration
            if not self.config["api_key"]:
                raise ValueError("DEEPSEEK_API_KEY manquant")
            
            if not self.config["base_url"]:
                raise ValueError("DEEPSEEK_BASE_URL manquant")
            
            # Configuration client HTTP optimis√©e
            timeout_config = Timeout(
                connect=10.0,
                read=self.config["timeout"],
                write=10.0,
                pool=30.0
            )
            
            self.client = AsyncClient(
                base_url=self.config["base_url"],
                headers={
                    "Authorization": f"Bearer {self.config['api_key']}",
                    "Content-Type": "application/json",
                    "User-Agent": "ConversationService/1.0"
                },
                timeout=timeout_config,
                limits=httpx.Limits(
                    max_keepalive_connections=5,
                    max_connections=10,
                    keepalive_expiry=30.0
                )
            )
            
            # Test connexion API
            test_success = await self._test_api_connection()
            if not test_success:
                raise Exception("Test connexion API DeepSeek √©chou√©")
            
            logger.info("‚úÖ DeepSeek Client initialis√© avec succ√®s")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation DeepSeek Client: {e}")
            if self.client:
                await self.client.aclose()
                self.client = None
            raise
    
    async def chat_completion(
        self,
        messages: List[Dict[str, str]],
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        top_p: Optional[float] = None,
        timeout: Optional[int] = None,
        use_cache: bool = True
    ) -> Optional[Dict[str, Any]]:
        """
        Appel chat completion DeepSeek avec optimisations
        
        Args:
            messages: Messages conversation format OpenAI
            max_tokens: Limite tokens r√©ponse
            temperature: Cr√©ativit√© (0.0-1.0)
            top_p: Nucleus sampling
            timeout: Timeout sp√©cifique
            use_cache: Utilisation cache
            
        Returns:
            Dict contenant r√©ponse + m√©tadonn√©es ou None si erreur
        """
        if not self.client:
            logger.error("‚ùå DeepSeek Client non initialis√©")
            return None
        
        # V√©rification circuit breaker
        if not self.circuit_breaker.is_call_allowed():
            logger.warning("üî¥ Circuit breaker OPEN - Appel bloqu√©")
            return None
        
        self._total_requests += 1
        start_time = time.time()
        
        # Param√®tres avec fallbacks depuis config
        params = {
            "max_tokens": max_tokens or self.config["max_tokens"],
            "temperature": temperature or self.config["temperature"],
            "top_p": top_p or self.config["top_p"]
        }
        
        try:
            # 1. V√©rification cache si activ√©
            if use_cache:
                cached_response = self.response_cache.get(messages, **params)
                if cached_response:
                    self._cached_requests += 1
                    self.circuit_breaker.record_success()
                    
                    log_intent_detection(
                        "deepseek_cache_hit",
                        cache_age=cached_response.get("cache_age_seconds", 0)
                    )
                    
                    return cached_response
            
            # 2. Appel API avec retry
            response = await self._make_api_call_with_retry(
                messages=messages,
                params=params,
                timeout=timeout or self.config["timeout"]
            )
            
            if not response:
                return None
            
            # 3. Traitement r√©ponse
            processed_response = self._process_api_response(response)
            
            # 4. Mise en cache si succ√®s
            if use_cache and processed_response:
                # TTL adaptatif selon type requ√™te
                cache_ttl = self._get_adaptive_ttl(messages, processed_response)
                self.response_cache.set(messages, processed_response, ttl=cache_ttl, **params)
            
            # 5. M√©triques
            latency = (time.time() - start_time) * 1000
            self._update_metrics(processed_response, latency)
            
            # 6. Circuit breaker succ√®s
            self.circuit_breaker.record_success()
            self._successful_requests += 1
            
            log_intent_detection(
                "deepseek_api_success",
                latency_ms=latency,
                tokens_used=processed_response.get("usage", {}).get("total_tokens", 0)
            )
            
            return processed_response
            
        except Exception as e:
            latency = (time.time() - start_time) * 1000
            
            # Circuit breaker √©chec
            self.circuit_breaker.record_failure()
            
            log_intent_detection(
                "deepseek_api_error",
                error=str(e),
                latency_ms=latency
            )
            
            logger.warning(f"‚ö†Ô∏è Erreur DeepSeek API: {e}")
            return None
    
    async def _make_api_call_with_retry(
        self,
        messages: List[Dict[str, str]],
        params: Dict[str, Any],
        timeout: int
    ) -> Optional[Dict[str, Any]]:
        """Appel API avec retry automatique et backoff exponentiel"""
        
        payload = {
            "model": self.config["chat_model"],
            "messages": messages,
            **params
        }
        
        for attempt in range(self.max_retries + 1):
            try:
                response = await self.client.post(
                    "/chat/completions",
                    json=payload,
                    timeout=timeout
                )
                
                response.raise_for_status()
                return response.json()
                
            except HTTPStatusError as e:
                if e.response.status_code == 429:  # Rate limit
                    if attempt < self.max_retries:
                        retry_delay = self.retry_delay * (2 ** attempt)  # Backoff exponentiel
                        logger.warning(f"‚è≥ Rate limit DeepSeek - Retry dans {retry_delay}s")
                        await asyncio.sleep(retry_delay)
                        continue
                    else:
                        logger.error("‚ùå Rate limit DeepSeek - Max retries atteint")
                        raise
                        
                elif e.response.status_code >= 500:  # Erreur serveur
                    if attempt < self.max_retries:
                        retry_delay = self.retry_delay * (2 ** attempt)
                        logger.warning(f"üîÑ Erreur serveur DeepSeek - Retry dans {retry_delay}s")
                        await asyncio.sleep(retry_delay)
                        continue
                    else:
                        logger.error(f"‚ùå Erreur serveur DeepSeek persistante: {e}")
                        raise
                else:
                    # Erreur client (4xx) - pas de retry
                    logger.error(f"‚ùå Erreur client DeepSeek: {e}")
                    raise
                    
            except RequestError as e:
                if attempt < self.max_retries:
                    retry_delay = self.retry_delay * (2 ** attempt)
                    logger.warning(f"üåê Erreur r√©seau DeepSeek - Retry dans {retry_delay}s")
                    await asyncio.sleep(retry_delay)
                    continue
                else:
                    logger.error(f"‚ùå Erreur r√©seau DeepSeek persistante: {e}")
                    raise
            
            except asyncio.TimeoutError as e:
                if attempt < self.max_retries:
                    logger.warning(f"‚è∞ Timeout DeepSeek - Tentative {attempt + 1}/{self.max_retries + 1}")
                    await asyncio.sleep(self.retry_delay)
                    continue
                else:
                    logger.error("‚ùå Timeout DeepSeek - Max retries atteint")
                    raise
        
        return None
    
    def _process_api_response(self, raw_response: Dict[str, Any]) -> Dict[str, Any]:
        """Traitement et normalisation r√©ponse API"""
        try:
            choices = raw_response.get("choices", [])
            if not choices:
                logger.warning("‚ö†Ô∏è R√©ponse DeepSeek sans choices")
                return None
            
            first_choice = choices[0]
            message = first_choice.get("message", {})
            content = message.get("content", "").strip()
            
            if not content:
                logger.warning("‚ö†Ô∏è R√©ponse DeepSeek vide")
                return None
            
            # R√©ponse normalis√©e
            processed = {
                "content": content,
                "role": message.get("role", "assistant"),
                "finish_reason": first_choice.get("finish_reason"),
                "usage": raw_response.get("usage", {}),
                "model": raw_response.get("model"),
                "created": raw_response.get("created"),
                "cached": False
            }
            
            return processed
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur traitement r√©ponse DeepSeek: {e}")
            return None
    
    def _get_adaptive_ttl(self, messages: List[Dict[str, str]], response: Dict[str, Any]) -> int:
        """TTL adaptatif bas√© sur type requ√™te et qualit√© r√©ponse"""
        base_ttl = 900  # 15 minutes par d√©faut
        
        # Analyse contenu pour d√©terminer TTL optimal
        content = response.get("content", "").lower()
        
        # R√©ponses classification intentions : TTL court (donn√©es sp√©cifiques)
        if any(intent in content for intent in ["intent", "confidence", "balance_check", "transfer"]):
            return base_ttl // 3  # 5 minutes
        
        # R√©ponses conseils g√©n√©raux : TTL long (stable)
        if any(word in content for word in ["conseil", "recommandation", "g√©n√©ral"]):
            return base_ttl * 2  # 30 minutes
        
        # R√©ponses courtes/simples : TTL moyen
        if len(content) < 100:
            return base_ttl // 2  # 7.5 minutes
        
        return base_ttl
    
    def _update_metrics(self, response: Dict[str, Any], latency_ms: float):
        """Mise √† jour m√©triques performance"""
        if not response:
            return
        
        # Tokens utilis√©s
        usage = response.get("usage", {})
        total_tokens = usage.get("total_tokens", 0)
        self._total_tokens += total_tokens
        
        # Latence
        self._total_latency += latency_ms
        
        # Estimation co√ªt (approximative)
        estimated_cost = (total_tokens / 1000) * 0.002  # $0.002 per 1K tokens
        self._cost_estimate += estimated_cost
    
    async def _test_api_connection(self) -> bool:
        """Test connexion API au d√©marrage"""
        try:
            test_messages = [{
                "role": "user",
                "content": "Test connexion. R√©pondez: OK"
            }]
            
            response = await self.chat_completion(
                messages=test_messages,
                max_tokens=5,
                temperature=0.1,
                use_cache=False
            )
            
            if response and "ok" in response.get("content", "").lower():
                logger.info("‚úÖ Test connexion DeepSeek r√©ussi")
                return True
            else:
                logger.warning("‚ö†Ô∏è Test connexion DeepSeek: r√©ponse inattendue")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Test connexion DeepSeek √©chou√©: {e}")
            return False
    
    # ==========================================
    # M√âTRIQUES ET MONITORING
    # ==========================================
    
    async def get_metrics(self) -> Dict[str, Any]:
        """M√©triques d√©taill√©es client DeepSeek"""
        success_rate = self._successful_requests / max(1, self._total_requests)
        cache_hit_rate = self._cached_requests / max(1, self._total_requests)
        avg_latency = self._total_latency / max(1, self._successful_requests)
        
        return {
            "total_requests": self._total_requests,
            "successful_requests": self._successful_requests,
            "cached_requests": self._cached_requests,
            "success_rate": round(success_rate, 3),
            "cache_hit_rate": round(cache_hit_rate, 3),
            "average_latency_ms": round(avg_latency, 2),
            "total_tokens_used": self._total_tokens,
            "estimated_cost_usd": round(self._cost_estimate, 4),
            "circuit_breaker": {
                "state": self.circuit_breaker.state,
                "failure_count": self.circuit_breaker.failure_count
            },
            "cache_stats": self.response_cache.get_stats(),
            "configuration": {
                "model": self.config["chat_model"],
                "base_url": self.config["base_url"],
                "max_retries": self.max_retries,
                "default_timeout": self.config["timeout"]
            }
        }
    
    async def get_health_status(self) -> Dict[str, Any]:
        """Status sant√© client DeepSeek"""
        is_healthy = (
            self.client is not None and
            self.circuit_breaker.state != "OPEN"
        )
        
        return {
            "healthy": is_healthy,
            "client_initialized": self.client is not None,
            "circuit_breaker_state": self.circuit_breaker.state,
            "api_key_configured": bool(self.config.get("api_key")),
            "base_url": self.config.get("base_url", ""),
            "last_success": self._successful_requests > 0
        }
    
    # ==========================================
    # M√âTHODES UTILITAIRES
    # ==========================================
    
    async def clear_cache(self):
        """Vidage cache r√©ponses"""
        self.response_cache.clear()
        logger.info("üßπ Cache DeepSeek vid√©")
    
    async def reset_circuit_breaker(self):
        """Reset manuel circuit breaker"""
        self.circuit_breaker.failure_count = 0
        self.circuit_breaker.state = "CLOSED"
        logger.info("üîÑ Circuit breaker DeepSeek reset")
    
    async def test_specific_prompt(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Test prompt sp√©cifique avec m√©triques d√©taill√©es"""
        start_time = time.time()
        
        messages = [{"role": "user", "content": prompt}]
        
        response = await self.chat_completion(
            messages=messages,
            use_cache=False,  # Pas de cache pour test
            **kwargs
        )
        
        test_result = {
            "prompt": prompt,
            "response_time_ms": round((time.time() - start_time) * 1000, 2),
            "success": response is not None
        }
        
        if response:
            test_result.update({
                "content": response.get("content", ""),
                "tokens_used": response.get("usage", {}).get("total_tokens", 0),
                "finish_reason": response.get("finish_reason"),
                "model": response.get("model")
            })
        
        return test_result
    
    async def shutdown(self):
        """Arr√™t propre client DeepSeek"""
        logger.info("üõë Arr√™t DeepSeek Client...")
        
        try:
            # M√©triques finales
            final_metrics = await self.get_metrics()
            logger.info(f"üìä M√©triques finales DeepSeek: "
                       f"Requests: {final_metrics['total_requests']}, "
                       f"Success rate: {final_metrics['success_rate']:.1%}, "
                       f"Cache hit rate: {final_metrics['cache_hit_rate']:.1%}, "
                       f"Total cost: ${final_metrics['estimated_cost_usd']:.4f}")
            
            # Fermeture client HTTP
            if self.client:
                await self.client.aclose()
                self.client = None
            
            # Clear cache
            self.response_cache.clear()
            
            logger.info("‚úÖ DeepSeek Client arr√™t√©")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur arr√™t DeepSeek Client: {e}")


# ==========================================
# HELPERS ET UTILITAIRES
# ==========================================

async def test_deepseek_integration() -> Dict[str, Any]:
    """Test int√©gration compl√®te DeepSeek"""
    client = DeepSeekClient()
    
    try:
        # Initialisation
        await client.initialize()
        
        # Tests divers
        test_cases = [
            {
                "name": "simple_query",
                "prompt": "Classifiez cette intention: 'quel est mon solde'",
                "expected_keywords": ["balance", "intent"]
            },
            {
                "name": "json_response",
                "prompt": "R√©pondez en JSON: {'test': 'ok'}",
                "expected_keywords": ["test", "ok"]
            },
            {
                "name": "french_support",
                "prompt": "Analysez cette requ√™te fran√ßaise: 'mes d√©penses restaurant'",
                "expected_keywords": ["d√©penses", "restaurant"]
            }
        ]
        
        results = []
        for test_case in test_cases:
            result = await client.test_specific_prompt(
                test_case["prompt"],
                max_tokens=100,
                temperature=0.1
            )
            
            # V√©rification mots-cl√©s attendus
            content_lower = result.get("content", "").lower()
            keywords_found = [
                kw for kw in test_case["expected_keywords"] 
                if kw.lower() in content_lower
            ]
            
            result.update({
                "test_name": test_case["name"],
                "keywords_expected": test_case["expected_keywords"],
                "keywords_found": keywords_found,
                "keywords_match_rate": len(keywords_found) / len(test_case["expected_keywords"])
            })
            
            results.append(result)
        
        # M√©triques globales test
        integration_result = {
            "integration_successful": all(r["success"] for r in results),
            "average_response_time_ms": sum(r["response_time_ms"] for r in results) / len(results),
            "total_tokens_used": sum(r.get("tokens_used", 0) for r in results),
            "test_results": results,
            "client_metrics": await client.get_metrics()
        }
        
        await client.shutdown()
        return integration_result
        
    except Exception as e:
        logger.error(f"‚ùå Erreur test int√©gration DeepSeek: {e}")
        return {"integration_successful": False, "error": str(e)}