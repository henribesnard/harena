# Quick Start Guide - Conversation Service V3

## üöÄ D√©marrage Rapide

### 1. Pr√©requis

```bash
# Python 3.10+
python --version

# Dependencies
cd conversation_service_v3
pip install -r requirements.txt
```

### 2. Configuration

Cr√©ez un fichier `.env` :

```bash
# Copier l'exemple
cp .env.example .env

# √âditer avec vos cl√©s
nano .env
```

Contenu minimum du `.env` :

```env
# OpenAI API Key (requis)
OPENAI_API_KEY=sk-your-openai-key-here

# LLM Configuration
LLM_MODEL=gpt-4o-mini
LLM_RESPONSE_MODEL=gpt-4o
LLM_TEMPERATURE=0.1

# Services
SEARCH_SERVICE_URL=http://localhost:3002

# Agent Configuration
MAX_CORRECTION_ATTEMPTS=2
QUERY_TIMEOUT_SECONDS=30

# Logging
LOG_LEVEL=INFO
```

### 3. D√©marrer le Service

```bash
# Depuis le dossier conversation_service_v3
python -m uvicorn app.main:app --host 0.0.0.0 --port 3008 --reload
```

Vous devriez voir :

```
INFO:     Uvicorn running on http://0.0.0.0:3008 (Press CTRL+C to quit)
INFO:     Started reloader process
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

### 4. V√©rifier que √ßa marche

Ouvrez un nouveau terminal :

```bash
# Health check
curl http://localhost:3008/health

# Devrait retourner:
# {"status":"healthy","service":"conversation_service_v3",...}
```

### 5. Tester l'API

#### Option A : Avec curl

```bash
curl -X POST http://localhost:3008/api/v1/conversation/3 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-jwt-token" \
  -d '{
    "client_info": {
      "platform": "web",
      "version": "1.0.0"
    },
    "message": "Mes d√©penses de plus de 100 euros",
    "message_type": "text",
    "priority": "normal"
  }'
```

#### Option B : Avec le script de test

```bash
# Test simple
python test_v1_compatibility.py

# Test d√©taill√© avec analyse
python test_detailed.py
```

#### Option C : Avec Python

```python
import requests

url = "http://localhost:3008/api/v1/conversation/3"

payload = {
    "client_info": {
        "platform": "web",
        "version": "1.0.0"
    },
    "message": "Mes d√©penses de plus de 100 euros",
    "message_type": "text",
    "priority": "normal"
}

headers = {
    "authorization": "Bearer your-jwt-token",
    "content-type": "application/json"
}

response = requests.post(url, json=payload, headers=headers)
print(response.json())
```

## üìù Tests D√©taill√©s

### Lancer les tests complets

```bash
python test_detailed.py
```

Ce script va :
- ‚úÖ V√©rifier que le service est accessible
- ‚úÖ Tester plusieurs types de requ√™tes
- ‚úÖ Mesurer les temps de r√©ponse
- ‚úÖ V√©rifier la structure des r√©ponses
- ‚úÖ Identifier les bugs automatiquement
- ‚úÖ Sauvegarder les r√©sultats dans un fichier JSON

### Analyser les r√©sultats

Les r√©sultats sont sauvegard√©s dans `test_results_YYYYMMDD_HHMMSS.json`

```bash
# Voir le dernier r√©sultat
cat test_results_*.json | jq .
```

## üêõ Troubleshooting

### Le service ne d√©marre pas

**Erreur : "OPENAI_API_KEY not found"**
```bash
# V√©rifier le .env
cat .env | grep OPENAI_API_KEY

# Doit contenir :
# OPENAI_API_KEY=sk-...
```

**Erreur : "Port already in use"**
```bash
# Trouver le processus qui utilise le port 3008
# Windows
netstat -ano | findstr :3008

# Linux/Mac
lsof -i :3008

# Tuer le processus ou changer le port
python -m uvicorn app.main:app --port 3009
```

**Erreur : "Module not found"**
```bash
# R√©installer les d√©pendances
pip install -r requirements.txt --force-reinstall
```

### Les tests √©chouent

**"Connection Error"**
```bash
# V√©rifier que le service tourne
curl http://localhost:3008/health
```

**"Timeout"**
- Le LLM peut prendre du temps √† r√©pondre (normal)
- V√©rifiez votre connexion internet
- V√©rifiez que search_service est accessible

**"Invalid JWT"**
- Le token JWT doit √™tre valide
- Pour les tests, vous pouvez temporairement d√©sactiver l'auth
- Ou utiliser un token de test valide

### Logs et Debug

```bash
# Voir les logs en temps r√©el
# Le terminal o√π uvicorn tourne affiche tous les logs

# Augmenter le niveau de log
# Dans .env :
LOG_LEVEL=DEBUG
```

## üìä Endpoints Disponibles

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/health` | GET | Health check global |
| `/api/v1/conversation/health` | GET | Health check conversation |
| `/api/v1/conversation/status` | GET | Statut du service |
| `/api/v1/conversation/metrics` | GET | M√©triques |
| `/api/v1/conversation/{user_id}` | POST | Endpoint principal |
| `/api/v1/conversation/{user_id}/stream` | POST | Streaming |

## üîß Analyse des Bugs

Apr√®s avoir lanc√© `python test_detailed.py`, vous aurez :

1. **R√©sultats console** : Affichage d√©taill√© de chaque test
2. **Fichier JSON** : R√©sultats complets pour analyse
3. **Section BUGS** : Liste automatique des bugs trouv√©s
4. **Section IMPROVEMENTS** : Suggestions d'am√©lioration

### Exemple d'analyse

```bash
# Lancer les tests
python test_detailed.py

# Regarder les bugs trouv√©s
cat test_results_*.json | jq '.bugs'

# Regarder les am√©liorations sugg√©r√©es
cat test_results_*.json | jq '.improvements'
```

## üéØ Prochaines √âtapes

Une fois que vous avez test√© et identifi√© les bugs :

1. **Partagez les r√©sultats** : Envoyez le fichier `test_results_*.json`
2. **Listez les bugs** : Copiez la section BUGS du terminal
3. **On corrigera ensemble** : Je corrigerai les bugs identifi√©s
4. **On optimisera** : Am√©liorations de performance et fiabilit√©

## üí° Tips

- **Premier lancement** : Peut prendre 10-30s (initialisation LangChain)
- **Requ√™tes lentes** : Normal pour les premi√®res requ√™tes (cold start)
- **Cache** : Les requ√™tes similaires seront plus rapides
- **JWT** : Pour les tests, vous pouvez utiliser un token dummy

Bon test ! üöÄ
