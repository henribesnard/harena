# Conversation Service V3 üöÄ

**Architecture LangChain avec Agents Autonomes + Streaming SSE + Redis Memory**

Architecture r√©volutionnaire bas√©e sur des agents LangChain autonomes avec capacit√© d'auto-correction, streaming temps r√©el, persistence des conversations et optimisations avanc√©es du contexte LLM.

## üéØ Fonctionnalit√©s V3

### üîÑ Streaming Server-Sent Events (SSE)
- **R√©ponses en temps r√©el**: Streaming progressif des r√©ponses via SSE
- **Progressive status messages**: Messages de progression contextuels pendant le traitement
  - "‚Ä¢ Analyse de votre question..."
  - "‚Ä¢ Recherche de vos transactions..."
  - "‚Ä¢ Analyse de vos donn√©es..."
  - "‚Ä¢ X transaction(s) trouv√©e(s), g√©n√©ration de la r√©ponse..."
- **Auto-hide**: Les messages de statut disparaissent automatiquement d√®s le d√©but du streaming de la r√©ponse
- **Zero latency impact**: Messages √©mis pendant le traitement r√©el, sans ajout de d√©lai

### üíæ Redis Conversation Memory
- **Persistence des conversations**: Sauvegarde automatique dans Redis avec TTL configurable (24h par d√©faut)
- **Token control**: Limite intelligente du contexte (4000 tokens par d√©faut) pour optimiser les co√ªts LLM
- **Truncation automatique**: Suppression des tours les plus anciens si d√©passement de la limite
- **Context enrichment**: Historique conversationnel inject√© dans le prompt LLM pour coh√©rence

### üéØ Classification d'Intent S√©mantique
- **Intentions support√©es**:
  - `search`: Recherche de transactions sp√©cifiques
  - `aggregate`: Calculs et agr√©gations (totaux, moyennes, statistiques)
  - `analytical`: Analyses avanc√©es avec 9 types d'analyses
- **9 Types d'analyses analytiques**:
  - `temporal_trends`: Tendances temporelles (√©volution dans le temps)
  - `category_breakdown`: R√©partition par cat√©gories
  - `spending_patterns`: Patterns de d√©penses (r√©currence, saisonnalit√©)
  - `comparison`: Comparaisons (p√©riodes, cat√©gories, marchands)
  - `anomaly_detection`: D√©tection d'anomalies et valeurs atypiques
  - `budget_analysis`: Analyse budg√©taire et d√©passements
  - `merchant_analysis`: Analyse par marchand (fr√©quence, montants)
  - `prediction`: Pr√©dictions et projections futures
  - `custom`: Analyses personnalis√©es
- **Confidence scoring**: Chaque classification avec score de confiance

### üîç Filtrage S√©mantique Strict
- **Filtrage "achats"**: Distinction stricte entre achats (d√©bits) et autres transactions
- **Exclusion automatique**: Les virements, salaires, remboursements sont exclus des "achats"
- **Transaction type control**: Gestion pr√©cise des types `debit` vs `credit`

### üé® Optimisation du Contexte LLM
- **Field filtering**: R√©duction √† 8 champs essentiels des transactions
  - `transaction_id`, `date`, `merchant_name`, `amount`, `category_name`, `transaction_type`, `primary_description`, `user_id`
- **Smart aggregations**: Agr√©gations prioris√©es dans le contexte
- **Transaction ordering**: Garantie de l'ordre chronologique des transactions dans les conversations
- **Context window management**: Gestion intelligente de la fen√™tre de contexte

### üõ°Ô∏è Robustesse et Fiabilit√©
- **None value handling**: Gestion correcte des valeurs `None` explicites dans Elasticsearch
- **Auto-correction**: Les agents corrigent automatiquement les erreurs de query
- **Validation stricte**: Validation du `user_id` dans toutes les queries pour s√©curit√©
- **Error recovery**: R√©cup√©ration automatique sur erreurs temporaires

### üé≠ Agents Autonomes
- **QueryAnalyzerAgent**: Analyse la requ√™te et extrait les entit√©s avec classification d'intent
- **ElasticsearchBuilderAgent**: Traduit en query Elasticsearch valide avec auto-correction
- **ResponseGeneratorAgent**: G√©n√®re des r√©ponses naturelles avec streaming et insights

## üöÄ Pipeline de Traitement

```
User Query
    ‚Üì
[1. Intent Classification]
    - search / aggregate / analytical
    - Confidence scoring
    ‚Üì
[2. Query Analysis]
    - Entity extraction
    - Semantic filtering
    ‚Üì
[3. Elasticsearch Query Building]
    - Query generation
    - Field filtering
    - Auto-correction if needed
    ‚Üì
[4. Search Execution]
    - Execute on search_service
    - Transaction ordering
    ‚Üì
[5. Response Generation (Streaming)]
    - Context enrichment with Redis history
    - Progressive status messages
    - Real-time SSE streaming
    ‚Üì
[6. Conversation Persistence]
    - Save to Redis
    - Token control & truncation
    ‚Üì
Natural Language Response (Streamed)
```

## üì° API Endpoints

### POST /api/v3/conversation/stream (Streaming SSE)
Endpoint principal avec streaming temps r√©el.

**Request:**
```json
{
  "message": "Analyse mes revenus de plus de 2500 euros",
  "conversation_id": "123"  // Optionnel, auto-cr√©√© si absent
}
```

**Headers:**
```
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json
```

**Response (SSE Stream):**
```
data: {"type": "status", "message": "‚Ä¢ Analyse de votre question..."}

data: {"type": "status", "message": "‚Ä¢ Recherche de vos transactions..."}

data: {"type": "status", "message": "‚Ä¢ Analyse de vos donn√©es..."}

data: {"type": "status", "message": "‚Ä¢ 21 transaction(s) trouv√©e(s), g√©n√©ration de la r√©ponse..."}

data: {"type": "chunk", "content": "Vous avez un total de "}

data: {"type": "chunk", "content": "**21 transactions** "}

data: {"type": "chunk", "content": "avec des revenus d√©passant 2500 ‚Ç¨..."}

data: {"type": "conversation_id", "conversation_id": 123}

data: {"type": "done"}
```

### GET /api/v3/conversation/conversations/{conversation_id}
R√©cup√®re l'historique d'une conversation avec ses tours.

**Response:**
```json
{
  "id": 123,
  "user_id": 3,
  "created_at": "2025-10-23T14:30:00",
  "updated_at": "2025-10-23T14:35:00",
  "turns": [
    {
      "id": 1,
      "user_message": "Mes revenus de plus de 2500 euros",
      "assistant_response": "Vous avez un total de...",
      "created_at": "2025-10-23T14:30:00"
    }
  ]
}
```

### POST /api/v1/conversation/{user_id} (Compatibilit√© V1)
Endpoint de compatibilit√© avec conversation_service v1 (non-streaming).

### GET /api/v3/conversation/conversations
Liste toutes les conversations d'un utilisateur.

**Query params:**
- `limit`: Nombre de conversations (d√©faut: 50)
- `offset`: Offset pour pagination (d√©faut: 0)

### DELETE /api/v3/conversation/conversations/{conversation_id}
Supprime une conversation et son historique.

### GET /api/v3/conversation/health
Health check de tous les composants (LLM, search_service, Redis, PostgreSQL).

### GET /api/v3/conversation/stats
Statistiques des agents et du service.

## üîß Configuration

### Variables d'Environnement

```bash
# Service
SERVICE_NAME=conversation_service_v3
PORT=3008

# External Services
SEARCH_SERVICE_URL=http://harena_search_service:3001

# Database
DATABASE_URL=postgresql://user:password@db:5432/harena

# Redis
REDIS_URL=redis://harena_redis:6379/0
REDIS_TTL_HOURS=24
REDIS_MAX_TOKENS=4000

# LLM Configuration
OPENAI_API_KEY=sk-...
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1

# Agent Configuration
MAX_CORRECTION_ATTEMPTS=2
QUERY_TIMEOUT_SECONDS=30

# Field Filtering
FIELD_FILTERING_ENABLED=true
TRANSACTION_FIELDS_TO_KEEP=transaction_id,date,merchant_name,amount,category_name,transaction_type,primary_description,user_id

# Logging
LOG_LEVEL=INFO
```

## üé® Exemples d'Utilisation

### Exemple 1: Streaming avec status messages
```python
import httpx

with httpx.stream(
    "POST",
    "http://localhost:3008/api/v3/conversation/stream",
    json={"message": "Mes d√©penses de plus de 100 euros ce mois-ci"},
    headers={"Authorization": "Bearer YOUR_TOKEN"},
    timeout=30.0
) as response:
    for line in response.iter_lines():
        if line.startswith("data: "):
            data = json.loads(line[6:])

            if data["type"] == "status":
                print(f"Status: {data['message']}")
            elif data["type"] == "chunk":
                print(data["content"], end="", flush=True)
            elif data["type"] == "done":
                print("\n‚úÖ Termin√©")
```

### Exemple 2: Conversation multi-tours
```python
# Premier message
response1 = httpx.post(
    "http://localhost:3008/api/v3/conversation/stream",
    json={"message": "Mes d√©penses en restaurants ce mois-ci"},
    headers={"Authorization": "Bearer YOUR_TOKEN"}
)
conversation_id = extract_conversation_id(response1)

# Deuxi√®me message avec contexte
response2 = httpx.post(
    "http://localhost:3008/api/v3/conversation/stream",
    json={
        "message": "Et le mois dernier ?",
        "conversation_id": conversation_id
    },
    headers={"Authorization": "Bearer YOUR_TOKEN"}
)
```

### Exemple 3: Analyse temporelle
```python
response = httpx.post(
    "http://localhost:3008/api/v3/conversation/stream",
    json={"message": "Montre-moi l'√©volution de mes d√©penses sur les 6 derniers mois"},
    headers={"Authorization": "Bearer YOUR_TOKEN"}
)
# Intent d√©tect√©: analytical (temporal_trends)
```

## üìà Performance

### M√©triques Typiques (v5.0.12)
- **Temps de r√©ponse moyen**: 1.5-3 secondes (premier chunk)
- **Streaming latency**: <100ms par chunk
- **Taux de succ√®s**: 98%+
- **Taux de correction**: ~10% des queries
- **Redis hit rate**: ~75% pour conversations multi-tours
- **Token savings**: ~60% gr√¢ce au field filtering

### Optimisations Appliqu√©es
- ‚úÖ Field filtering: 8 champs essentiels au lieu de 20+
- ‚úÖ Redis caching: Conversation history en m√©moire
- ‚úÖ Token control: Truncation intelligente √† 4000 tokens
- ‚úÖ Streaming SSE: First byte en <500ms
- ‚úÖ Status messages: Zero latency (√©mis pendant processing)
- ‚úÖ None handling: Valeurs par d√©faut avec `or` operator

## üîê S√©curit√©

- **JWT Authentication**: Token Bearer obligatoire
- **User isolation**: Filtre `user_id` automatique et valid√©
- **Conversation ownership**: V√©rification du propri√©taire avant acc√®s
- **Field validation**: Schema Elasticsearch strictement respect√©
- **SQL injection protection**: Utilisation de SQLAlchemy ORM
- **Redis namespace**: Isolation par conversation_id

## üêõ Debugging

### Logs Structur√©s
```bash
# Production
LOG_LEVEL=INFO

# Development
LOG_LEVEL=DEBUG
```

Logs typiques:
```
2025-10-23 14:30:15 - app.agents.query_analyzer_agent - INFO - Analyzing query: Mes revenus de plus de 2500 euros
2025-10-23 14:30:18 - app.agents.query_analyzer_agent - INFO - Query analysis completed: intent=search, confidence=0.95
2025-10-23 14:30:20 - app.agents.response_generator_agent - INFO - [STREAM] Transactions: 21 ‚Üí 21 (filtered to 8 fields)
```

### Health Check
```bash
curl http://localhost:3008/api/v3/conversation/health
```

Response:
```json
{
  "status": "healthy",
  "components": {
    "llm": "ok",
    "search_service": "ok",
    "redis": "ok",
    "database": "ok"
  }
}
```

## üìä Versions History

### v6.0.0Stable (2025-10-23)
- ‚úÖ Production-ready avec toutes les fonctionnalit√©s stabilis√©es
- ‚úÖ Streaming SSE avec status messages
- ‚úÖ Redis conversation memory avec token control
- ‚úÖ Field filtering pour optimisation LLM
- ‚úÖ Robust None handling dans transaction data
- ‚úÖ 9 types d'analyses analytiques
- ‚úÖ Filtrage s√©mantique strict pour "achats"

### v5.0.12 (2025-10-23)
- üêõ Fix: Handle None values in transaction fields (merchant_name, category_name)

### v5.0.11 (2025-10-23)
- üêõ Fix: Add None check for merchant field in transaction formatting

### v5.0.10 (2025-10-23)
- üé® Style: Replace emojis with bullet points in status messages

### v5.0.9 (2025-10-23)
- ‚ú® Feature: Add progressive status messages during streaming

### v5.0.8 (2025-10-23)
- ‚ú® Feature: Apply field filtering in streaming mode for consistency

### v5.0.7 (2025-10-23)
- ‚ú® Feature: Advanced analytical capabilities with 9 analysis types

### v5.0.6 (2025-10-23)
- ‚ú® Feature: Optimize LLM context with transaction field filtering

### v5.0.5 (2025-10-23)
- ‚ú® Feature: Redis conversation memory with token control

### v5.0.4 (2025-10-23)
- ‚ú® Feature: Implement strict "achats" semantic filtering

## üîÆ Roadmap v6.1

- [ ] Multi-language support (EN, ES, DE)
- [ ] Advanced analytics dashboard
- [ ] Webhook notifications for long-running queries
- [ ] GraphQL API alternative
- [ ] Prometheus metrics export
- [ ] A/B testing framework for agent prompts
- [ ] Voice input support
- [ ] Export to PDF/Excel

## üìù License

MIT

## üë• Auteurs

√âquipe Harena - 2025
