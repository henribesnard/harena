"""
Elasticsearch Builder Agent - Construit et corrige les queries Elasticsearch
Utilise LangChain avec capacitÃ© d'auto-correction
"""
import logging
import json
import os
from typing import Dict, Any, Optional, List
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_openai import ChatOpenAI

from ..models import (
    QueryAnalysis, ElasticsearchQuery, QueryValidationResult,
    AgentResponse, AgentRole
)
from ..schemas.elasticsearch_schema import (
    ELASTICSEARCH_SCHEMA, get_schema_description, get_query_template
)
from .function_definitions import (
    SEARCH_TRANSACTIONS_FUNCTION,
    AGGREGATION_TEMPLATES,
    get_all_templates_description
)
from ..services.metadata_service import metadata_service

logger = logging.getLogger(__name__)


class ElasticsearchBuilderAgent:
    """
    Agent de construction de query Elasticsearch avec auto-correction

    ResponsabilitÃ©s:
    - Traduire l'analyse en query Elasticsearch valide
    - Ajouter les agrÃ©gations appropriÃ©es
    - Valider la query gÃ©nÃ©rÃ©e
    - Se corriger automatiquement si la query Ã©choue
    """

    def __init__(self, llm_model: str = "gpt-4o-mini", temperature: float = 0.0):
        # ChatOpenAI charge automatiquement OPENAI_API_KEY depuis l'environnement
        self.llm = ChatOpenAI(
            model=llm_model,
            temperature=temperature  # TempÃ©rature basse pour plus de cohÃ©rence
        )

        self.schema_description = get_schema_description()

        # Charger les mÃ©tadonnÃ©es dynamiques (catÃ©gories, operation_types)
        try:
            self.metadata_prompt = metadata_service.get_full_metadata_prompt()
            logger.info("Metadata loaded successfully for ElasticsearchBuilderAgent")
        except Exception as e:
            logger.error(f"Failed to load metadata: {e}")
            self.metadata_prompt = ""

        # Utiliser la dÃ©finition complÃ¨te de la fonction depuis function_definitions
        # Ajuster le nom pour correspondre Ã  l'usage interne
        self.search_query_function = SEARCH_TRANSACTIONS_FUNCTION.copy()
        self.search_query_function["name"] = "generate_search_query"

        # Obtenir la description des templates disponibles
        templates_description = get_all_templates_description()

        # Prompt enrichi pour function calling avec templates et exemples
        # Injecter les mÃ©tadonnÃ©es dynamiques avant les rÃ¨gles critiques
        self.build_prompt_text = """Question utilisateur: "{user_query}"

GÃ©nÃ¨re une requÃªte de recherche pour: {intent}

Contexte:
- User ID: {user_id}
- Date actuelle: {current_date}
- Filtres dÃ©tectÃ©s: {filters}
- AgrÃ©gations demandÃ©es: {aggregations}
- PÃ©riode: {time_range}

TEMPLATES D'AGRÃ‰GATIONS DISPONIBLES:

""" + templates_description + """

{metadata}

RÃˆGLES CRITIQUES:
1. **QUESTIONS DE SOLDE / COMPTES** â†’ Utiliser l'index ACCOUNTS:
   - Mots-clÃ©s: "solde", "compte", "balance", "combien j'ai sur mon compte"
   - Utiliser les champs: account_balance, account_name, account_type, account_currency, is_active
   - Inclure "source": ["account_id", "account_name", "account_balance", "account_currency"]
   - Sort par account_balance (pas par date)
   - Le search_service dÃ©tectera automatiquement l'index accounts

2. **PÃ‰RIODES TEMPORELLES** - Filtres de date:
   - "cette annÃ©e" = {{"gte": "AAAA-01-01T00:00:00Z", "lte": "AAAA-12-31T23:59:59Z"}} (utiliser l'annÃ©e de {current_date})
   - "ce mois" = 01 au dernier jour du mois actuel
   - "cette semaine" = lundi au dimanche de la semaine actuelle
   - Mois spÃ©cifique: "juin 2025" = {{"gte": "2025-06-01T00:00:00Z", "lte": "2025-06-30T23:59:59Z"}}

3. "plus de X euros" = amount_abs: {{"gt": X}} â†’ EXCLUT X (strictement supÃ©rieur)
4. "au moins X euros" = amount_abs: {{"gte": X}} â†’ INCLUT X (supÃ©rieur ou Ã©gal)
5. DISTINCTION TRANSACTIONS / DÃ‰PENSES / REVENUS:
   - "transactions" = PAS de filtre transaction_type (inclut dÃ©bits ET crÃ©dits)
   - "dÃ©penses" / "dÃ©bits" = transaction_type: "debit"
   - "revenus" / "crÃ©dits" = transaction_type: "credit"
6. Pour les TRANSACTIONS, TOUJOURS inclure sort: [{{"date": {{"order": "desc"}}}}] (OBLIGATOIRE)
7. AgrÃ©gations sur montants: utiliser "amount_abs", JAMAIS "amount"
8. Pour merchant_name et category_name:
   - âš ï¸ IMPORTANT: Si l'analyse fournit une LISTE de valeurs ["val1", "val2", ...], tu DOIS GARDER TOUTES les valeurs sans exception. NE PAS tronquer, NE PAS sÃ©lectionner, GARDER LA LISTE COMPLÃˆTE EXACTEMENT TELLE QUELLE.
   - Si c'est une VALEUR UNIQUE "val", utiliser {{"match": "val"}} pour recherche floue
9. TOUJOURS ajouter des agrÃ©gations de base (total, count) pour donner des statistiques utiles
10. Si l'intent indique "statistics" ou "analyze", utiliser les templates d'agrÃ©gations disponibles
11. page_size doit Ãªtre >= 1 (JAMAIS 0). Pour les queries d'agrÃ©gations, utiliser page_size: 10

EXEMPLES D'UTILISATION:

âš ï¸ IMPORTANT: Pour les questions de SOLDE / COMPTES, consulter PRIORITAIREMENT les Exemples 1 et 2 ci-dessous!

--- QUERIES SUR L'INDEX ACCOUNTS (Soldes et comptes) - PRIORITÃ‰ #1 ---

Exemple 1 - "Quel est mon solde actuel ?" ou "Montre-moi mes comptes":
{{
    "user_id": {user_id},
    "filters": {{
        "is_active": true
    }},
    "source": ["account_id", "account_name", "account_type", "account_balance", "account_currency"],
    "sort": [{{"account_balance": {{"order": "desc"}}}}],
    "page_size": 20,
    "aggregations": {{
        "total_balance": {{"sum": {{"field": "account_balance"}}}},
        "account_count": {{"value_count": {{"field": "account_id"}}}},
        "by_account_type": {{
            "terms": {{"field": "account_type.keyword", "size": 10}},
            "aggs": {{
                "total_balance": {{"sum": {{"field": "account_balance"}}}}
            }}
        }}
    }}
}}
Note: Pour les questions de SOLDE, utiliser les champs account_* (account_balance, account_name, account_type, etc.).
Le search_service dÃ©tecte automatiquement qu'il doit chercher dans l'index accounts (harena_accounts).

Exemple 2 - "Quel est le solde de mon compte courant ?":
{{
    "user_id": {user_id},
    "filters": {{
        "account_type": "checking",
        "is_active": true
    }},
    "source": ["account_id", "account_name", "account_balance", "account_currency"],
    "sort": [{{"account_balance": {{"order": "desc"}}}}],
    "page_size": 10,
    "aggregations": {{
        "total_balance": {{"sum": {{"field": "account_balance"}}}}
    }}
}}

--- QUERIES SUR L'INDEX TRANSACTIONS ---

Exemple 3 - "Mes transactions de plus de 2500 euros":
{{
    "user_id": {user_id},
    "filters": {{
        "amount_abs": {{"gt": 2500}}
    }},
    "sort": [{{"date": {{"order": "desc"}}}}],
    "page_size": 50,
    "aggregations": {{
        "transaction_count": {{"value_count": {{"field": "transaction_id"}}}},
        "total_amount": {{"sum": {{"field": "amount_abs"}}}},
        "debit_total": {{"sum": {{"field": "amount_abs"}}, "filter": {{"term": {{"transaction_type": "debit"}}}}}},
        "credit_total": {{"sum": {{"field": "amount_abs"}}, "filter": {{"term": {{"transaction_type": "credit"}}}}}}
    }}
}}
Note: PAS de filtre transaction_type car "transactions" inclut dÃ©bits ET crÃ©dits

Exemple 4 - "Mes dÃ©penses de plus de 100 euros":
{{
    "user_id": {user_id},
    "filters": {{
        "transaction_type": "debit",
        "amount_abs": {{"gt": 100}}
    }},
    "sort": [{{"date": {{"order": "desc"}}}}],
    "page_size": 50,
    "aggregations": {{
        "transaction_count": {{"value_count": {{"field": "transaction_id"}}}},
        "total_amount": {{"sum": {{"field": "amount_abs"}}}}
    }}
}}

Exemple 5 - "Combien j'ai dÃ©pensÃ© en restaurants ce mois?":
{{
    "user_id": {user_id},
    "filters": {{
        "category_name": {{"match": "restaurant"}},
        "transaction_type": "debit",
        "date": {{"gte": "2025-10-01T00:00:00Z", "lte": "2025-10-31T23:59:59Z"}}
    }},
    "sort": [{{"date": {{"order": "desc"}}}}],
    "page_size": 10,
    "aggregations": {{
        "total_spent": {{"sum": {{"field": "amount_abs"}}}},
        "transaction_count": {{"value_count": {{"field": "transaction_id"}}}},
        "avg_transaction": {{"avg": {{"field": "amount_abs"}}}}
    }}
}}

Exemple 6 - "Mes achats entre 50â‚¬ et 150â‚¬" (catÃ©gories multiples):
{{
    "user_id": {user_id},
    "filters": {{
        "category_name": ["Alimentation", "Restaurant", "achats en ligne", "Transport", "SantÃ©/pharmacie", "Loisirs"],
        "transaction_type": "debit",
        "amount_abs": {{"gte": 50, "lte": 150}}
    }},
    "sort": [{{"date": {{"order": "desc"}}}}],
    "page_size": 10,
    "aggregations": {{
        "total_spent": {{"sum": {{"field": "amount_abs"}}}},
        "transaction_count": {{"value_count": {{"field": "transaction_id"}}}}
    }}
}}

Exemple 7 - "Ã‰volution mensuelle de mes dÃ©penses sur 6 mois":
{{
    "user_id": {user_id},
    "filters": {{
        "transaction_type": "debit",
        "date": {{"gte": "2025-04-01T00:00:00Z", "lte": "2025-10-31T23:59:59Z"}}
    }},
    "sort": [{{"date": {{"order": "desc"}}}}],
    "page_size": 10,
    "aggregations": {{
        "monthly_breakdown": {{
            "date_histogram": {{
                "field": "date",
                "calendar_interval": "month",
                "format": "yyyy-MM"
            }},
            "aggs": {{
                "total_spent": {{"sum": {{"field": "amount_abs"}}}},
                "transaction_count": {{"value_count": {{"field": "transaction_id"}}}}
            }}
        }}
    }}
}}

Exemple 8 - "RÃ©partition de mes dÃ©penses par catÃ©gorie":
{{
    "user_id": {user_id},
    "filters": {{
        "transaction_type": "debit"
    }},
    "sort": [{{"date": {{"order": "desc"}}}}],
    "page_size": 10,
    "aggregations": {{
        "by_category": {{
            "terms": {{
                "field": "category_name.keyword",
                "size": 20,
                "order": {{"total_amount": "desc"}}
            }},
            "aggs": {{
                "total_amount": {{"sum": {{"field": "amount_abs"}}}},
                "transaction_count": {{"value_count": {{"field": "transaction_id"}}}},
                "avg_transaction": {{"avg": {{"field": "amount_abs"}}}}
            }}
        }}
    }}
}}

Exemple 9 - "Mon taux d'Ã©pargne cette annÃ©e" ou "Mes dÃ©penses cette annÃ©e":
{{
    "user_id": {user_id},
    "filters": {{
        "transaction_type": "debit",
        "date": {{"gte": "2025-01-01T00:00:00Z", "lte": "2025-12-31T23:59:59Z"}}
    }},
    "sort": [{{"date": {{"order": "desc"}}}}],
    "page_size": 10,
    "aggregations": {{
        "total_spent": {{"sum": {{"field": "amount_abs"}}}},
        "transaction_count": {{"value_count": {{"field": "transaction_id"}}}}
    }}
}}
Note: "cette annÃ©e" doit filtrer sur l'annÃ©e en cours (date actuelle: {current_date}).
Extraire l'annÃ©e de {current_date} et filtrer de 01-01 Ã  31-12 de cette annÃ©e."""

        # Prompt pour l'auto-correction
        self.correction_prompt = ChatPromptTemplate.from_messages([
            ("system", """Tu es un expert Elasticsearch qui corrige des queries dÃ©faillantes.

SchÃ©ma Elasticsearch:
{schema}

Ta mission: Analyser l'erreur et proposer une query corrigÃ©e.

Erreurs courantes Ã  corriger:
- Champs inexistants â†’ utiliser les bons noms de champs
- Syntaxe invalide â†’ corriger la structure JSON
- AgrÃ©gations mal formÃ©es â†’ utiliser la bonne syntaxe
- Filtres manquants â†’ ajouter user_id

Retourne UNIQUEMENT le JSON de la query corrigÃ©e."""),
            ("user", """Query qui a Ã©chouÃ©:
{failed_query}

Erreur rencontrÃ©e:
{error_message}

Contexte original:
Intent: {intent}
Filtres demandÃ©s: {filters}
User ID: {user_id}

Corrige cette query pour qu'elle fonctionne.""")
        ])

        # Pas de chain pour function calling, on appelle directement le LLM
        self.correction_chain = self.correction_prompt | self.llm | JsonOutputParser()

        self.stats = {
            "queries_built": 0,
            "corrections_attempted": 0,
            "successful_corrections": 0
        }

        logger.info(f"ElasticsearchBuilderAgent initialized with model {llm_model}")

    async def build_query(
        self,
        query_analysis: QueryAnalysis,
        user_id: int,
        current_date: str = None,
        user_query: str = None
    ) -> AgentResponse:
        """
        Construit une query Elasticsearch Ã  partir de l'analyse
        UTILISE FUNCTION CALLING pour garantir le bon format

        Args:
            query_analysis: Analyse de la requÃªte utilisateur
            user_id: ID de l'utilisateur
            current_date: Date actuelle pour les calculs de pÃ©riode (dÃ©faut: aujourd'hui)
            user_query: Question originale de l'utilisateur (optionnel mais recommandÃ©)

        Returns:
            AgentResponse contenant ElasticsearchQuery
        """
        # Utiliser la date actuelle si non fournie
        if not current_date:
            from datetime import datetime
            current_date = datetime.now().strftime("%Y-%m-%d")
        try:
            logger.info(f"Building Elasticsearch query for intent: {query_analysis.intent}")

            # PrÃ©parer le message pour function calling
            prompt_message = self.build_prompt_text.format(
                user_query=user_query if user_query else "Non spÃ©cifiÃ©e",
                intent=query_analysis.intent,
                filters=json.dumps(query_analysis.filters, ensure_ascii=False),
                aggregations=json.dumps(query_analysis.aggregations_needed, ensure_ascii=False),
                time_range=json.dumps(query_analysis.time_range, ensure_ascii=False) if query_analysis.time_range else "Non spÃ©cifiÃ©",
                user_id=user_id,
                current_date=current_date,
                metadata=self.metadata_prompt
            )

            # Appeler le LLM avec function calling (utiliser predict_messages pour function calling)
            from langchain.schema import HumanMessage
            response = await self.llm.apredict_messages(
                [HumanMessage(content=prompt_message)],
                functions=[self.search_query_function],
                function_call={"name": "generate_search_query"}
            )

            # Extraire le rÃ©sultat de la function call
            # apredict_messages retourne un AIMessage directement
            function_call = response.additional_kwargs.get("function_call")
            if not function_call:
                raise ValueError("No function call in LLM response")

            result = json.loads(function_call["arguments"])

            # S'assurer que user_id est prÃ©sent
            if "user_id" not in result:
                result["user_id"] = user_id

            # âš ï¸ RÃˆGLE D'EXCLUSION MUTUELLE: marchand vs catÃ©gories
            # PrioritÃ©: marchand > catÃ©gories
            # Si un marchand est spÃ©cifiÃ©, on ne filtre PAS sur les catÃ©gories
            # Cela Ã©vite des rÃ©sultats vides quand marchand + catÃ©gories sont combinÃ©s
            if "filters" in result and isinstance(result["filters"], dict):
                has_merchant = "merchant_name" in result["filters"] and result["filters"]["merchant_name"]
                has_category = "category_name" in result["filters"] and result["filters"]["category_name"]

                if has_merchant and has_category:
                    logger.info(
                        f"ðŸ”§ Mutual exclusion: merchant_name present, removing category_name filter. "
                        f"Merchant: {result['filters']['merchant_name']}"
                    )
                    del result["filters"]["category_name"]

            # CORRECTIF: PrÃ©server les listes de catÃ©gories/marchands depuis l'analyse originale
            # Le LLM a tendance Ã  tronquer les longues listes, donc on force la liste originale
            if "filters" in result and isinstance(result["filters"], dict):
                # PrÃ©server category_name si c'Ã©tait une liste ET si aucun marchand n'est prÃ©sent
                # âš ï¸ EXCLUSION MUTUELLE: Ne pas rÃ©introduire category_name si merchant_name existe
                if ("category_name" in query_analysis.filters
                    and isinstance(query_analysis.filters["category_name"], list)
                    and "merchant_name" not in result["filters"]):
                    original_categories = query_analysis.filters["category_name"]

                    # FILTRE RESTRICTIF: Ne garder que les VRAIES catÃ©gories d'achats
                    # Ces catÃ©gories reprÃ©sentent l'acquisition ponctuelle de biens ou services
                    PURCHASE_CATEGORIES = {
                        "Alimentation", "Restaurant", "Transport", "Carburant",
                        "achats en ligne", "SantÃ©/pharmacie", "SantÃƒÂ©/pharmacie",
                        "Loisirs", "VÃªtements", "Shopping"
                    }

                    # Filtrer pour ne garder que les achats
                    filtered_categories = [cat for cat in original_categories if cat in PURCHASE_CATEGORIES]

                    if filtered_categories:
                        logger.info(f"Filtered purchase categories: {len(filtered_categories)} out of {len(original_categories)} (kept: {filtered_categories})")
                        result["filters"]["category_name"] = filtered_categories
                    else:
                        # Si aucune catÃ©gorie d'achat, garder l'original (probablement une catÃ©gorie unique spÃ©cifique)
                        logger.warning(f"No purchase categories found in list, keeping original: {original_categories}")
                        result["filters"]["category_name"] = original_categories

                # PrÃ©server merchant_name si c'Ã©tait une liste
                elif "merchant_name" in query_analysis.filters and isinstance(query_analysis.filters["merchant_name"], list):
                    logger.info(f"Preserving original merchant list ({len(query_analysis.filters['merchant_name'])} merchants)")
                    result["filters"]["merchant_name"] = query_analysis.filters["merchant_name"]

            # Nettoyer les agrÃ©gations (enlever les champs "name" invalides ajoutÃ©s par le LLM)
            if "aggregations" in result and result["aggregations"]:
                result["aggregations"] = self._clean_aggregations(result["aggregations"])

            # Construire l'objet ElasticsearchQuery
            # Le rÃ©sultat contient: {user_id, filters, sort, page_size, aggregations}
            es_query = ElasticsearchQuery(
                query=result,  # Format search_service complet
                aggregations=result.get("aggregations"),
                size=result.get("page_size", 50),
                sort=result.get("sort")
            )

            # Validation basique
            validation = self._validate_query(es_query, user_id)

            if not validation.is_valid:
                logger.warning(f"Query validation failed: {validation.errors}")

            self.stats["queries_built"] += 1

            logger.info(f"Query built successfully with function calling. Size: {es_query.size}, Has aggs: {es_query.aggregations is not None}")

            return AgentResponse(
                success=True,
                data=es_query,
                agent_role=AgentRole.ELASTICSEARCH_BUILDER,
                metadata={
                    "validation": validation,
                    "intent": query_analysis.intent,
                    "used_function_calling": True
                }
            )

        except Exception as e:
            logger.error(f"Error building query with function calling: {str(e)}")
            return AgentResponse(
                success=False,
                data=None,
                agent_role=AgentRole.ELASTICSEARCH_BUILDER,
                error=str(e)
            )

    async def correct_query(
        self,
        failed_query: ElasticsearchQuery,
        error_message: str,
        original_analysis: QueryAnalysis,
        user_id: int
    ) -> AgentResponse:
        """
        Tente de corriger une query qui a Ã©chouÃ©

        Args:
            failed_query: Query qui a Ã©chouÃ©
            error_message: Message d'erreur d'Elasticsearch
            original_analysis: Analyse originale de la requÃªte
            user_id: ID utilisateur

        Returns:
            AgentResponse avec query corrigÃ©e
        """
        try:
            logger.info(f"Attempting to correct failed query. Error: {error_message[:100]}")

            self.stats["corrections_attempted"] += 1

            # Construire la query complÃ¨te pour le contexte
            full_query = {
                "query": failed_query.query,
                "size": failed_query.size
            }
            if failed_query.aggregations:
                full_query["aggs"] = failed_query.aggregations
            if failed_query.sort:
                full_query["sort"] = failed_query.sort

            # Invoquer le LLM pour corriger
            result = await self.correction_chain.ainvoke({
                "schema": self.schema_description,
                "failed_query": json.dumps(full_query, indent=2, ensure_ascii=False),
                "error_message": error_message,
                "intent": original_analysis.intent,
                "filters": json.dumps(original_analysis.filters, ensure_ascii=False),
                "user_id": user_id
            })

            # Construire la query corrigÃ©e
            corrected_query = ElasticsearchQuery(
                query=result.get("query", {}),
                aggregations=result.get("aggs"),
                size=result.get("size", 50),
                sort=result.get("sort")
            )

            # Validation
            validation = self._validate_query(corrected_query, user_id)

            if validation.is_valid:
                self.stats["successful_corrections"] += 1
                logger.info("Query corrected successfully")
            else:
                logger.warning(f"Corrected query still has issues: {validation.errors}")

            return AgentResponse(
                success=True,
                data=corrected_query,
                agent_role=AgentRole.ELASTICSEARCH_BUILDER,
                metadata={
                    "validation": validation,
                    "correction_attempted": True,
                    "original_error": error_message
                }
            )

        except Exception as e:
            logger.error(f"Error correcting query: {str(e)}")
            return AgentResponse(
                success=False,
                data=None,
                agent_role=AgentRole.ELASTICSEARCH_BUILDER,
                error=f"Correction failed: {str(e)}"
            )

    def _validate_query(self, query: ElasticsearchQuery, user_id: int) -> QueryValidationResult:
        """
        Valide une query au format search_service

        Args:
            query: Query Ã  valider
            user_id: ID utilisateur attendu

        Returns:
            QueryValidationResult
        """
        errors = []
        warnings = []

        # VÃ©rifier que la query existe
        if not query.query:
            errors.append("Query is empty")
            return QueryValidationResult(is_valid=False, errors=errors)

        # VÃ©rifier le format search_service (doit avoir user_id, filters, etc.)
        if "bool" in query.query or "must" in query.query or "filter" in query.query:
            errors.append("Query is in Elasticsearch DSL format instead of search_service format")
            errors.append("Expected format: {user_id, filters, sort, page_size, aggregations}")

        # VÃ©rifier le user_id au niveau racine
        if "user_id" not in query.query:
            errors.append("Missing user_id at root level - SECURITY ISSUE")
        elif query.query.get("user_id") != user_id:
            errors.append(f"Wrong user_id in query: expected {user_id}, got {query.query.get('user_id')}")

        # VÃ©rifier que filters existe (peut Ãªtre vide)
        if "filters" not in query.query:
            warnings.append("Missing 'filters' field in search_service format")

        # VÃ©rifier les champs dans les filtres
        valid_fields = set(ELASTICSEARCH_SCHEMA["fields"].keys())
        if "filters" in query.query and isinstance(query.query["filters"], dict):
            for field_name in query.query["filters"].keys():
                if field_name not in valid_fields:
                    errors.append(f"Unknown field '{field_name}' in filters")

        # VÃ©rifier les agrÃ©gations si prÃ©sentes
        if query.aggregations:
            self._validate_aggregations(query.aggregations, valid_fields, errors, warnings)

        is_valid = len(errors) == 0

        return QueryValidationResult(
            is_valid=is_valid,
            errors=errors,
            warnings=warnings
        )

    def _check_fields_in_dict(
        self,
        obj: Any,
        valid_fields: set,
        errors: List[str],
        warnings: List[str],
        path: str = ""
    ):
        """VÃ©rifie rÃ©cursivement les champs utilisÃ©s"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                current_path = f"{path}.{key}" if path else key

                # VÃ©rifier si c'est un nom de champ
                if key in ["term", "terms", "range", "match", "wildcard"]:
                    if isinstance(value, dict):
                        for field_name in value.keys():
                            if field_name not in valid_fields:
                                errors.append(f"Unknown field '{field_name}' at {current_path}")

                # RÃ©cursion
                self._check_fields_in_dict(value, valid_fields, errors, warnings, current_path)

        elif isinstance(obj, list):
            for idx, item in enumerate(obj):
                self._check_fields_in_dict(item, valid_fields, errors, warnings, f"{path}[{idx}]")

    def _clean_aggregations(self, aggs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Nettoie les agrÃ©gations en enlevant les champs invalides ajoutÃ©s par le LLM

        ProblÃ¨mes corrigÃ©s:
        1. Champs "name" invalides qui causent "Expected [START_OBJECT] under [name]"
        2. Multiples types d'agrÃ©gation dans le mÃªme objet (ex: sum + value_count)

        Args:
            aggs: AgrÃ©gations Ã  nettoyer

        Returns:
            AgrÃ©gations nettoyÃ©es
        """
        if not isinstance(aggs, dict):
            return aggs

        AGG_TYPES = ["sum", "avg", "min", "max", "stats", "value_count", "terms", "date_histogram", "cardinality"]

        cleaned = {}
        for agg_name, agg_def in aggs.items():
            if isinstance(agg_def, dict):
                # Trouver tous les types d'agrÃ©gation dans cet objet
                agg_types_found = [key for key in agg_def.keys() if key in AGG_TYPES]

                if len(agg_types_found) > 1:
                    # PROBLÃˆME: Multiple types dans une seule agrÃ©gation
                    # Solution: Garder le premier type, crÃ©er des agrÃ©gations sÃ©parÃ©es pour les autres
                    logger.warning(f"Multiple aggregation types in '{agg_name}': {agg_types_found}. Splitting...")

                    # Garder le premier type dans l'agrÃ©gation principale
                    main_type = agg_types_found[0]
                    cleaned[agg_name] = {main_type: agg_def[main_type]}

                    # CrÃ©er de nouvelles agrÃ©gations pour les autres types
                    for idx, other_type in enumerate(agg_types_found[1:], 1):
                        new_agg_name = f"{agg_name}_{other_type}"
                        cleaned[new_agg_name] = {other_type: agg_def[other_type]}
                        logger.info(f"Created separate aggregation: {new_agg_name}")

                    # GÃ©rer les sous-agrÃ©gations (aggs) s'il y en a
                    if "aggs" in agg_def:
                        cleaned[agg_name]["aggs"] = self._clean_aggregations(agg_def["aggs"])

                else:
                    # Une seule agrÃ©gation : copier en nettoyant
                    cleaned_agg = {}
                    for key, value in agg_def.items():
                        if key == "name":
                            # Ignorer le champ "name" invalide
                            logger.debug(f"Removed invalid 'name' field from aggregation '{agg_name}'")
                            continue
                        elif key == "aggs" and isinstance(value, dict):
                            # Nettoyer rÃ©cursivement les sous-agrÃ©gations
                            cleaned_agg[key] = self._clean_aggregations(value)
                        else:
                            cleaned_agg[key] = value
                    cleaned[agg_name] = cleaned_agg
            else:
                cleaned[agg_name] = agg_def

        return cleaned

    def _validate_aggregations(
        self,
        aggs: Dict[str, Any],
        valid_fields: set,
        errors: List[str],
        warnings: List[str]
    ):
        """Valide les agrÃ©gations"""
        for agg_name, agg_def in aggs.items():
            # VÃ©rifier les champs dans les agrÃ©gations
            if isinstance(agg_def, dict):
                for agg_type, agg_config in agg_def.items():
                    if agg_type in ["sum", "avg", "min", "max", "stats", "value_count"]:
                        if isinstance(agg_config, dict) and "field" in agg_config:
                            field = agg_config["field"]
                            if field not in valid_fields:
                                errors.append(f"Unknown field '{field}' in aggregation '{agg_name}'")

                    elif agg_type in ["terms", "date_histogram"]:
                        if isinstance(agg_config, dict) and "field" in agg_config:
                            field = agg_config["field"]
                            if field not in valid_fields:
                                errors.append(f"Unknown field '{field}' in aggregation '{agg_name}'")

                    # AgrÃ©gations imbriquÃ©es
                    if "aggs" in agg_def:
                        self._validate_aggregations(
                            agg_def["aggs"],
                            valid_fields,
                            errors,
                            warnings
                        )

    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de l'agent"""
        success_rate = 0.0
        if self.stats["corrections_attempted"] > 0:
            success_rate = self.stats["successful_corrections"] / self.stats["corrections_attempted"]

        return {
            "agent": "elasticsearch_builder",
            "model": self.llm.model_name,
            **self.stats,
            "correction_success_rate": success_rate
        }
