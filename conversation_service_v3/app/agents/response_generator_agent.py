"""
Response Generator Agent - G√©n√®re la r√©ponse finale
Utilise les agr√©gations + r√©sum√© + transactions pour cr√©er une r√©ponse pertinente
"""
import logging
import json
import os
from typing import Dict, Any, List, Optional
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from ..models import SearchResults, AgentResponse, AgentRole, ConversationResponse

logger = logging.getLogger(__name__)


class ResponseGeneratorAgent:
    """
    Agent de g√©n√©ration de r√©ponse finale

    Responsabilit√©s:
    - Analyser les agr√©gations Elasticsearch
    - R√©sumer les r√©sultats de recherche
    - Cr√©er une r√©ponse naturelle et pertinente
    - Inclure les d√©tails des premi√®res transactions si pertinent
    """

    def __init__(self, llm_model: str = "gpt-4o", temperature: float = 0.3):
        # ChatOpenAI charge automatiquement OPENAI_API_KEY depuis l'environnement
        self.llm = ChatOpenAI(
            model=llm_model,
            temperature=temperature
        )

        # Prompt pour la g√©n√©ration de r√©ponse
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """Tu es un assistant financier personnel expert en analyse de donn√©es.

IMPORTANT - Utilisation des donn√©es:
- Les AGR√âGATIONS contiennent les STATISTIQUES GLOBALES sur TOUS les r√©sultats
- Les transactions d√©taill√©es sont des EXEMPLES ILLUSTRATIFS (limit√©s √† {transactions_count})
- TOUJOURS utiliser les AGR√âGATIONS pour les chiffres totaux et statistiques
- JAMAIS dire "j'ai trouv√© {transactions_count} transactions" si le total est diff√©rent
- Les agr√©gations sont PRIORITAIRES sur les transactions d√©taill√©es

IMPORTANT - Contexte conversationnel:
- Tu as acc√®s √† l'historique de la conversation pr√©c√©dente
- Utilise ce contexte pour des r√©ponses coh√©rentes et personnalis√©es
- Si l'utilisateur fait r√©f√©rence √† une question pr√©c√©dente, utilise cet historique
- Reste naturel et conversationnel en tenant compte du contexte

Ton r√¥le est de cr√©er une r√©ponse claire, pr√©cise et utile bas√©e sur:
1. Les agr√©gations Elasticsearch (totaux, moyennes, statistiques) - SOURCE DE V√âRIT√â
2. Un r√©sum√© des r√©sultats de recherche
3. Les premi√®res transactions d√©taill√©es (exemples illustratifs)
4. L'historique de conversation (si disponible)

R√®gles de r√©ponse:
- Commence TOUJOURS par les chiffres des AGR√âGATIONS
- Utilise "vos/votre" (jamais "utilisateur 123")
- Mentionne les insights importants des agr√©gations
- Inclus des exemples de transactions SI pertinent
- Sois naturel et conversationnel
- Si aucun r√©sultat, explique pourquoi et propose des alternatives
- Utilise le contexte conversationnel pour des r√©ponses plus pertinentes

Format de r√©ponse:
1. R√©ponse directe √† la question avec les chiffres cl√©s
2. Insights et observations
3. D√©tails des principales transactions (si pertinent)
4. Suggestion d'action ou question de suivi (optionnel)

Exemples de bonnes r√©ponses:

Question: "Combien j'ai d√©pens√© en courses ce mois-ci ?"
Agr√©gations: total_spent: 342.50, transaction_count: 12, avg_transaction: 28.54
‚úÖ BON: "Vous avez d√©pens√© **342,50 ‚Ç¨** en courses ce mois-ci (bas√© sur 12 transactions).
         D√©pense moyenne: 28,54‚Ç¨ par visite."
‚ùå MAUVAIS: "J'ai trouv√© 10 transactions pour un total de 250‚Ç¨"
            (si les agr√©gations montrent 12 transactions et 342,50‚Ç¨)

Question: "Montre-moi mes achats Amazon"
Agr√©gations: total: 456.80, count: 8
Transactions d√©taill√©es: 5 affich√©es
‚úÖ BON: "Vous avez **8 transactions** chez Amazon pour un total de **456,80‚Ç¨**.
         Voici vos principales transactions: [liste des 5 transactions]"
‚ùå MAUVAIS: "Voici vos 5 transactions Amazon pour 250‚Ç¨"
            (si les agr√©gations en montrent 8 pour 456,80‚Ç¨)

Question: "R√©partition de mes d√©penses par cat√©gorie"
Agr√©gations: by_category avec 15 cat√©gories, totaux et comptages
‚úÖ BON: "Voici la r√©partition compl√®te de vos d√©penses par cat√©gorie (15 cat√©gories analys√©es):
         1. Alimentation: 342,50‚Ç¨ (12 transactions)
         2. Transport: 156,80‚Ç¨ (8 transactions)
         ..."
‚ùå MAUVAIS: "D'apr√®s les 10 transactions que je vois..."
            (les agr√©gations contiennent TOUTES les cat√©gories)
"""),
            ("user", """**Historique de conversation:**
{conversation_history}

**Question utilisateur actuelle:** {user_message}

**Agr√©gations Elasticsearch:**
{aggregations}

**R√©sum√© des r√©sultats:**
- Nombre total de r√©sultats: {total_results}
- Nombre de transactions retourn√©es: {transactions_count}

**Transactions (premi√®res {transactions_count}):**
{transactions}

G√©n√®re une r√©ponse compl√®te et utile en tenant compte du contexte de la conversation.""")
        ])

        self.chain = self.prompt | self.llm

        self.stats = {
            "responses_generated": 0,
            "avg_response_length": 0
        }

        logger.info(f"ResponseGeneratorAgent initialized with model {llm_model}")

    async def generate_response(
        self,
        user_message: str,
        search_results: SearchResults,
        original_query_analysis: Optional[Dict[str, Any]] = None,
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> AgentResponse:
        """
        G√©n√®re une r√©ponse finale bas√©e sur les r√©sultats de recherche

        OPTIMISATION: Ne met en contexte que:
        - Le r√©sum√© de la recherche (total, etc.)
        - Les agr√©gations compl√®tes
        - Les N premi√®res transactions (d√©fini par MAX_TRANSACTIONS_IN_CONTEXT)
        - L'historique de conversation r√©cent (si disponible)

        Args:
            user_message: Message original de l'utilisateur
            search_results: R√©sultats Elasticsearch (hits + agr√©gations)
            original_query_analysis: Analyse originale (pour contexte)
            conversation_history: Historique de conversation (format OpenAI chat)

        Returns:
            AgentResponse contenant ConversationResponse
        """
        try:
            logger.info("Generating response for query")
            logger.info("DEBUG: Line 139 - before import settings")

            from ..config.settings import settings

            logger.info("DEBUG: Line 142 - after import settings")
            # DEBUG: Log aggregations
            logger.info("DEBUG: About to log aggregations")
            logger.info(f"DEBUG: Aggregations type: {type(search_results.aggregations)}")

            # Pr√©parer les agr√©gations pour le LLM (toujours compl√®tes)
            try:
                logger.info("Step A: Starting aggregation formatting")
                aggs_summary = self._format_aggregations(search_results.aggregations)
                logger.info(f"Step A: Aggregations formatted successfully - length: {len(aggs_summary)}")
            except Exception as agg_error:
                logger.error(f"Step A ERROR: Error formatting aggregations: {agg_error}", exc_info=True)
                aggs_summary = "Agr√©gations non disponibles (erreur de formatting)"

            # Limiter le nombre de transactions dans le contexte
            logger.info("Step B: Limiting transactions")
            max_transactions = min(settings.MAX_TRANSACTIONS_IN_CONTEXT, len(search_results.hits))
            limited_transactions = search_results.hits[:max_transactions]

            # Step B.5: Filtrer les champs pour r√©duire le contexte (~50% de tokens √©conomis√©s)
            # Ne garder que les champs essentiels pour le LLM
            essential_fields = [
                'amount', 'currency_code', 'transaction_type', 'date',
                'primary_description', 'merchant_name', 'category_name', 'operation_type'
            ]

            filtered_transactions = []
            for transaction in limited_transactions:
                filtered = {field: transaction.get(field) for field in essential_fields if field in transaction}
                filtered_transactions.append(filtered)

            limited_transactions = filtered_transactions

            # DEBUG: Log pour identifier le probl√®me
            logger.info(f"Transactions received: {len(search_results.hits)}, Limited to: {len(limited_transactions)}")
            if len(limited_transactions) > 0:
                logger.info(f"Filtered transaction keys: {list(limited_transactions[0].keys())} (was 16, now {len(limited_transactions[0])})")
            else:
                logger.warning("No transactions in search_results.hits")

            if len(search_results.hits) > max_transactions:
                logger.debug(
                    f"Context limitation: {len(search_results.hits)} ‚Üí {max_transactions} transactions"
                )

            # Pr√©parer les transactions pour le LLM (limit√©es)
            logger.debug("Step C: Formatting transactions")
            transactions_text = self._format_transactions(limited_transactions)
            logger.debug(f"Step C: Transactions formatted - length: {len(transactions_text)}")

            # DEBUG: Log formatted transactions
            logger.debug(f"Transactions text preview: {transactions_text[:min(200, len(transactions_text))]}")

            # S'assurer qu'aucune valeur n'est None (LangChain ne g√®re pas bien None)
            total_results_safe = search_results.total if search_results.total is not None else 0

            # Formater l'historique de conversation
            logger.debug("Step D1: Formatting conversation history")
            history_text = self._format_conversation_history(conversation_history)
            logger.debug(f"Step D1: History formatted - length: {len(history_text)}")

            logger.debug("Step D: Preparing chain parameters")
            logger.debug(f"Chain params: total_results={total_results_safe}, transactions_count={len(limited_transactions)}")

            # Invoquer le LLM
            logger.debug("Step E: Invoking LLM chain")
            chain_params = {
                "user_message": user_message,
                "conversation_history": history_text,
                "aggregations": aggs_summary,
                "total_results": total_results_safe,
                "transactions_count": len(limited_transactions),
                "transactions": transactions_text
            }
            logger.debug(f"Chain params types: user_message={type(user_message)}, history={type(history_text)}, aggs={type(aggs_summary)}, total={type(total_results_safe)}, count={type(len(limited_transactions))}, trans={type(transactions_text)}")

            result = await self.chain.ainvoke(chain_params)
            logger.debug("Step E: LLM chain invoked successfully")

            response_text = result.content
            logger.debug(f"Step F: Response text extracted - length: {len(response_text)}")

            # Cr√©er la r√©ponse de conversation
            conversation_response = ConversationResponse(
                success=True,
                message=response_text,
                search_results=search_results,
                aggregations_summary=aggs_summary,
                metadata={
                    "total_results": total_results_safe,
                    "response_length": len(response_text),
                    "took_ms": search_results.took_ms if search_results.took_ms is not None else 0
                }
            )

            # Mise √† jour des stats
            self.stats["responses_generated"] += 1
            current_avg = self.stats["avg_response_length"]
            total_responses = self.stats["responses_generated"]
            self.stats["avg_response_length"] = (
                (current_avg * (total_responses - 1) + len(response_text)) / total_responses
            )

            logger.info(f"Response generated successfully. Length: {len(response_text)} chars")

            return AgentResponse(
                success=True,
                data=conversation_response,
                agent_role=AgentRole.RESPONSE_GENERATOR,
                metadata={
                    "response_length": len(response_text),
                    "total_results": total_results_safe
                }
            )

        except Exception as e:
            logger.error(f"Error generating response: {str(e)}", exc_info=True)
            return AgentResponse(
                success=False,
                data=None,
                agent_role=AgentRole.RESPONSE_GENERATOR,
                error=str(e)
            )

    async def generate_response_stream(
        self,
        user_message: str,
        search_results: SearchResults,
        original_query_analysis: Optional[Dict[str, Any]] = None
    ):
        """
        G√©n√®re une r√©ponse en mode streaming (yield chunks)

        Args:
            user_message: Message original de l'utilisateur
            search_results: R√©sultats Elasticsearch (hits + agr√©gations)
            original_query_analysis: Analyse originale (pour contexte)

        Yields:
            Chunks de texte au fur et √† mesure de la g√©n√©ration
        """
        try:
            logger.info(f"Generating streaming response for query: {user_message[:100]}")

            from ..config.settings import settings

            # Pr√©parer les agr√©gations pour le LLM
            aggs_summary = self._format_aggregations(search_results.aggregations)

            # Limiter le nombre de transactions dans le contexte
            max_transactions = min(settings.MAX_TRANSACTIONS_IN_CONTEXT, len(search_results.hits))
            limited_transactions = search_results.hits[:max_transactions]

            # Filtrer les champs pour r√©duire le contexte (~50% de tokens √©conomis√©s)
            # Ne garder que les champs essentiels pour le LLM
            essential_fields = [
                'amount', 'currency_code', 'transaction_type', 'date',
                'primary_description', 'merchant_name', 'category_name', 'operation_type'
            ]

            filtered_transactions = []
            for transaction in limited_transactions:
                filtered = {field: transaction.get(field) for field in essential_fields if field in transaction}
                filtered_transactions.append(filtered)

            limited_transactions = filtered_transactions

            logger.info(f"[STREAM] Transactions: {len(search_results.hits)} ‚Üí {len(limited_transactions)} (filtered to {len(essential_fields)} fields)")

            # Pr√©parer les transactions pour le LLM
            transactions_text = self._format_transactions(limited_transactions)

            # Stream la r√©ponse du LLM
            async for chunk in self.chain.astream({
                "user_message": user_message,
                "conversation_history": "",  # Pas d'historique en mode streaming (pour compatibilit√© prompt)
                "aggregations": aggs_summary,
                "total_results": search_results.total,
                "transactions_count": len(limited_transactions),
                "transactions": transactions_text
            }):
                # Chaque chunk contient le contenu g√©n√©r√©
                if hasattr(chunk, 'content'):
                    yield chunk.content

            logger.info("Streaming response completed")

        except Exception as e:
            logger.error(f"Error in streaming response: {str(e)}")
            yield f"Erreur lors de la g√©n√©ration de la r√©ponse: {str(e)}"

    def _format_aggregations(self, aggregations: Optional[Dict[str, Any]]) -> str:
        """
        Formate les agr√©gations Elasticsearch de mani√®re d√©taill√©e pour le LLM

        VERSION AM√âLIOR√âE avec interpr√©tation et contexte enrichi

        Args:
            aggregations: Agr√©gations brutes d'Elasticsearch

        Returns:
            String format√©e avec contexte enrichi
        """
        if not aggregations:
            return "Aucune agr√©gation disponible"

        formatted_lines = []
        formatted_lines.append("üìä R√âSUM√â STATISTIQUE COMPLET (SOURCE DE V√âRIT√â):\n")

        logger.debug(f"Formatting {len(aggregations)} aggregations")

        for agg_name, agg_data in aggregations.items():
            try:
                logger.debug(f"Processing aggregation: {agg_name}, type: {type(agg_data)}")
                if isinstance(agg_data, dict):
                    # Agr√©gation de valeur unique (sum, avg, etc.)
                    if "value" in agg_data:
                        value = agg_data['value']
                        if value is not None:
                            formatted_lines.append(f"‚úÖ {agg_name}: {value:.2f}")

                            # Ajouter interpr√©tation
                            if "total" in agg_name.lower() or "sum" in agg_name.lower():
                                formatted_lines.append(f"   ‚Üí Montant total calcul√© sur tous les r√©sultats")
                            elif "avg" in agg_name.lower() or "moyenne" in agg_name.lower():
                                formatted_lines.append(f"   ‚Üí Moyenne calcul√©e")
                            elif "count" in agg_name.lower():
                                formatted_lines.append(f"   ‚Üí Nombre total de transactions")

                    # Statistiques compl√®tes (stats aggregation)
                    elif "count" in agg_data and "sum" in agg_data:
                        formatted_lines.append(f"\nüìà {agg_name} (Statistiques compl√®tes):")
                        formatted_lines.append(f"   ‚Ä¢ Nombre: {agg_data.get('count', 0)}")

                        # G√©rer les valeurs None (quand 0 r√©sultats)
                        sum_val = agg_data.get('sum') or 0
                        avg_val = agg_data.get('avg') or 0
                        min_val = agg_data.get('min') or 0
                        max_val = agg_data.get('max') or 0

                        formatted_lines.append(f"   ‚Ä¢ Total: {sum_val:.2f}‚Ç¨")
                        formatted_lines.append(f"   ‚Ä¢ Moyenne: {avg_val:.2f}‚Ç¨")
                        formatted_lines.append(f"   ‚Ä¢ Min: {min_val:.2f}‚Ç¨")
                        formatted_lines.append(f"   ‚Ä¢ Max: {max_val:.2f}‚Ç¨")

                    # Filter aggregation (ex: debit_stats, credit_stats)
                    elif "doc_count" in agg_data:
                        doc_count = agg_data.get("doc_count", 0)
                        formatted_lines.append(f"\nüìä {agg_name}:")
                        formatted_lines.append(f"   ‚Ä¢ Nombre: {doc_count} transactions")

                        # Parser les sous-agr√©gations
                        for sub_agg_name, sub_agg_data in agg_data.items():
                            if sub_agg_name != "doc_count" and isinstance(sub_agg_data, dict):
                                if "value" in sub_agg_data:
                                    value = sub_agg_data.get("value")
                                    # G√©rer None
                                    if value is not None:
                                        formatted_lines.append(f"   ‚Ä¢ {sub_agg_name}: {value:.2f}‚Ç¨")
                                    else:
                                        formatted_lines.append(f"   ‚Ä¢ {sub_agg_name}: 0.00‚Ç¨")

                    # Terms aggregation (groupements par cat√©gorie, marchand, etc.)
                    elif "buckets" in agg_data:
                        buckets = agg_data["buckets"]
                        total_buckets = len(buckets)
                        displayed_buckets = buckets[:15]  # Top 15

                        formatted_lines.append(f"\nüè∑Ô∏è  {agg_name} ({total_buckets} groupes au total):")

                        for idx, bucket in enumerate(displayed_buckets, 1):
                            key = bucket.get("key", "Unknown")
                            doc_count = bucket.get("doc_count", 0)

                            line = f"   {idx}. {key}: {doc_count} transactions"

                            # Sous-agr√©gations (montants, moyennes, etc.)
                            sub_agg_parts = []
                            for sub_agg_name, sub_agg_data in bucket.items():
                                if sub_agg_name not in ["key", "doc_count", "key_as_string"]:
                                    if isinstance(sub_agg_data, dict) and "value" in sub_agg_data:
                                        value = sub_agg_data['value']
                                        if value is not None:
                                            sub_agg_parts.append(f"{sub_agg_name}: {value:.2f}‚Ç¨")

                            if sub_agg_parts:
                                line += f" | {' | '.join(sub_agg_parts)}"

                            formatted_lines.append(line)

                        if total_buckets > 15:
                            formatted_lines.append(f"   ... et {total_buckets - 15} autres groupes")

                    # Date histogram aggregation (tendances temporelles)
                    elif agg_data.get("buckets") and len(agg_data.get("buckets", [])) > 0 and "key_as_string" in agg_data["buckets"][0]:
                        formatted_lines.append(f"\nüìÖ {agg_name} (√âvolution temporelle):")
                        buckets = agg_data.get("buckets", [])

                        for bucket in buckets[:12]:  # Max 12 p√©riodes
                            period = bucket.get("key_as_string", bucket.get("key", "Unknown"))
                            doc_count = bucket.get("doc_count", 0)

                            line = f"   ‚Ä¢ {period}: {doc_count} transactions"

                            # Sous-agr√©gations
                            for sub_agg_name, sub_agg_data in bucket.items():
                                if sub_agg_name not in ["key", "doc_count", "key_as_string"]:
                                    if isinstance(sub_agg_data, dict) and "value" in sub_agg_data:
                                        value = sub_agg_data['value']
                                        if value is not None:
                                            line += f" | {sub_agg_name}: {value:.2f}‚Ç¨"

                            formatted_lines.append(line)

            except Exception as agg_error:
                logger.error(f"Error formatting aggregation '{agg_name}': {agg_error}", exc_info=True)
                formatted_lines.append(f"\n‚ö†Ô∏è {agg_name}: Erreur de formatting")

        formatted_lines.append(f"\nüí° IMPORTANT: Ces statistiques couvrent TOUS les r√©sultats, pas seulement les exemples de transactions list√©s ci-dessous.")

        return "\n".join(formatted_lines)

    def _format_transactions(self, transactions: List[Dict[str, Any]]) -> str:
        """
        Formate les transactions de mani√®re lisible pour le LLM

        Args:
            transactions: Liste des transactions

        Returns:
            String format√©e
        """
        if not transactions:
            return "Aucune transaction trouv√©e"

        formatted_lines = []

        for idx, transaction in enumerate(transactions[:50], 1):  # Max 50
            # search_service retourne les transactions avec les champs directement
            # (pas de wrapper _source comme Elasticsearch brut)

            # Extraire les informations cl√©s
            date = transaction.get("date", "Date inconnue")
            amount = transaction.get("amount") or 0  # G√©rer None
            merchant = transaction.get("merchant_name", "Marchand inconnu")
            category = transaction.get("category_name", "")
            description = transaction.get("primary_description", "")

            # Formater le montant (g√©rer None explicitement)
            amount_safe = abs(amount) if amount is not None else 0
            amount_str = f"{amount_safe:.2f} ‚Ç¨"
            if amount < 0:
                amount_str = f"-{amount_str}"

            # Ligne de transaction
            line = f"{idx}. {date} - {merchant} - {amount_str}"
            if category:
                line += f" ({category})"

            formatted_lines.append(line)

            # Ajouter description si disponible et diff√©rente du marchand
            if description and description.lower() != merchant.lower():
                formatted_lines.append(f"   Description: {description[:100]}")

        return "\n".join(formatted_lines)

    def _format_conversation_history(
        self,
        conversation_history: Optional[List[Dict[str, str]]]
    ) -> str:
        """
        Formate l'historique de conversation pour le LLM

        Args:
            conversation_history: Liste de messages {"role": "user/assistant", "content": "..."}

        Returns:
            String format√©e de l'historique
        """
        if not conversation_history or len(conversation_history) == 0:
            return "(Aucun historique de conversation - premi√®re interaction)"

        formatted_lines = []
        for idx, message in enumerate(conversation_history, 1):
            role = message.get("role", "unknown")
            content = message.get("content", "")

            # Mapper les r√¥les pour plus de clart√©
            role_display = "üë§ Utilisateur" if role == "user" else "ü§ñ Assistant"

            formatted_lines.append(f"{role_display}: {content}")

        history_count = len(conversation_history)
        return f"({history_count} messages pr√©c√©dents)\n" + "\n".join(formatted_lines)

    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de l'agent"""
        return {
            "agent": "response_generator",
            "model": self.llm.model_name,
            **self.stats
        }
