version: '3.8'

services:
  # ============================================
  # Services applicatifs
  # ============================================
  # Note: PostgreSQL, Redis et Elasticsearch sont sur AWS (63.35.52.216)

  # User Service - Gestion des utilisateurs et authentification
  user_service:
    build:
      context: .
      dockerfile: user_service/Dockerfile
    container_name: harena_user_service
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      - SECRET_KEY=${SECRET_KEY}
      - BRIDGE_CLIENT_ID=${BRIDGE_CLIENT_ID}
      - BRIDGE_CLIENT_SECRET=${BRIDGE_CLIENT_SECRET}
      - API_V1_STR=${API_V1_STR}
      - ENVIRONMENT=dev
    volumes:
      - ./user_service:/app/user_service
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "user_service"

  # Search Service - Recherche et indexation
  search_service:
    build:
      context: .
      dockerfile: search_service/Dockerfile
    container_name: harena_search_service
    ports:
      - "3001:3001"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      - REDIS_URL=${REDIS_URL}
      - API_V1_STR=${API_V1_STR}
      - ENVIRONMENT=dev
    volumes:
      - ./search_service:/app/search_service
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "search_service"

  # Metric Service - Métriques et analytics
  metric_service:
    build:
      context: .
      dockerfile: metric_service/Dockerfile
    container_name: harena_metric_service
    ports:
      - "3002:3002"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - API_V1_STR=${API_V1_STR}
      - ENVIRONMENT=dev
    volumes:
      - ./metric_service:/app/metric_service
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "metric_service"

  # Conversation Service - IA conversationnelle
  conversation_service:
    build:
      context: .
      dockerfile: conversation_service/Dockerfile
    container_name: harena_conversation_service
    ports:
      - "3003:3003"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - QDRANT_URL=${QDRANT_URL}
      - QDRANT_API_KEY=${QDRANT_API_KEY}
      - API_V1_STR=${API_V1_STR}
      - SEARCH_SERVICE_URL=http://harena_search_service:3001
      - ENVIRONMENT=dev
    volumes:
      - ./conversation_service:/app/conversation_service
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "conversation_service"

  # Sync Service - Synchronisation Bridge API
  sync_service:
    build:
      context: .
      dockerfile: sync_service/Dockerfile
    container_name: harena_sync_service
    ports:
      - "3004:3004"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - BRIDGE_CLIENT_ID=${BRIDGE_CLIENT_ID}
      - BRIDGE_CLIENT_SECRET=${BRIDGE_CLIENT_SECRET}
      - BRIDGE_API_URL=${BRIDGE_API_URL}
      - API_V1_STR=${API_V1_STR}
      - ENVIRONMENT=dev
    volumes:
      - ./sync_service:/app/sync_service
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "sync_service"

  # Enrichment Service - Enrichissement des transactions
  enrichment_service:
    build:
      context: .
      dockerfile: enrichment_service/Dockerfile
    container_name: harena_enrichment_service
    ports:
      - "3005:3005"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      - REDIS_URL=${REDIS_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - API_V1_STR=${API_V1_STR}
      - ENVIRONMENT=dev
    volumes:
      - ./enrichment_service:/app/enrichment_service
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "enrichment_service"

  # Budget Profiling Service - Profilage budgétaire et recommandations
  budget_profiling_service:
    build:
      context: .
      dockerfile: budget_profiling_service/Dockerfile
    container_name: harena_budget_profiling_service
    ports:
      - "3006:3006"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - SECRET_KEY=${SECRET_KEY}
      - API_V1_STR=${API_V1_STR}
      - ENVIRONMENT=dev
      - BUDGET_PROFILING_ENABLED=true
      - BUDGET_PROFILING_LOG_LEVEL=INFO
      - BUDGET_PROFILING_PORT=3006
    volumes:
      - ./budget_profiling_service:/app/budget_profiling_service
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "budget_profiling_service"

  # Conversation Service V2 - Nouvelle architecture Text-to-SQL avec DeepSeek
  conversation_service_v2:
    build:
      context: .
      dockerfile: conversation_service_v2/Dockerfile.prod
    container_name: harena_conversation_v2
    ports:
      - "3007:3007"
    environment:
      # App Configuration
      - APP_PORT=3007
      - APP_ENV=production
      - APP_DEBUG=false

      # AWS Resources (same as other services)
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - POSTGRES_HOST=63.35.52.216
      - POSTGRES_PORT=5432
      - POSTGRES_DB=harena
      - POSTGRES_USER=harena_admin
      - POSTGRES_PASSWORD=HaReNa2024SecureDbPassword123
      - REDIS_HOST=63.35.52.216
      - REDIS_PORT=6379
      - REDIS_PASSWORD=HaReNa2024-Redis-Auth-Token-Secure-Key-123456

      # DeepSeek API
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - DEEPSEEK_API_URL=${DEEPSEEK_API_URL}

      # JWT (same key as other services)
      - JWT_SECRET_KEY=${SECRET_KEY}
      - SECRET_KEY=${SECRET_KEY}

      # API
      - API_V1_STR=${API_V1_STR}
      - ENVIRONMENT=dev
    volumes:
      - ./conversation_service_v2:/app/conversation_service_v2
      - ./db_service:/app/db_service
      - ./config_service:/app/config_service
      - ./.env:/app/.env
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "conversation_service_v2"

  # Conversation Service V3 - LangChain Autonomous Agents avec Auto-Correction
  conversation_service_v3:
    build:
      context: ./conversation_service_v3
      dockerfile: Dockerfile
    container_name: harena_conversation_v3
    ports:
      - "3008:3008"
    environment:
      # Service Configuration
      - SERVICE_NAME=conversation_service_v3
      - SERVICE_VERSION=3.0.0
      - HOST=0.0.0.0
      - PORT=3008

      # External Services
      - SEARCH_SERVICE_URL=http://harena_metric_service:3002

      # OpenAI API
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=gpt-4o-mini
      - LLM_RESPONSE_MODEL=gpt-4o
      - LLM_TEMPERATURE=0.1

      # Agent Configuration
      - MAX_CORRECTION_ATTEMPTS=2
      - QUERY_TIMEOUT_SECONDS=30

      # Logging
      - LOG_LEVEL=INFO

      # API Prefix
      - API_V3_PREFIX=/api/v3
    networks:
      - harena-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "conversation_service_v3"
    depends_on:
      - metric_service

networks:
  harena-network:
    driver: bridge
