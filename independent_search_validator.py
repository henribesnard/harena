#!/usr/bin/env python3
"""
Script de validation compl√®tement ind√©pendant des fonctionnalit√©s de recherche.
Teste directement Bonsai Elasticsearch et Qdrant sans passer par search_service.
Valide que les recherches lexicales et s√©mantiques fonctionnent bien.

Usage:
    python independent_search_validator.py

Le script utilise la configuration centralis√©e de Harena via config_service.
"""
import asyncio
import aiohttp
import json
import time
import ssl
import hashlib
import sys
import os
from datetime import datetime
from typing import Dict, Any, List, Optional
from urllib.parse import urlparse

# Ajouter le r√©pertoire parent au path pour importer config_service
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config_service.config import settings
    print("‚úÖ Configuration Harena charg√©e avec succ√®s")
except ImportError as e:
    print(f"‚ùå Impossible d'importer la configuration Harena: {e}")
    print("üí° Assurez-vous que le script est dans le bon r√©pertoire du projet")
    sys.exit(1)

class IndependentSearchValidator:
    """Validateur ind√©pendant des fonctionnalit√©s de recherche."""
    
    def __init__(self):
        # Configuration depuis config_service centralis√©
        self.bonsai_url = settings.BONSAI_URL
        self.qdrant_url = settings.QDRANT_URL
        self.qdrant_api_key = settings.QDRANT_API_KEY
        
        # Utilisateur de test (modifiez selon vos donn√©es)
        self.test_user_id = 34
        
        # Index/Collection √† tester (selon votre architecture Harena)
        self.elasticsearch_index = "harena_transactions"  # Index Elasticsearch/Bonsai 
        self.qdrant_collection = "financial_transactions"  # Collection Qdrant 
        
        # Requ√™tes de test
        self.test_queries = [
            {
                "query": "virement",
                "description": "Terme financier exact",
                "expected_type": "lexical_perfect"
            },
            {
                "query": "restaurant",
                "description": "Terme commercial courant",
                "expected_type": "both_good"
            },
            {
                "query": "carte bancaire",
                "description": "Expression compos√©e",
                "expected_type": "lexical_better"
            },
            {
                "query": "achat nourriture",
                "description": "Concept alimentaire",
                "expected_type": "semantic_better"
            },
            {
                "query": "transport d√©placement",
                "description": "Concept mobilit√©",
                "expected_type": "semantic_better"
            }
        ]
        
        self.results = {
            "bonsai_lexical": [],
            "qdrant_semantic": [],
            "comparison": []
        }
    
    def log(self, level: str, message: str):
        """Log avec format color√©."""
        timestamp = datetime.now().strftime("%H:%M:%S")
        icons = {"INFO": "‚ÑπÔ∏è", "SUCCESS": "‚úÖ", "ERROR": "‚ùå", "WARNING": "‚ö†Ô∏è", "TEST": "üß™", "SEARCH": "üîç"}
        icon = icons.get(level, "üìù")
        print(f"[{timestamp}] {icon} {message}")
    
    async def run_complete_validation(self) -> Dict[str, Any]:
        """Lance la validation compl√®te des fonctionnalit√©s de recherche."""
        self.log("INFO", "üöÄ VALIDATION IND√âPENDANTE DES RECHERCHES")
        print("=" * 80)
        
        # 1. V√©rifier la configuration
        self.log("INFO", "üìã √âtape 1: V√©rification de la configuration")
        config_ok = await self.verify_configuration()
        
        if not config_ok:
            return {"error": "Configuration incompl√®te", "config_issues": True}
        
        # 2. Tester la connectivit√© de base
        self.log("INFO", "üåê √âtape 2: Test de connectivit√©")
        connectivity = await self.test_basic_connectivity()
        
        if not (connectivity["bonsai"]["connected"] or connectivity["qdrant"]["connected"]):
            return {"error": "Aucun service accessible", "connectivity": connectivity}
        
        # 3. V√©rifier les index/collections
        self.log("INFO", "üìä √âtape 3: V√©rification des donn√©es")
        data_status = await self.verify_data_availability()
        
        # 4. Tests de recherche lexicale (Bonsai)
        if connectivity["bonsai"]["connected"]:
            self.log("INFO", "üîç √âtape 4: Tests de recherche lexicale (Bonsai)")
            await self.test_bonsai_lexical_search()
        
        # 5. Tests de recherche s√©mantique (Qdrant)
        if connectivity["qdrant"]["connected"]:
            self.log("INFO", "üß† √âtape 5: Tests de recherche s√©mantique (Qdrant)")
            await self.test_qdrant_semantic_search()
        
        # 6. Comparaison des approches
        self.log("INFO", "‚öñÔ∏è √âtape 6: Comparaison des approches")
        comparison_results = await self.compare_search_approaches()
        
        # 7. Compilation du rapport final
        final_report = {
            "test_summary": {
                "timestamp": datetime.now().isoformat(),
                "configuration": config_ok,
                "connectivity": connectivity,
                "data_status": data_status
            },
            "search_results": {
                "bonsai_lexical": self.results["bonsai_lexical"],
                "qdrant_semantic": self.results["qdrant_semantic"],
                "comparison": comparison_results
            }
        }
        
        # 8. Analyse et recommandations
        final_report["analysis"] = self.analyze_search_performance(final_report)
        
        # 9. Affichage du rapport
        self.display_validation_report(final_report)
        
        return final_report
    
    async def verify_configuration(self) -> bool:
        """V√©rifie que la configuration est compl√®te."""
        issues = []
        
        if not self.bonsai_url or "your-" in self.bonsai_url:
            issues.append("BONSAI_URL non configur√©e")
            self.log("ERROR", "‚ùå BONSAI_URL manquante ou invalide")
        else:
            self.log("SUCCESS", f"‚úÖ BONSAI_URL configur√©e: {self.mask_url(self.bonsai_url)}")
        
        if not self.qdrant_url or "your-" in self.qdrant_url:
            issues.append("QDRANT_URL non configur√©e")
            self.log("ERROR", "‚ùå QDRANT_URL manquante ou invalide")
        else:
            self.log("SUCCESS", f"‚úÖ QDRANT_URL configur√©e: {self.qdrant_url}")
        
        if not self.qdrant_api_key or "your-" in self.qdrant_api_key:
            issues.append("QDRANT_API_KEY non configur√©e")
            self.log("ERROR", "‚ùå QDRANT_API_KEY manquante ou invalide")
        else:
            self.log("SUCCESS", "‚úÖ QDRANT_API_KEY configur√©e")
        
        if issues:
            self.log("WARNING", f"‚ö†Ô∏è Probl√®mes de configuration: {', '.join(issues)}")
            return False
        
        return True
    
    def mask_url(self, url: str) -> str:
        """Masque les credentials dans l'URL."""
        if "@" in url:
            parts = url.split("@")
            if len(parts) == 2:
                protocol_part = parts[0]
                host_part = parts[1]
                if "://" in protocol_part:
                    protocol = protocol_part.split("://")[0]
                    return f"{protocol}://***:***@{host_part}"
        return url
    
    async def test_basic_connectivity(self) -> Dict[str, Any]:
        """Teste la connectivit√© de base vers les services."""
        connectivity = {
            "bonsai": {"connected": False, "response_time": 0, "error": None, "cluster_info": {}},
            "qdrant": {"connected": False, "response_time": 0, "error": None, "version": ""}
        }
        
        # Test Bonsai
        if self.bonsai_url and "your-" not in self.bonsai_url:
            try:
                ssl_context = ssl.create_default_context()
                connector = aiohttp.TCPConnector(ssl=ssl_context)
                timeout = aiohttp.ClientTimeout(total=10)
                
                async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                    start_time = time.time()
                    async with session.get(self.bonsai_url) as response:
                        connectivity["bonsai"]["response_time"] = time.time() - start_time
                        
                        if response.status == 200:
                            connectivity["bonsai"]["connected"] = True
                            data = await response.json()
                            connectivity["bonsai"]["cluster_info"] = {
                                "name": data.get('cluster_name', 'unknown'),
                                "version": data.get('version', {}).get('number', 'unknown')
                            }
                            self.log("SUCCESS", f"‚úÖ Bonsai connect√©: {data.get('cluster_name', 'unknown')}")
                        else:
                            connectivity["bonsai"]["error"] = f"HTTP {response.status}"
                            self.log("ERROR", f"‚ùå Bonsai: HTTP {response.status}")
            except Exception as e:
                connectivity["bonsai"]["error"] = str(e)
                self.log("ERROR", f"‚ùå Bonsai inaccessible: {e}")
        
        # Test Qdrant
        if self.qdrant_url and "your-" not in self.qdrant_url:
            try:
                headers = {"api-key": self.qdrant_api_key} if self.qdrant_api_key else {}
                timeout = aiohttp.ClientTimeout(total=10)
                
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    start_time = time.time()
                    async with session.get(f"{self.qdrant_url}/", headers=headers) as response:
                        connectivity["qdrant"]["response_time"] = time.time() - start_time
                        
                        if response.status == 200:
                            connectivity["qdrant"]["connected"] = True
                            data = await response.json()
                            connectivity["qdrant"]["version"] = data.get("version", "unknown")
                            self.log("SUCCESS", f"‚úÖ Qdrant connect√©: v{connectivity['qdrant']['version']}")
                        else:
                            connectivity["qdrant"]["error"] = f"HTTP {response.status}"
                            self.log("ERROR", f"‚ùå Qdrant: HTTP {response.status}")
            except Exception as e:
                connectivity["qdrant"]["error"] = str(e)
                self.log("ERROR", f"‚ùå Qdrant inaccessible: {e}")
        
        return connectivity
    
    async def verify_data_availability(self) -> Dict[str, Any]:
        """V√©rifie la disponibilit√© des donn√©es dans les index/collections."""
        data_status = {
            "bonsai_index": {"exists": False, "document_count": 0, "error": None},
            "qdrant_collection": {"exists": False, "point_count": 0, "error": None}
        }
        
        # V√©rifier l'index Bonsai (harena_transactions)
        if self.bonsai_url and "your-" not in self.bonsai_url:
            try:
                ssl_context = ssl.create_default_context()
                connector = aiohttp.TCPConnector(ssl=ssl_context)
                timeout = aiohttp.ClientTimeout(total=10)
                
                async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                    # V√©rifier l'existence de l'index
                    async with session.head(f"{self.bonsai_url}/{self.elasticsearch_index}") as response:
                        if response.status == 200:
                            data_status["bonsai_index"]["exists"] = True
                            
                            # Compter les documents pour l'utilisateur de test
                            count_query = {
                                "query": {
                                    "bool": {
                                        "must": [
                                            {"term": {"user_id": self.test_user_id}}
                                        ]
                                    }
                                }
                            }
                            
                            async with session.post(
                                f"{self.bonsai_url}/{self.elasticsearch_index}/_count",
                                json=count_query
                            ) as count_response:
                                if count_response.status == 200:
                                    count_data = await count_response.json()
                                    doc_count = count_data.get("count", 0)
                                    data_status["bonsai_index"]["document_count"] = doc_count
                                    self.log("SUCCESS", f"‚úÖ Index Bonsai ({self.elasticsearch_index}): {doc_count} documents pour user {self.test_user_id}")
                                else:
                                    self.log("WARNING", f"‚ö†Ô∏è Impossible de compter les documents Bonsai")
                        else:
                            data_status["bonsai_index"]["error"] = f"Index not found (HTTP {response.status})"
                            self.log("WARNING", f"‚ö†Ô∏è Index {self.elasticsearch_index} non trouv√©")
            except Exception as e:
                data_status["bonsai_index"]["error"] = str(e)
                self.log("ERROR", f"‚ùå Erreur v√©rification index Bonsai: {e}")
        
        # V√©rifier la collection Qdrant (financial_transactions)
        if self.qdrant_url and "your-" not in self.qdrant_url:
            try:
                headers = {"api-key": self.qdrant_api_key} if self.qdrant_api_key else {}
                timeout = aiohttp.ClientTimeout(total=10)
                
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    # V√©rifier l'existence de la collection
                    async with session.get(
                        f"{self.qdrant_url}/collections/{self.qdrant_collection}", 
                        headers=headers
                    ) as response:
                        if response.status == 200:
                            collection_info = await response.json()
                            data_status["qdrant_collection"]["exists"] = True
                            
                            point_count = collection_info.get("result", {}).get("points_count", 0)
                            data_status["qdrant_collection"]["point_count"] = point_count
                            
                            self.log("SUCCESS", f"‚úÖ Collection Qdrant ({self.qdrant_collection}): {point_count} points")
                        else:
                            data_status["qdrant_collection"]["error"] = f"Collection not found (HTTP {response.status})"
                            self.log("WARNING", f"‚ö†Ô∏è Collection {self.qdrant_collection} non trouv√©e")
                            
                            # Proposer de cr√©er la collection
                            if response.status == 404:
                                self.log("INFO", "üí° Voulez-vous cr√©er la collection manquante ?")
                                await self.create_missing_qdrant_collection(session, headers)
            except Exception as e:
                data_status["qdrant_collection"]["error"] = str(e)
                self.log("ERROR", f"‚ùå Erreur v√©rification collection Qdrant: {e}")
        
        return data_status
    
    async def create_missing_qdrant_collection(self, session: aiohttp.ClientSession, headers: Dict[str, str]):
        """Cr√©e la collection Qdrant manquante."""
        try:
            self.log("INFO", f"üîß Tentative de cr√©ation de la collection {self.qdrant_collection}")
            
            # Configuration de la collection (dimension standard pour OpenAI text-embedding-3-small)
            collection_config = {
                "vectors": {
                    "size": 1536,  # Dimension pour OpenAI text-embedding-3-small
                    "distance": "Cosine"
                }
            }
            
            async with session.put(
                f"{self.qdrant_url}/collections/{self.qdrant_collection}",
                json=collection_config,
                headers=headers
            ) as response:
                if response.status in [200, 201]:
                    self.log("SUCCESS", f"‚úÖ Collection {self.qdrant_collection} cr√©√©e avec succ√®s")
                else:
                    response_text = await response.text()
                    self.log("ERROR", f"‚ùå √âchec cr√©ation collection: HTTP {response.status} - {response_text}")
        except Exception as e:
            self.log("ERROR", f"‚ùå Erreur lors de la cr√©ation de collection: {e}")
    
    async def test_bonsai_lexical_search(self):
        """Teste les recherches lexicales sur Bonsai Elasticsearch."""
        if not self.bonsai_url or "your-" in self.bonsai_url:
            self.log("WARNING", "‚ö†Ô∏è Bonsai non configur√©, tests lexicaux ignor√©s")
            return
        
        ssl_context = ssl.create_default_context()
        connector = aiohttp.TCPConnector(ssl=ssl_context)
        timeout = aiohttp.ClientTimeout(total=15)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            for test_query in self.test_queries:
                query_text = test_query["query"]
                description = test_query["description"]
                
                self.log("SEARCH", f"üîç Test lexical: '{query_text}' ({description})")
                
                try:
                    # Construire la requ√™te Elasticsearch optimis√©e pour Bonsai
                    search_body = {
                        "query": {
                            "bool": {
                                "must": [
                                    {"term": {"user_id": self.test_user_id}}
                                ],
                                "should": [
                                    {
                                        "multi_match": {
                                            "query": query_text,
                                            "fields": [
                                                "searchable_text^3",
                                                "primary_description^2", 
                                                "merchant_name^2",
                                                "category_name"
                                            ],
                                            "type": "best_fields",
                                            "operator": "or",
                                            "fuzziness": "AUTO"
                                        }
                                    },
                                    {
                                        "match": {
                                            "primary_description": {
                                                "query": query_text,
                                                "boost": 2.0
                                            }
                                        }
                                    }
                                ],
                                "minimum_should_match": 1
                            }
                        },
                        "size": 10,
                        "sort": [
                            {"_score": {"order": "desc"}},
                            {"transaction_date": {"order": "desc", "unmapped_type": "date"}}
                        ],
                        "highlight": {
                            "fields": {
                                "searchable_text": {},
                                "primary_description": {},
                                "merchant_name": {}
                            }
                        }
                    }
                    
                    start_time = time.time()
                    async with session.post(
                        f"{self.bonsai_url}/{self.elasticsearch_index}/_search",
                        json=search_body
                    ) as response:
                        response_time = time.time() - start_time
                        
                        if response.status == 200:
                            data = await response.json()
                            hits = data.get("hits", {}).get("hits", [])
                            total = data.get("hits", {}).get("total", {})
                            
                            if isinstance(total, dict):
                                total_count = total.get("value", 0)
                            else:
                                total_count = total
                            
                            result = {
                                "query": query_text,
                                "description": description,
                                "success": True,
                                "results_count": len(hits),
                                "total_found": total_count,
                                "response_time": response_time,
                                "max_score": max([hit["_score"] for hit in hits]) if hits else 0,
                                "avg_score": sum([hit["_score"] for hit in hits]) / len(hits) if hits else 0,
                                "sample_results": [
                                    {
                                        "score": hit["_score"],
                                        "description": hit["_source"].get("primary_description", ""),
                                        "merchant": hit["_source"].get("merchant_name", ""),
                                        "amount": hit["_source"].get("amount", 0)
                                    }
                                    for hit in hits[:3]
                                ]
                            }
                            
                            self.results["bonsai_lexical"].append(result)
                            self.log("SUCCESS", f"   ‚úÖ {len(hits)} r√©sultats, score max: {result['max_score']:.2f}, temps: {response_time:.2f}s")
                            
                        else:
                            error_result = {
                                "query": query_text,
                                "description": description,
                                "success": False,
                                "error": f"HTTP {response.status}",
                                "response_time": response_time
                            }
                            self.results["bonsai_lexical"].append(error_result)
                            self.log("ERROR", f"   ‚ùå HTTP {response.status}")
                
                except Exception as e:
                    error_result = {
                        "query": query_text,
                        "description": description,
                        "success": False,
                        "error": str(e),
                        "response_time": 0
                    }
                    self.results["bonsai_lexical"].append(error_result)
                    self.log("ERROR", f"   ‚ùå Exception: {e}")
                
                # Petit d√©lai entre les requ√™tes
                await asyncio.sleep(0.3)
    
    async def test_qdrant_semantic_search(self):
        """Teste les recherches s√©mantiques sur Qdrant."""
        if not self.qdrant_url or "your-" not in self.qdrant_url:
            self.log("WARNING", "‚ö†Ô∏è Qdrant non configur√©, tests s√©mantiques ignor√©s")
            return
        
        headers = {"api-key": self.qdrant_api_key} if self.qdrant_api_key else {}
        timeout = aiohttp.ClientTimeout(total=15)
        
        async with aiohttp.ClientSession(timeout=timeout) as session:
            for test_query in self.test_queries:
                query_text = test_query["query"]
                description = test_query["description"]
                
                self.log("SEARCH", f"üß† Test s√©mantique: '{query_text}' ({description})")
                
                try:
                    # G√©n√©rer un embedding simple (simul√© pour le test)
                    # En production, vous utiliseriez OpenAI, Cohere, ou un autre service d'embeddings
                    fake_embedding = await self.generate_fake_embedding(query_text)
                    
                    # Construire la requ√™te Qdrant
                    search_body = {
                        "vector": fake_embedding,
                        "filter": {
                            "must": [
                                {
                                    "key": "user_id",
                                    "match": {"value": self.test_user_id}
                                }
                            ]
                        },
                        "limit": 10,
                        "with_payload": True,
                        "with_vector": False
                    }
                    
                    start_time = time.time()
                    async with session.post(
                        f"{self.qdrant_url}/collections/{self.qdrant_collection}/points/search",
                        json=search_body,
                        headers=headers
                    ) as response:
                        response_time = time.time() - start_time
                        
                        if response.status == 200:
                            data = await response.json()
                            points = data.get("result", [])
                            
                            result = {
                                "query": query_text,
                                "description": description,
                                "success": True,
                                "results_count": len(points),
                                "response_time": response_time,
                                "max_score": max([point["score"] for point in points]) if points else 0,
                                "avg_score": sum([point["score"] for point in points]) / len(points) if points else 0,
                                "sample_results": [
                                    {
                                        "score": point["score"],
                                        "description": point["payload"].get("primary_description", ""),
                                        "merchant": point["payload"].get("merchant_name", ""),
                                        "amount": point["payload"].get("amount", 0)
                                    }
                                    for point in points[:3]
                                ]
                            }
                            
                            self.results["qdrant_semantic"].append(result)
                            self.log("SUCCESS", f"   ‚úÖ {len(points)} r√©sultats, score max: {result['max_score']:.2f}, temps: {response_time:.2f}s")
                            
                        else:
                            error_result = {
                                "query": query_text,
                                "description": description,
                                "success": False,
                                "error": f"HTTP {response.status}",
                                "response_time": response_time
                            }
                            self.results["qdrant_semantic"].append(error_result)
                            self.log("ERROR", f"   ‚ùå HTTP {response.status}")
                
                except Exception as e:
                    error_result = {
                        "query": query_text,
                        "description": description,
                        "success": False,
                        "error": str(e),
                        "response_time": 0
                    }
                    self.results["qdrant_semantic"].append(error_result)
                    self.log("ERROR", f"   ‚ùå Exception: {e}")
                
                # Petit d√©lai entre les requ√™tes
                await asyncio.sleep(0.3)
    
    async def generate_fake_embedding(self, text: str) -> List[float]:
        """G√©n√®re un embedding factice pour les tests (√† remplacer par un vrai service)."""
        # Ceci est un embedding factice bas√© sur un hash simple
        # En production, utilisez OpenAI, Cohere, ou un autre service d'embeddings
        
        # Cr√©er un hash bas√© sur le texte
        text_hash = hashlib.md5(text.encode()).hexdigest()
        
        # Convertir en embedding de 384 dimensions (taille courante pour les embeddings)
        embedding = []
        for i in range(0, len(text_hash), 2):
            hex_pair = text_hash[i:i+2]
            value = int(hex_pair, 16) / 255.0 - 0.5  # Normaliser entre -0.5 et 0.5
            embedding.append(value)
        
        # Compl√©ter √† 384 dimensions
        while len(embedding) < 384:
            embedding.append(0.0)
        
        return embedding[:384]
    
    async def compare_search_approaches(self) -> List[Dict[str, Any]]:
        """Compare les r√©sultats des approches lexicale et s√©mantique."""
        comparisons = []
        
        for query_data in self.test_queries:
            query = query_data["query"]
            
            # Trouver les r√©sultats correspondants
            lexical_result = next((r for r in self.results["bonsai_lexical"] if r["query"] == query), None)
            semantic_result = next((r for r in self.results["qdrant_semantic"] if r["query"] == query), None)
            
            if lexical_result or semantic_result:
                comparison = {
                    "query": query,
                    "description": query_data["description"],
                    "expected_type": query_data["expected_type"],
                    "lexical": {
                        "success": lexical_result["success"] if lexical_result else False,
                        "count": lexical_result["results_count"] if lexical_result and lexical_result["success"] else 0,
                        "max_score": lexical_result["max_score"] if lexical_result and lexical_result["success"] else 0,
                        "response_time": lexical_result["response_time"] if lexical_result else 0
                    },
                    "semantic": {
                        "success": semantic_result["success"] if semantic_result else False,
                        "count": semantic_result["results_count"] if semantic_result and semantic_result["success"] else 0,
                        "max_score": semantic_result["max_score"] if semantic_result and semantic_result["success"] else 0,
                        "response_time": semantic_result["response_time"] if semantic_result else 0
                    }
                }
                
                # D√©terminer le meilleur
                lexical_score = comparison["lexical"]["count"] * comparison["lexical"]["max_score"]
                semantic_score = comparison["semantic"]["count"] * comparison["semantic"]["max_score"]
                
                if lexical_score > semantic_score:
                    comparison["winner"] = "lexical"
                elif semantic_score > lexical_score:
                    comparison["winner"] = "semantic"
                else:
                    comparison["winner"] = "tie"
                
                comparisons.append(comparison)
                
                self.log("INFO", f"üîç '{query}': Lexical={comparison['lexical']['count']} r√©sultats, "
                               f"Semantic={comparison['semantic']['count']} r√©sultats ‚Üí Meilleur: {comparison['winner']}")
        
        return comparisons
    
    def analyze_search_performance(self, report: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse les performances de recherche."""
        analysis = {
            "lexical_performance": {},
            "semantic_performance": {},
            "overall_assessment": {},
            "recommendations": []
        }
        
        # Analyser les performances lexicales
        lexical_results = report["search_results"]["bonsai_lexical"]
        if lexical_results:
            successful_lexical = [r for r in lexical_results if r["success"]]
            analysis["lexical_performance"] = {
                "success_rate": len(successful_lexical) / len(lexical_results),
                "avg_response_time": sum(r["response_time"] for r in successful_lexical) / len(successful_lexical) if successful_lexical else 0,
                "avg_results_count": sum(r["results_count"] for r in successful_lexical) / len(successful_lexical) if successful_lexical else 0,
                "avg_max_score": sum(r["max_score"] for r in successful_lexical) / len(successful_lexical) if successful_lexical else 0
            }
        
        # Analyser les performances s√©mantiques
        semantic_results = report["search_results"]["qdrant_semantic"]
        if semantic_results:
            successful_semantic = [r for r in semantic_results if r["success"]]
            analysis["semantic_performance"] = {
                "success_rate": len(successful_semantic) / len(semantic_results),
                "avg_response_time": sum(r["response_time"] for r in successful_semantic) / len(successful_semantic) if successful_semantic else 0,
                "avg_results_count": sum(r["results_count"] for r in successful_semantic) / len(successful_semantic) if successful_semantic else 0,
                "avg_max_score": sum(r["max_score"] for r in successful_semantic) / len(successful_semantic) if successful_semantic else 0
            }
        
        # √âvaluation globale
        lexical_ok = analysis["lexical_performance"].get("success_rate", 0) > 0.7
        semantic_ok = analysis["semantic_performance"].get("success_rate", 0) > 0.7
        
        if lexical_ok and semantic_ok:
            analysis["overall_assessment"]["status"] = "excellent"
            analysis["overall_assessment"]["message"] = "Les deux approches fonctionnent bien"
            analysis["recommendations"].append("‚úÖ Vous pouvez impl√©menter une recherche hybride")
        elif lexical_ok:
            analysis["overall_assessment"]["status"] = "lexical_only"
            analysis["overall_assessment"]["message"] = "Seule la recherche lexicale fonctionne"
            analysis["recommendations"].append("üîß Corriger la recherche s√©mantique (Qdrant)")
        elif semantic_ok:
            analysis["overall_assessment"]["status"] = "semantic_only"
            analysis["overall_assessment"]["message"] = "Seule la recherche s√©mantique fonctionne"
            analysis["recommendations"].append("üîß Corriger la recherche lexicale (Bonsai)")
        else:
            analysis["overall_assessment"]["status"] = "failure"
            analysis["overall_assessment"]["message"] = "Aucune approche ne fonctionne"
            analysis["recommendations"].append("üö® V√©rifier les configurations et la connectivit√©")
        
        # Recommandations sp√©cifiques
        if analysis["lexical_performance"].get("avg_response_time", 0) > 2.0:
            analysis["recommendations"].append("‚ö° Optimiser les performances Elasticsearch")
        
        if analysis["semantic_performance"].get("avg_response_time", 0) > 3.0:
            analysis["recommendations"].append("‚ö° Optimiser les performances Qdrant")
        
        return analysis
    
    def display_validation_report(self, report: Dict[str, Any]):
        """Affiche un rapport de validation d√©taill√©."""
        print("\n" + "=" * 80)
        print("üìä RAPPORT DE VALIDATION COMPLET")
        print("=" * 80)
        
        # R√©sum√© de la configuration
        config = report["test_summary"]["configuration"]
        connectivity = report["test_summary"]["connectivity"]
        data_status = report["test_summary"]["data_status"]
        
        print(f"\nüîß CONFIGURATION:")
        print(f"   Configuration compl√®te: {'‚úÖ' if config else '‚ùå'}")
        print(f"   Bonsai accessible: {'‚úÖ' if connectivity['bonsai']['connected'] else '‚ùå'}")
        print(f"   Qdrant accessible: {'‚úÖ' if connectivity['qdrant']['connected'] else '‚ùå'}")
        
        # D√©tails de connectivit√©
        if connectivity["bonsai"]["connected"]:
            cluster_name = connectivity["bonsai"]["cluster_info"].get("name", "unknown")
            response_time = connectivity["bonsai"]["response_time"]
            print(f"   Bonsai cluster: {cluster_name} ({response_time:.2f}s)")
        
        if connectivity["qdrant"]["connected"]:
            version = connectivity["qdrant"]["version"]
            response_time = connectivity["qdrant"]["response_time"]
            print(f"   Qdrant version: {version} ({response_time:.2f}s)")
        
        # Statut des donn√©es
        print(f"\nüìä DONN√âES:")
        if data_status["bonsai_index"]["exists"]:
            doc_count = data_status["bonsai_index"]["document_count"]
            print(f"   Index Bonsai: ‚úÖ ({doc_count} documents)")
        else:
            print(f"   Index Bonsai: ‚ùå (non trouv√©)")
        
        if data_status["qdrant_collection"]["exists"]:
            point_count = data_status["qdrant_collection"]["point_count"]
            print(f"   Collection Qdrant: ‚úÖ ({point_count} points)")
        else:
            print(f"   Collection Qdrant: ‚ùå (non trouv√©e)")
        
        # R√©sultats de recherche
        print(f"\nüîç R√âSULTATS DE RECHERCHE:")
        
        lexical_results = report["search_results"]["bonsai_lexical"]
        semantic_results = report["search_results"]["qdrant_semantic"]
        
        if lexical_results:
            successful_lexical = [r for r in lexical_results if r["success"]]
            print(f"   Recherche lexicale: {len(successful_lexical)}/{len(lexical_results)} tests r√©ussis")
            
            if successful_lexical:
                avg_time = sum(r["response_time"] for r in successful_lexical) / len(successful_lexical)
                avg_results = sum(r["results_count"] for r in successful_lexical) / len(successful_lexical)
                print(f"     Temps moyen: {avg_time:.2f}s")
                print(f"     R√©sultats moyens: {avg_results:.1f}")
        
        if semantic_results:
            successful_semantic = [r for r in semantic_results if r["success"]]
            print(f"   Recherche s√©mantique: {len(successful_semantic)}/{len(semantic_results)} tests r√©ussis")
            
            if successful_semantic:
                avg_time = sum(r["response_time"] for r in successful_semantic) / len(successful_semantic)
                avg_results = sum(r["results_count"] for r in successful_semantic) / len(successful_semantic)
                print(f"     Temps moyen: {avg_time:.2f}s")
                print(f"     R√©sultats moyens: {avg_results:.1f}")
        
        # Comparaisons d√©taill√©es
        comparisons = report["search_results"]["comparison"]
        if comparisons:
            print(f"\n‚öñÔ∏è COMPARAISONS PAR REQU√äTE:")
            for comp in comparisons:
                query = comp["query"]
                winner = comp["winner"]
                lex_count = comp["lexical"]["count"]
                sem_count = comp["semantic"]["count"]
                
                winner_icon = {"lexical": "üîç", "semantic": "üß†", "tie": "ü§ù"}[winner]
                print(f"   '{query}': {winner_icon} {winner} (Lex:{lex_count}, Sem:{sem_count})")
        
        # Analyse et recommandations
        analysis = report["analysis"]
        status = analysis["overall_assessment"]["status"]
        message = analysis["overall_assessment"]["message"]
        
        print(f"\nüéØ √âVALUATION GLOBALE:")
        status_icons = {
            "excellent": "üéâ",
            "lexical_only": "‚ö†Ô∏è",
            "semantic_only": "‚ö†Ô∏è", 
            "failure": "üö®"
        }
        print(f"   {status_icons.get(status, '‚ùì')} {message}")
        
        print(f"\nüí° RECOMMANDATIONS:")
        for recommendation in analysis["recommendations"]:
            print(f"   {recommendation}")
        
        print("\n" + "=" * 80)


async def main():
    """Fonction principale pour lancer la validation."""
    print("üöÄ D√âMARRAGE DE LA VALIDATION IND√âPENDANTE")
    print("=" * 50)
    
    # Afficher la configuration charg√©e
    print(f"üìã Configuration Harena:")
    print(f"   Environnement: {settings.ENVIRONMENT}")
    print(f"   BONSAI_URL: {'‚úÖ Configur√©' if settings.BONSAI_URL else '‚ùå Non configur√©'}")
    print(f"   QDRANT_URL: {'‚úÖ Configur√©' if settings.QDRANT_URL else '‚ùå Non configur√©'}")
    print(f"   QDRANT_API_KEY: {'‚úÖ Configur√©' if settings.QDRANT_API_KEY else '‚ùå Non configur√©'}")
    print()
    
    # V√©rifier qu'au moins un service est configur√©
    if not any([settings.BONSAI_URL, settings.QDRANT_URL]):
        print("‚ùå ERREUR: Aucun service de recherche configur√©")
        print("\nüìã V√©rifiez votre fichier .env ou vos variables d'environnement:")
        print("   BONSAI_URL=https://user:pass@your-cluster.bonsaisearch.net:443")
        print("   QDRANT_URL=https://your-cluster.qdrant.io")
        print("   QDRANT_API_KEY=your-api-key")
        return 1
    
    # Cr√©er le validateur
    validator = IndependentSearchValidator()
    
    try:
        # Lancer la validation compl√®te
        report = await validator.run_complete_validation()
        
        # Sauvegarder le rapport
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"search_validation_report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nüíæ Rapport sauvegard√©: {report_file}")
        
        # Retourner le code de sortie appropri√©
        analysis = report.get("analysis", {})
        status = analysis.get("overall_assessment", {}).get("status", "failure")
        
        if status == "excellent":
            print("üéâ VALIDATION R√âUSSIE - Tous les services fonctionnent parfaitement")
            return 0
        elif status in ["lexical_only", "semantic_only"]:
            print("‚ö†Ô∏è VALIDATION PARTIELLE - Un service fonctionne")
            return 1
        else:
            print("üö® VALIDATION √âCHOU√âE - Probl√®mes critiques d√©tect√©s")
            return 2
            
    except Exception as e:
        print(f"üí• ERREUR FATALE: {e}")
        import traceback
        traceback.print_exc()
        return 3


if __name__ == "__main__":
    # Configuration pour √©viter les warnings SSL
    import warnings
    warnings.filterwarnings("ignore", category=DeprecationWarning)
    
    # Lancer la validation
    exit_code = asyncio.run(main())