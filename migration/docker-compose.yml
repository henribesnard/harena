version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: harena-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME:-harena}
      POSTGRES_USER: ${DB_USERNAME:-harena_admin}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups/postgres:/backups
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USERNAME:-harena_admin}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - harena-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: harena-redis
    restart: unless-stopped
    command: >
      redis-server
      --requirepass ${REDIS_AUTH_TOKEN}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save 60 1
      --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - harena-network

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: harena-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./backups/elasticsearch:/backups
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - harena-network

  # Backend API
  backend:
    build:
      context: .
      dockerfile: ../Dockerfile
    container_name: harena-backend
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    environment:
      # Database
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ${DB_NAME:-harena}
      DB_USERNAME: ${DB_USERNAME:-harena_admin}
      DB_PASSWORD: ${DB_PASSWORD}

      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_AUTH_TOKEN}

      # Elasticsearch
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200

      # API Configuration
      SECRET_KEY: ${SECRET_KEY}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY}
      API_HOST: 0.0.0.0
      API_PORT: 8000

      # Environment
      ENVIRONMENT: production
      LOG_LEVEL: info
    volumes:
      - ../conversation_service:/app/conversation_service
      - backend_logs:/app/logs
    ports:
      - "8000:8000"
      - "8001:8001"
    networks:
      - harena-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Backup service (cron pour backups automatiques)
  backup:
    image: alpine:latest
    container_name: harena-backup
    restart: unless-stopped
    depends_on:
      - postgres
      - elasticsearch
    volumes:
      - postgres_data:/postgres_data:ro
      - elasticsearch_data:/elasticsearch_data:ro
      - ./backups:/backups
      - ./scripts:/scripts:ro
    environment:
      - BACKUP_RETENTION_DAYS=7
      - S3_BUCKET=${BACKUP_S3_BUCKET:-}
    entrypoint: /scripts/backup_cron.sh
    networks:
      - harena-network

networks:
  harena-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  elasticsearch_data:
    driver: local
  backend_logs:
    driver: local
