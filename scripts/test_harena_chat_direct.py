"""
Test complet pour Harena : analyse des intentions sur 50+ questions
G√©n√®re un rapport markdown d√©taill√© des performances
"""

import json
import time
import requests
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass


@dataclass
class TestResult:
    """Structure pour stocker les r√©sultats de test"""
    question: str
    intent_type: str
    confidence: float
    category: str
    latency_ms: float
    success: bool
    error_message: Optional[str] = None
    performance_grade: Optional[str] = None
    efficiency_score: Optional[float] = None


class HarenaTestSuite:
    """Suite de tests pour l'API Harena"""
    
    def __init__(self, base_url: str = "http://localhost:8000/api/v1"):
        self.base_url = base_url
        self.session = requests.Session()
        self.user_id: Optional[int] = None
        self.results: List[TestResult] = []
        
    def authenticate(self, username: str, password: str) -> bool:
        """Authentifie l'utilisateur et configure la session"""
        try:
            data = f"username={username}&password={password}"
            headers = {"Content-Type": "application/x-www-form-urlencoded"}
            
            resp = self.session.post(
                f"{self.base_url}/users/auth/login", 
                data=data, 
                headers=headers
            )
            resp.raise_for_status()
            
            token = resp.json()["access_token"]
            self.session.headers.update({"Authorization": f"Bearer {token}"})
            
            # R√©cup√©ration de l'ID utilisateur
            user_resp = self.session.get(f"{self.base_url}/users/me")
            user_resp.raise_for_status()
            self.user_id = user_resp.json().get("id")
            
            print(f"‚úÖ Authentification r√©ussie - User ID: {self.user_id}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur d'authentification: {e}")
            return False
    
    def run_single_test(self, question: str) -> TestResult:
        """Ex√©cute un test sur une question donn√©e"""
        if not self.user_id:
            return TestResult(
                question=question,
                intent_type="ERROR",
                confidence=0.0,
                category="ERROR",
                latency_ms=0.0,
                success=False,
                error_message="Utilisateur non authentifi√©"
            )
        
        payload = {
            "client_info": {
                "platform": "web",
                "version": "1.0.0"
            },
            "message": question,
            "message_type": "text",
            "priority": "normal"
        }
        
        start_time = time.perf_counter()
        
        try:
            response = self.session.post(
                f"{self.base_url}/conversation/{self.user_id}",
                json=payload,
                headers={'Content-Type': 'application/json'}
            )
            
            latency_ms = (time.perf_counter() - start_time) * 1000
            
            if response.status_code != 200:
                return TestResult(
                    question=question,
                    intent_type="HTTP_ERROR",
                    confidence=0.0,
                    category="ERROR",
                    latency_ms=latency_ms,
                    success=False,
                    error_message=f"HTTP {response.status_code}"
                )
            
            data = response.json()
            intent = data.get("intent", {})
            agent_metrics = data.get("agent_metrics", {})
            
            return TestResult(
                question=question,
                intent_type=intent.get("intent_type", "UNKNOWN"),
                confidence=intent.get("confidence", 0.0),
                category=intent.get("category", "UNKNOWN"),
                latency_ms=latency_ms,
                success=True,
                performance_grade=agent_metrics.get("performance_grade"),
                efficiency_score=agent_metrics.get("efficiency_score")
            )
            
        except Exception as e:
            latency_ms = (time.perf_counter() - start_time) * 1000
            return TestResult(
                question=question,
                intent_type="EXCEPTION",
                confidence=0.0,
                category="ERROR",
                latency_ms=latency_ms,
                success=False,
                error_message=str(e)
            )
    
    def run_test_suite(self, questions: List[str]) -> None:
        """Ex√©cute la suite de tests compl√®te"""
        print(f"üöÄ D√©marrage des tests sur {len(questions)} questions...")
        
        for i, question in enumerate(questions, 1):
            print(f"üìù Test {i}/{len(questions)}: {question[:50]}...")
            result = self.run_single_test(question)
            self.results.append(result)
            
            if result.success:
                print(f"   ‚úÖ {result.intent_type} ({result.confidence:.2f}) - {result.latency_ms:.0f}ms")
            else:
                print(f"   ‚ùå {result.error_message} - {result.latency_ms:.0f}ms")
            
            # Petite pause pour ne pas surcharger l'API
            time.sleep(0.1)
    
    def generate_markdown_report(self, filename: str = "harena_test_report.md") -> None:
        """G√©n√®re un rapport d√©taill√© en markdown"""
        if not self.results:
            print("‚ùå Aucun r√©sultat √† reporter")
            return
        
        # Statistiques globales
        total_tests = len(self.results)
        successful_tests = sum(1 for r in self.results if r.success)
        success_rate = (successful_tests / total_tests) * 100
        
        avg_latency = sum(r.latency_ms for r in self.results) / total_tests
        avg_confidence = sum(r.confidence for r in self.results if r.success) / max(successful_tests, 1)
        
        # Comptage par intention
        intent_counts = {}
        category_counts = {}
        
        for result in self.results:
            if result.success:
                intent_counts[result.intent_type] = intent_counts.get(result.intent_type, 0) + 1
                category_counts[result.category] = category_counts.get(result.category, 0) + 1
        
        # G√©n√©ration du rapport
        report_content = f"""# Rapport de Test Harena Chat API

**Date de g√©n√©ration**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üìä Statistiques Globales

- **Total des tests**: {total_tests}
- **Tests r√©ussis**: {successful_tests}
- **Taux de r√©ussite**: {success_rate:.1f}%
- **Latence moyenne**: {avg_latency:.0f}ms
- **Confiance moyenne**: {avg_confidence:.2f}

## üéØ Distribution des Intentions

| Intention | Nombre | Pourcentage |
|-----------|--------|-------------|
"""
        
        for intent_type, count in sorted(intent_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / successful_tests) * 100
            report_content += f"| {intent_type} | {count} | {percentage:.1f}% |\n"
        
        report_content += f"""
## üìÇ Distribution des Cat√©gories

| Cat√©gorie | Nombre | Pourcentage |
|-----------|--------|-------------|
"""
        
        for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / successful_tests) * 100
            report_content += f"| {category} | {count} | {percentage:.1f}% |\n"
        
        report_content += """
## üìã R√©sultats D√©taill√©s

| Question | Intention | Confiance | Cat√©gorie | Latence (ms) | Status |
|----------|-----------|-----------|-----------|--------------|--------|
"""
        
        for result in self.results:
            status = "‚úÖ" if result.success else "‚ùå"
            question_short = result.question[:60] + "..." if len(result.question) > 60 else result.question
            
            report_content += f"| {question_short} | {result.intent_type} | {result.confidence:.2f} | {result.category} | {result.latency_ms:.0f} | {status} |\n"
        
        # Analyse des performances
        report_content += f"""
## ‚ö° Analyse des Performances

### Latence par Quintiles
"""
        
        latencies = sorted([r.latency_ms for r in self.results if r.success])
        if latencies:
            report_content += f"""
- **Min**: {min(latencies):.0f}ms
- **P25**: {latencies[len(latencies)//4]:.0f}ms
- **M√©diane**: {latencies[len(latencies)//2]:.0f}ms
- **P75**: {latencies[3*len(latencies)//4]:.0f}ms
- **Max**: {max(latencies):.0f}ms
"""
        
        # Erreurs et probl√®mes
        errors = [r for r in self.results if not r.success]
        if errors:
            report_content += f"""
## ‚ùå Erreurs D√©tect√©es ({len(errors)} erreurs)

| Question | Type d'Erreur | Message |
|----------|---------------|---------|
"""
            for error in errors:
                question_short = error.question[:50] + "..." if len(error.question) > 50 else error.question
                report_content += f"| {question_short} | {error.intent_type} | {error.error_message} |\n"
        
        # Recommandations
        report_content += """
## üí° Recommandations

"""
        
        if success_rate < 90:
            report_content += "- ‚ö†Ô∏è Le taux de r√©ussite est inf√©rieur √† 90%. V√©rifier la stabilit√© de l'API.\n"
        
        if avg_latency > 5000:
            report_content += "- ‚ö†Ô∏è Latence moyenne √©lev√©e (>5s). Optimiser les performances.\n"
        
        if avg_confidence < 0.8:
            report_content += "- ‚ö†Ô∏è Confiance moyenne faible (<0.8). Am√©liorer le mod√®le de classification.\n"
        
        # Sauvegarde
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"‚úÖ Rapport g√©n√©r√©: {filename}")
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration du rapport: {e}")


def get_test_questions() -> List[str]:
    """Retourne la liste des 50+ questions de test"""
    return [
        # Questions sur les virements et transferts
        "Combien ai-je fait de virements en mai ?",
        "Quels sont mes virements du mois dernier ?",
        "Peux-tu me montrer tous mes virements de juin ?",
        "Combien j'ai vir√© ce mois-ci ?",
        "Liste de mes transferts de la semaine pass√©e",
        
        # Questions sur les d√©penses
        "Combien ai-je d√©pens√© en juin ?",
        "Mes d√©penses de mai √©taient de combien ?",
        "Peux-tu calculer mes d√©penses totales ?",
        "Combien j'ai d√©pens√© chez Carrefour ?",
        "Mes achats Amazon du mois dernier",
        
        # Questions sur les entr√©es d'argent
        "Combien j'ai eu d'entr√©e d'argent en juin ?",
        "Mes revenus de mai s'√©levaient √† combien ?",
        "Peux-tu me dire mes entr√©es d'argent ?",
        "Combien j'ai re√ßu ce mois-ci ?",
        "Mes revenus de la semaine derni√®re",
        
        # Questions comparatives
        "Compare mes entr√©es et sorties d'argent en juin !",
        "Diff√©rence entre mes revenus et d√©penses de mai",
        "Est-ce que j'ai plus d√©pens√© ou gagn√© ce mois ?",
        "Balance de mes comptes ce mois",
        "Comparaison revenus/d√©penses sur 3 mois",
        
        # Questions sur des marchands sp√©cifiques
        "Combien j'ai d√©pens√© chez McDonald's ?",
        "Mes achats FNAC du trimestre",
        "D√©penses Total Station service",
        "Combien chez Leclerc ce mois ?",
        "Mes paiements Spotify de l'ann√©e",
        
        # Questions temporelles vari√©es
        "Mes transactions d'hier",
        "D√©penses de la semaine derni√®re",
        "Revenus du trimestre pass√©",
        "Transactions de ce weekend",
        "Mes op√©rations de cette ann√©e",
        
        # Questions sur les cat√©gories
        "Mes d√©penses en alimentation",
        "Combien pour les transports ce mois ?",
        "Budget loisirs du trimestre",
        "D√©penses sant√© de l'ann√©e",
        "Co√ªt des courses alimentaires",
        
        # Questions sur les montants
        "Transactions sup√©rieures √† 100‚Ç¨",
        "Petites d√©penses inf√©rieures √† 10‚Ç¨",
        "Mes gros virements (>500‚Ç¨)",
        "D√©penses entre 50 et 100‚Ç¨",
        "Transactions de moins de 5‚Ç¨",
        
        # Questions sur les comptes
        "Solde de mon compte principal",
        "Historique compte √©pargne",
        "Mouvements compte joint",
        "Transactions carte bleue",
        "Op√©rations compte courant",
        
        # Questions complexes
        "√âvolution de mes d√©penses sur 6 mois",
        "Tendance de mes revenus cette ann√©e",
        "Pr√©vision budget mois prochain",
        "Analyse de mes habitudes de consommation",
        "R√©partition de mes d√©penses par cat√©gorie",
        
        # Questions inhabituelles ou edge cases
        "Salut, comment √ßa va ?",
        "Quelle heure est-il ?",
        "Peux-tu m'aider ?",
        "123456789",
        "‚Ç¨‚Ç¨‚Ç¨ !!! ???",
        "Transaction"
    ]


def main():
    """Fonction principale"""
    # Configuration
    BASE_URL = "http://localhost:8000/api/v1"
    USERNAME = "test2@example.com"
    PASSWORD = "password123"
    
    # Initialisation de la suite de tests
    test_suite = HarenaTestSuite(BASE_URL)
    
    # Authentification
    if not test_suite.authenticate(USERNAME, PASSWORD):
        print("‚ùå Impossible de continuer sans authentification")
        return
    
    # R√©cup√©ration des questions de test
    questions = get_test_questions()
    
    # Ex√©cution des tests
    test_suite.run_test_suite(questions)
    
    # G√©n√©ration du rapport
    report_filename = f"harena_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    test_suite.generate_markdown_report(report_filename)
    
    print(f"\nüéâ Tests termin√©s ! Rapport disponible: {report_filename}")


if __name__ == "__main__":
    main()