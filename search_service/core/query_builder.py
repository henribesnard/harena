import logging
from typing import Dict, Any, List, Optional
from search_service.models.request import SearchRequest

logger = logging.getLogger(__name__)

# üî• DEBUG FORCING - Cette ligne DOIT appara√Ætre dans les logs
logger.critical("üî•üî•üî• QUERY BUILDER VERSION FINALE CORRIG√âE CHARG√âE üî•üî•üî•")

class QueryBuilder:
    """Constructeur de requ√™tes Elasticsearch - üî• VERSION FINALE CORRIG√âE AVEC DEBUG FORCING"""
    
    def __init__(self):
        logger.critical("üî• QueryBuilder.__init__() - VERSION FINALE CORRIG√âE")
        # ‚úÖ CORRECTION : Configuration des champs de recherche bas√©e sur mapping r√©el
        self.search_fields = [
            "primary_description^1.5",   # Description transaction (existe)
            "merchant_name^1.8",         # Nom marchand (existe) 
            "category_name^1.0",         # Cat√©gorie (existe)
            # ‚ùå SUPPRIM√â : "searchable_text^2.0" car potentiellement inexistant
        ]

    @staticmethod
    def _is_numeric(value: str) -> bool:
        """V√©rifie si la cha√Æne fournie repr√©sente un nombre."""
        try:
            float(value)
            return True
        except (TypeError, ValueError):
            return False

    def build_query(self, request: SearchRequest) -> Dict[str, Any]:
        """
        üî• VERSION FINALE CORRIG√âE avec s√©paration query/filter + debug forcing complet
        """
        logger.critical(f"üî• build_query() APPEL√âE - query='{request.query}', highlight={bool(request.highlight)}")
        
        # ‚úÖ CORRECTION CRITIQUE : S√©paration query et filters
        text_query_part = None
        must_filters = []
        
        # Filtre obligatoire user_id (toujours en filter)
        must_filters.append({"term": {"user_id": request.user_id}})
        logger.critical(f"üî• Ajout filtre user_id: {request.user_id}")
        
        # ‚úÖ CORRECTION : Requ√™te textuelle devient une QUERY (pas filter) 
        if request.query and request.query.strip():
            cleaned_query = request.query.strip()
            logger.critical(f"üî• REQU√äTE TEXTUELLE D√âTECT√âE: '{cleaned_query}'")
            
            if self._is_numeric(cleaned_query):
                value = float(cleaned_query)
                must_filters.append({"range": {"account_balance": {"gte": value, "lte": value}}})
                logger.critical(f"üî• Ajout filtre num√©rique account_balance: {value}")
            else:
                text_query_part = self._build_text_query(cleaned_query)
                logger.critical(f"üî• REQU√äTE DE SCORING CR√â√âE: {text_query_part}")
        else:
            logger.critical("üî• Pas de requ√™te textuelle fournie")
        
        # Filtres additionnels
        additional_filters = self._build_additional_filters(request.filters)
        must_filters.extend(additional_filters)
        logger.critical(f"üî• Total filtres ajout√©s: {len(additional_filters)} additionnels")
        
        # ‚úÖ CORRECTION CRITIQUE : Construction requ√™te avec s√©paration query/filter
        bool_query = {}
        
        if text_query_part:
            bool_query["must"] = [text_query_part]
            logger.critical("üî• SCORING QUERY AJOUT√âE DANS 'must' - va g√©n√©rer _score")
        
        if must_filters:
            if text_query_part:
                bool_query["filter"] = must_filters
                logger.critical(f"üî• {len(must_filters)} FILTRES AJOUT√âS DANS 'filter' (pas de scoring)")
            else:
                bool_query["must"] = must_filters
                logger.critical(f"üî• {len(must_filters)} FILTRES AJOUT√âS DANS 'must' (pas de query textuelle)")
        
        # Pagination : calcul de l'offset bas√© sur page/page_size
        page = getattr(request, "page", 1)
        page_size = request.page_size
        offset = (page - 1) * page_size

        # Construction requ√™te finale
        query = {
            "query": {"bool": bool_query},
            "sort": self._build_sort_criteria(request),
            "_source": self._get_source_fields(),
            "size": request.page_size,
            "from": request.offset
        }

        # ‚úÖ CORRECTION HIGHLIGHTING : Toujours ajout√© si demand√©
        if request.highlight:
            query["highlight"] = request.highlight
            logger.critical(f"üî• HIGHLIGHTING AJOUT√â √Ä LA REQU√äTE: {request.highlight}")
        else:
            logger.critical("üî• Pas de highlighting demand√©")

        logger.critical(f"üî• PAGINATION: page={page}, page_size={page_size}, offset={offset}")
        logger.critical(f"üî• REQU√äTE FINALE G√âN√âR√âE: {query}")
        
        return query

    def _build_text_query(self, query_text: str) -> Dict[str, Any]:
        """
        Construction de la requ√™te textuelle optimis√©e
        üî• VERSION FINALE CORRIG√âE - Requ√™te qui g√©n√®re _score
        """
        logger.critical(f"üî• _build_text_query('{query_text}')")
        
        terms_count = len(query_text.split())
        minimum_should_match = "50%" if terms_count >= 2 else "100%"
        
        text_query = {
            "multi_match": {
                "query": query_text,
                "fields": self.search_fields,
                "type": "best_fields",
                "fuzziness": "AUTO",
                "minimum_should_match": minimum_should_match
            }
        }
        
        logger.critical(f"üî• TEXT QUERY G√âN√âR√âE: {text_query}")
        logger.critical(f"üî• Champs de recherche utilis√©s: {self.search_fields}")
        return text_query

    def _build_sort_criteria(self, request: SearchRequest) -> List[Dict[str, Any]]:
        """
        Construction des crit√®res de tri
        üî• VERSION FINALE CORRIG√âE - Sort par score uniquement si query textuelle
        """
        sort_criteria = []
        
        # ‚úÖ CORRECTION : Si c'est une recherche textuelle NON-NUM√âRIQUE, trier par score d'abord
        if (request.query and request.query.strip() and 
            not self._is_numeric(request.query.strip())):
            sort_criteria.append({"_score": {"order": "desc"}})
            logger.critical("üî• TRI PAR _score AJOUT√â (recherche textuelle)")
        else:
            logger.critical("üî• Pas de tri par _score (pas de recherche textuelle ou requ√™te num√©rique)")
        
        # Toujours trier par date d√©croissante en second
        sort_criteria.append({"date": {"order": "desc"}})
        
        logger.critical(f"üî• CRIT√àRES DE TRI FINAUX: {sort_criteria}")
        return sort_criteria

    def _build_additional_filters(self, filters: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Construction des filtres additionnels - üî• VERSION FINALE AVEC DEBUG"""
        logger.critical(f"üî• _build_additional_filters() - {len(filters)} filtres √† traiter")
        
        filter_list: List[Dict[str, Any]] = []

        for field, value in filters.items():
            if value is None:
                continue
            
            logger.critical(f"üî• Traitement filtre: {field} = {value}")

            # --- Dictionnaire : diff√©rents types de filtres ---
            if isinstance(value, dict):
                # 1) Range : d√©tection des op√©rateurs num√©riques
                if {"gt", "gte", "lt", "lte"} & set(value.keys()):
                    filter_list.append({"range": {field: value}})
                    logger.critical(f"üî• Ajout range filter sur {field}: {value}")

                # 2) Exists
                elif value.get("exists"):
                    filter_list.append({"exists": {"field": field}})
                    logger.critical(f"üî• Ajout exists filter sur {field}")

                # 3) Wildcard
                elif "wildcard" in value:
                    field_name = self._get_filter_field_name(field)
                    pattern = value["wildcard"]
                    filter_list.append({"wildcard": {field_name: {"value": pattern}}})
                    logger.critical(f"üî• Ajout wildcard filter sur {field_name}: {pattern}")

                # 4) Prefix
                elif "prefix" in value:
                    field_name = self._get_filter_field_name(field)
                    prefix = value["prefix"]
                    filter_list.append({"prefix": {field_name: prefix}})
                    logger.critical(f"üî• Ajout prefix filter sur {field_name}: {prefix}")

                # 5) Regexp
                elif "regexp" in value:
                    field_name = self._get_filter_field_name(field)
                    regex = value["regexp"]
                    filter_list.append({"regexp": {field_name: regex}})
                    logger.critical(f"üî• Ajout regexp filter sur {field_name}: {regex}")

                # 6) Term / Terms explicit
                elif "term" in value:
                    field_name = self._get_filter_field_name(field)
                    filter_list.append({"term": {field_name: value["term"]}})
                    logger.critical(f"üî• Ajout explicit term filter sur {field_name}: {value['term']}")

                elif "terms" in value:
                    field_name = self._get_filter_field_name(field)
                    filter_list.append({"terms": {field_name: value["terms"]}})
                    logger.critical(f"üî• Ajout explicit terms filter sur {field_name}: {len(value['terms'])} values")

                else:
                    # Filtre inconnu => erreur claire
                    msg = f"Unsupported filter type for field '{field}': {value}"
                    logger.error(f"üî• ERREUR: {msg}")
                    raise ValueError(msg)

            # --- Liste : terms ---
            elif isinstance(value, list):
                field_name = self._get_filter_field_name(field)
                filter_list.append({"terms": {field_name: value}})
                logger.critical(f"üî• Ajout terms filter sur {field_name}: {len(value)} values")

            # --- Valeur simple : term ---
            else:
                field_name = self._get_filter_field_name(field)
                filter_list.append({"term": {field_name: value}})
                logger.critical(f"üî• Ajout term filter sur {field_name}: {value}")

        logger.critical(f"üî• FILTRES FINAUX G√âN√âR√âS: {len(filter_list)} filtres")
        return filter_list
    
    def _get_filter_field_name(self, field: str) -> str:
        """
        D√©termine le nom de champ correct pour les filtres
        Ajoute .keyword pour les champs textuels si n√©cessaire
        """
        # Champs qui n√©cessitent .keyword pour les filtres exacts
        keyword_fields = {
            'category_name', 'merchant_name', 'operation_type',
            'currency_code', 'transaction_type', 'weekday',
            'account_name', 'account_type', 'account_currency'
        }
        
        field_name = f"{field}.keyword" if field in keyword_fields else field
        logger.critical(f"üî• Nom de champ pour filtre: {field} -> {field_name}")
        return field_name
    
    def _get_source_fields(self) -> List[str]:
        """D√©finit les champs √† retourner dans les r√©sultats"""
        source_fields = [
            "transaction_id", "user_id", "account_id",
            "account_name", "account_type", "account_balance", "account_currency",
            "amount", "amount_abs", "currency_code", "transaction_type",
            "date", "month_year", "weekday",
            "primary_description", "merchant_name", "category_name", "operation_type"
        ]
        logger.critical(f"üî• Source fields d√©finis: {len(source_fields)} champs")
        return source_fields
    
    def build_aggregation_query(
        self, request: SearchRequest, aggregation: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Construction d'une requ√™te avec agr√©gations Elasticsearch natives.
        üî• VERSION FINALE CORRIG√âE - Support des deux formats avec debug
        """
        logger.critical(f"üî• build_aggregation_query() APPEL√âE")
        
        base_query = self.build_query(request)

        if not aggregation:
            logger.critical("üî• Pas d'agr√©gations fournies")
            return base_query

        aggregations: Dict[str, Any] = {}

        # ‚úÖ NOUVEAU : D√©tection et traitement du format Elasticsearch natif
        if self._is_elasticsearch_native_format(aggregation):
            logger.critical("üî• Format d'agr√©gation Elasticsearch natif d√©tect√©")
            # Validation et passage direct des agr√©gations
            validated_aggs = self._validate_elasticsearch_aggregations(aggregation)
            aggregations = validated_aggs
        
        # ‚úÖ ANCIEN : Support format abstrait pour compatibilit√© arri√®re
        else:
            logger.critical("üî• Format d'agr√©gation abstrait legacy d√©tect√©")
            group_by = aggregation.get("group_by") or []
            metrics = aggregation.get("metrics") or []

            if group_by:
                for field in group_by:
                    field_name = self._get_filter_field_name(field)
                    agg_def: Dict[str, Any] = {
                        "terms": {"field": field_name, "size": 10}
                    }
                    sub_aggs: Dict[str, Any] = {}
                    if "sum" in metrics:
                        sub_aggs["amount_sum"] = {"sum": {"field": "amount"}}
                    if sub_aggs:
                        agg_def["aggs"] = sub_aggs
                    aggregations[f"{field}_terms"] = agg_def
            elif "sum" in metrics:
                aggregations["amount_sum"] = {"sum": {"field": "amount"}}

        # Ajouter les agr√©gations √† la requ√™te finale
        if aggregations:
            base_query["aggs"] = aggregations
            logger.critical(f"üî• Ajout de {len(aggregations)} agr√©gations: {list(aggregations.keys())}")
            if getattr(request, "aggregation_only", False):
                base_query["size"] = 0
                logger.critical("üî• Requ√™te aggregation-only: size = 0")
            else:
                base_query["size"] = request.page_size
                logger.critical(f"üî• Requ√™te avec agr√©gations + r√©sultats: size = {request.page_size}")
        else:
            logger.critical("üî• Aucune agr√©gation valide g√©n√©r√©e")

        return base_query

    def _is_elasticsearch_native_format(self, aggregation: Dict[str, Any]) -> bool:
        """
        D√©tecte si les agr√©gations sont au format Elasticsearch natif.
        """
        # Si contient les cl√©s abstraites, c'est l'ancien format
        abstract_keys = {"group_by", "metrics", "types"}
        if any(key in aggregation for key in abstract_keys):
            return False
        
        # V√©rifier que c'est bien du format Elasticsearch natif
        elasticsearch_agg_types = {
            # M√©triques simples
            "sum", "avg", "min", "max", "value_count", "cardinality",
            "stats", "extended_stats", "percentiles", "percentile_ranks",
            
            # Buckets
            "terms", "date_histogram", "histogram", "range", "date_range",
            "filters", "filter", "missing", "nested", "reverse_nested",
            "global", "sampler", "diversified_sampler"
        }
        
        # V√©rifier chaque agr√©gation
        for agg_name, agg_def in aggregation.items():
            if not isinstance(agg_def, dict):
                continue
                
            # Chercher un type d'agr√©gation ES valide au niveau racine
            agg_types_found = set(agg_def.keys()) & elasticsearch_agg_types
            if agg_types_found:
                return True
                
            # V√©rifier les sous-agr√©gations (aggs)
            if "aggs" in agg_def and isinstance(agg_def["aggs"], dict):
                return True
        
        return False

    def _validate_elasticsearch_aggregations(self, aggregation: Dict[str, Any]) -> Dict[str, Any]:
        """
        Valide et nettoie les agr√©gations Elasticsearch natives.
        """
        # Champs autoris√©s pour les agr√©gations
        allowed_fields = {
            "amount", "amount_abs", "date", "transaction_id", "user_id", "account_id",
            "currency_code", "transaction_type", "operation_type", "category_name",
            "merchant_name", "primary_description", "month_year", "weekday",
            "account_name", "account_type", "account_balance", "account_currency"
        }
        
        validated = {}
        
        for agg_name, agg_def in aggregation.items():
            # Validation nom agr√©gation (pas d'injection)
            if not isinstance(agg_name, str) or len(agg_name) > 100:
                logger.warning(f"Invalid aggregation name: {agg_name}")
                continue
                
            if not isinstance(agg_def, dict):
                logger.warning(f"Invalid aggregation definition for {agg_name}")
                continue
                
            # Validation r√©cursive de la d√©finition
            validated_def = self._validate_aggregation_definition(agg_def, allowed_fields)
            if validated_def:
                validated[agg_name] = validated_def
        
        logger.critical(f"üî• Agr√©gations valid√©es: {list(validated.keys())}")
        return validated

    def _validate_aggregation_definition(self, agg_def: Dict[str, Any], allowed_fields: set) -> Optional[Dict[str, Any]]:
        """Valide r√©cursivement une d√©finition d'agr√©gation."""
        validated = {}
        
        for key, value in agg_def.items():
            # Cl√© 'field' - valider que le champ existe
            if key == "field" and isinstance(value, str):
                # Retirer .keyword pour la validation
                field_name = value.replace(".keyword", "")
                if field_name in allowed_fields:
                    validated[key] = value
                else:
                    logger.warning(f"Field not allowed in aggregation: {value}")
                    return None  # Rejeter toute l'agr√©gation
            
            # Cl√© 'aggs' - validation r√©cursive
            elif key == "aggs" and isinstance(value, dict):
                sub_aggs = {}
                for sub_name, sub_def in value.items():
                    validated_sub = self._validate_aggregation_definition(sub_def, allowed_fields)
                    if validated_sub:
                        sub_aggs[sub_name] = validated_sub
                if sub_aggs:
                    validated[key] = sub_aggs
            
            # Autres cl√©s - passage direct avec validation basique
            else:
                # Limiter les valeurs num√©riques
                if isinstance(value, (int, float)):
                    if -1000000 <= value <= 1000000:  # Limites raisonnables
                        validated[key] = value
                    else:
                        logger.warning(f"Numeric value out of range: {value}")
                        return None
                
                # Strings courtes seulement
                elif isinstance(value, str) and len(value) <= 100:
                    validated[key] = value
                
                # Dictionnaires et listes - passage direct
                elif isinstance(value, (dict, list)):
                    validated[key] = value
                
                else:
                    logger.warning(f"Invalid value type for key {key}: {type(value)}")
                    return None
        
        return validated if validated else None