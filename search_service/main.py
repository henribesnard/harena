"""
Service de recherche Harena - Point d'entr√©e principal (VERSION ROBUSTE).

Ce module configure et d√©marre le service de recherche hybride combinant
Elasticsearch (Bonsai) pour la recherche lexicale et Qdrant pour la recherche s√©mantique.

Version simplifi√©e et robuste pour Heroku avec gestion d'erreur am√©lior√©e.
"""

import asyncio
import logging
import os
import sys
import time
from contextlib import asynccontextmanager
from datetime import datetime
from typing import Dict, Any, Optional

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# Configuration du logging avant les autres imports
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(name)s] - %(levelname)s - %(module)s:%(lineno)d - %(message)s',
    stream=sys.stdout
)

logger = logging.getLogger("search_service.main")

# ==================== VARIABLES GLOBALES ====================

# Clients principaux
elastic_client = None
qdrant_client = None

# Services IA
embedding_service = None
reranker_service = None

# Utilitaires
search_cache = None
metrics_collector = None

# Diagnostics
startup_diagnostics = {}
startup_time = None
initialization_errors = []

# ==================== FONCTIONS UTILITAIRES ====================

def log_startup_banner():
    """Affiche la banni√®re de d√©marrage."""
    print("=" * 100)
    print("üîç HARENA SEARCH SERVICE - D√âMARRAGE ROBUSTE")
    print("=" * 100)
    print(f"üïê Heure de d√©marrage: {datetime.now().isoformat()}")
    print(f"üêç Python: {sys.version}")
    print("=" * 100)

def check_environment_variables():
    """V√©rifie les variables d'environnement critiques."""
    logger.info("üìã V√©rification des variables d'environnement...")
    
    env_status = {
        "BONSAI_URL": bool(os.environ.get("BONSAI_URL")),
        "QDRANT_URL": bool(os.environ.get("QDRANT_URL")),
        "QDRANT_API_KEY": bool(os.environ.get("QDRANT_API_KEY")),
        "OPENAI_API_KEY": bool(os.environ.get("OPENAI_API_KEY")),
        "COHERE_KEY": bool(os.environ.get("COHERE_KEY")),
    }
    
    for var, present in env_status.items():
        status_icon = "‚úÖ" if present else "‚ùå"
        logger.info(f"   {status_icon} {var}: {'Configur√©' if present else 'Manquant'}")
    
    critical_missing = []
    if not env_status["BONSAI_URL"]:
        critical_missing.append("BONSAI_URL")
    if not env_status["QDRANT_URL"]:
        critical_missing.append("QDRANT_URL")
    
    if critical_missing:
        logger.warning(f"‚ö†Ô∏è Variables critiques manquantes: {critical_missing}")
        logger.warning("üí° Le service d√©marrera en mode d√©grad√©")
    
    return env_status

# ==================== INITIALISATION DES CLIENTS ====================

async def safe_initialize_elasticsearch() -> Optional[Any]:
    """Initialise Elasticsearch de mani√®re s√©curis√©e avec timeout."""
    global elastic_client
    
    logger.info("üîç Initialisation d'Elasticsearch...")
    
    try:
        # Import avec gestion d'erreur
        try:
            from search_service.storage.elastic_client_hybrid import HybridElasticClient
            from config_service.config import settings
        except ImportError as e:
            logger.error(f"‚ùå Import Elasticsearch √©chou√©: {e}")
            initialization_errors.append(f"Elasticsearch import: {e}")
            return None
        
        # V√©rification de la configuration
        if not settings.BONSAI_URL:
            logger.warning("‚ö†Ô∏è BONSAI_URL non configur√©e - Elasticsearch ignor√©")
            return None
        
        # Initialisation avec timeout strict
        logger.info("üîÑ Cr√©ation du client Elasticsearch...")
        elastic_client = HybridElasticClient()
        
        logger.info("üîÑ Initialisation du client Elasticsearch...")
        try:
            await asyncio.wait_for(elastic_client.initialize(), timeout=45.0)
        except asyncio.TimeoutError:
            logger.error("‚ùå Timeout (45s) lors de l'initialisation d'Elasticsearch")
            initialization_errors.append("Elasticsearch timeout during initialization")
            return None
        
        # V√©rification de l'√©tat
        if hasattr(elastic_client, '_initialized') and elastic_client._initialized:
            logger.info("‚úÖ Elasticsearch initialis√© avec succ√®s")
            
            # Test de sant√© rapide
            try:
                if hasattr(elastic_client, 'is_healthy'):
                    is_healthy = await asyncio.wait_for(elastic_client.is_healthy(), timeout=10.0)
                    if is_healthy:
                        logger.info("‚úÖ Elasticsearch est en bonne sant√©")
                    else:
                        logger.warning("‚ö†Ô∏è Elasticsearch initialis√© mais pas en bonne sant√©")
            except Exception as health_error:
                logger.warning(f"‚ö†Ô∏è Test de sant√© Elasticsearch √©chou√©: {health_error}")
            
            return elastic_client
        else:
            logger.error("‚ùå Elasticsearch non initialis√© (flag _initialized absent/false)")
            initialization_errors.append("Elasticsearch initialization flag not set")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'initialisation d'Elasticsearch: {e}")
        initialization_errors.append(f"Elasticsearch error: {e}")
        return None

async def safe_initialize_qdrant() -> Optional[Any]:
    """Initialise Qdrant de mani√®re s√©curis√©e avec timeout."""
    global qdrant_client
    
    logger.info("üéØ Initialisation de Qdrant...")
    
    try:
        # Import avec gestion d'erreur
        try:
            from search_service.storage.qdrant_client import QdrantClient
            from config_service.config import settings
        except ImportError as e:
            logger.error(f"‚ùå Import Qdrant √©chou√©: {e}")
            initialization_errors.append(f"Qdrant import: {e}")
            return None
        
        # V√©rification de la configuration
        if not settings.QDRANT_URL:
            logger.warning("‚ö†Ô∏è QDRANT_URL non configur√©e - Qdrant ignor√©")
            return None
        
        # Initialisation avec timeout strict
        logger.info("üîÑ Cr√©ation du client Qdrant...")
        qdrant_client = QdrantClient()
        
        logger.info("üîÑ Initialisation du client Qdrant...")
        try:
            await asyncio.wait_for(qdrant_client.initialize(), timeout=45.0)
        except asyncio.TimeoutError:
            logger.error("‚ùå Timeout (45s) lors de l'initialisation de Qdrant")
            initialization_errors.append("Qdrant timeout during initialization")
            return None
        
        # V√©rification de l'√©tat
        if hasattr(qdrant_client, '_initialized') and qdrant_client._initialized:
            logger.info("‚úÖ Qdrant initialis√© avec succ√®s")
            
            # Test de sant√© rapide
            try:
                if hasattr(qdrant_client, 'get_collections'):
                    collections = await asyncio.wait_for(qdrant_client.get_collections(), timeout=10.0)
                    logger.info(f"‚úÖ Qdrant - Collections disponibles: {len(collections) if collections else 0}")
            except Exception as health_error:
                logger.warning(f"‚ö†Ô∏è Test de sant√© Qdrant √©chou√©: {health_error}")
            
            return qdrant_client
        else:
            logger.error("‚ùå Qdrant non initialis√© (flag _initialized absent/false)")
            initialization_errors.append("Qdrant initialization flag not set")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'initialisation de Qdrant: {e}")
        initialization_errors.append(f"Qdrant error: {e}")
        return None

async def create_qdrant_collections():
    """Cr√©e les collections Qdrant si n√©cessaire."""
    if not qdrant_client or not hasattr(qdrant_client, '_initialized') or not qdrant_client._initialized:
        logger.info("‚ö†Ô∏è Qdrant non disponible - cr√©ation de collections ignor√©e")
        return False
    
    logger.info("üèóÔ∏è V√©rification/cr√©ation des collections Qdrant...")
    
    try:
        # Import de la fonction de cr√©ation
        try:
            from search_service.utils.initialization import create_collections_if_needed
        except ImportError:
            logger.warning("‚ö†Ô∏è Fonction create_collections_if_needed non disponible")
            return False
        
        # Cr√©ation avec timeout
        success = await asyncio.wait_for(
            create_collections_if_needed(qdrant_client), 
            timeout=30.0
        )
        
        if success:
            logger.info("‚úÖ Collections Qdrant pr√™tes")
        else:
            logger.warning("‚ö†Ô∏è Probl√®me avec les collections Qdrant")
        
        return success
        
    except asyncio.TimeoutError:
        logger.error("‚ùå Timeout lors de la cr√©ation des collections Qdrant")
        return False
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la cr√©ation des collections: {e}")
        return False

# ==================== INITIALISATION DES SERVICES OPTIONNELS ====================

def safe_initialize_ai_services() -> Dict[str, bool]:
    """Initialise les services IA de mani√®re s√©curis√©e."""
    global embedding_service, reranker_service
    
    logger.info("ü§ñ Initialisation des services IA...")
    
    results = {
        "embedding_service": False,
        "reranker_service": False
    }
    
    # Service d'embeddings
    try:
        from search_service.core.embeddings import EmbeddingService
        embedding_service = EmbeddingService()
        results["embedding_service"] = True
        logger.info("‚úÖ Service d'embeddings initialis√©")
    except ImportError:
        logger.info("‚ÑπÔ∏è Service d'embeddings non disponible (module non trouv√©)")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur service d'embeddings: {e}")
        embedding_service = None
    
    # Service de reranking
    try:
        from search_service.core.reranker import RerankerService
        reranker_service = RerankerService()
        results["reranker_service"] = True
        logger.info("‚úÖ Service de reranking initialis√©")
    except ImportError:
        logger.info("‚ÑπÔ∏è Service de reranking non disponible (module non trouv√©)")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur service de reranking: {e}")
        reranker_service = None
    
    return results

def safe_initialize_utilities() -> Dict[str, bool]:
    """Initialise les utilitaires de mani√®re s√©curis√©e."""
    global search_cache, metrics_collector
    
    logger.info("üõ†Ô∏è Initialisation des utilitaires...")
    
    results = {
        "cache": False,
        "metrics": False
    }
    
    # Cache de recherche
    try:
        from search_service.utils.cache import SearchCache
        search_cache = SearchCache()
        results["cache"] = True
        logger.info("‚úÖ Cache de recherche initialis√©")
    except ImportError:
        logger.info("‚ÑπÔ∏è Cache de recherche non disponible (module non trouv√©)")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur cache de recherche: {e}")
        search_cache = None
    
    # Collecteur de m√©triques (placeholder)
    try:
        # Pour l'instant, on simule le collecteur de m√©triques
        metrics_collector = None  # Sera impl√©ment√© plus tard
        logger.info("‚ÑπÔ∏è Collecteur de m√©triques d√©sactiv√© (non impl√©ment√©)")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur collecteur de m√©triques: {e}")
        metrics_collector = None
    
    return results

# ==================== INJECTION DES D√âPENDANCES ====================

def force_inject_dependencies() -> bool:
    """Force l'injection des d√©pendances dans les routes."""
    logger.info("üîó Injection forc√©e des d√©pendances...")
    
    try:
        # Import du module routes
        try:
            import search_service.api.routes as routes
            logger.info("‚úÖ Module routes import√© avec succ√®s")
        except ImportError as e:
            logger.error(f"‚ùå Impossible d'importer le module routes: {e}")
            initialization_errors.append(f"Routes import failed: {e}")
            return False
        
        # Injection avec validation
        injection_results = {}
        
        # Clients principaux
        routes.elastic_client = elastic_client
        injection_results["elasticsearch"] = elastic_client is not None
        logger.info(f"{'‚úÖ' if elastic_client else '‚ö†Ô∏è'} elastic_client inject√©: {type(elastic_client).__name__ if elastic_client else 'None'}")
        
        routes.qdrant_client = qdrant_client
        injection_results["qdrant"] = qdrant_client is not None
        logger.info(f"{'‚úÖ' if qdrant_client else '‚ö†Ô∏è'} qdrant_client inject√©: {type(qdrant_client).__name__ if qdrant_client else 'None'}")
        
        # Services IA
        routes.embedding_service = embedding_service
        injection_results["embeddings"] = embedding_service is not None
        logger.info(f"{'‚úÖ' if embedding_service else '‚ÑπÔ∏è'} embedding_service inject√©: {type(embedding_service).__name__ if embedding_service else 'None'}")
        
        routes.reranker_service = reranker_service
        injection_results["reranking"] = reranker_service is not None
        logger.info(f"{'‚úÖ' if reranker_service else '‚ÑπÔ∏è'} reranker_service inject√©: {type(reranker_service).__name__ if reranker_service else 'None'}")
        
        # Utilitaires
        routes.search_cache = search_cache
        injection_results["cache"] = search_cache is not None
        logger.info(f"{'‚úÖ' if search_cache else '‚ÑπÔ∏è'} search_cache inject√©: {type(search_cache).__name__ if search_cache else 'None'}")
        
        routes.metrics_collector = metrics_collector
        injection_results["metrics"] = metrics_collector is not None
        logger.info(f"{'‚ÑπÔ∏è'} metrics_collector inject√©: {type(metrics_collector).__name__ if metrics_collector else 'None'}")
        
        # V√©rification post-injection
        verification_passed = True
        required_attrs = ['elastic_client', 'qdrant_client', 'embedding_service', 'reranker_service', 'search_cache', 'metrics_collector']
        
        for attr in required_attrs:
            if not hasattr(routes, attr):
                logger.error(f"‚ùå Attribut {attr} manquant apr√®s injection")
                verification_passed = False
            else:
                logger.debug(f"‚úÖ Attribut {attr} pr√©sent")
        
        # Compter les services critiques inject√©s
        critical_services = sum([
            injection_results.get("elasticsearch", False),
            injection_results.get("qdrant", False)
        ])
        
        total_services = sum(injection_results.values())
        
        logger.info(f"üìä R√©sum√© injection: {total_services}/6 services inject√©s ({critical_services}/2 critiques)")
        
        if critical_services == 0:
            logger.error("‚ùå Aucun service critique inject√© - fonctionnalit√© limit√©e")
            return False
        elif critical_services == 1:
            logger.warning("‚ö†Ô∏è Un seul service critique inject√© - mode d√©grad√©")
            return True
        else:
            logger.info("‚úÖ Tous les services critiques inject√©s - mode optimal")
            return True
            
    except Exception as e:
        logger.error(f"üí• Erreur critique lors de l'injection: {e}")
        initialization_errors.append(f"Injection failed: {e}")
        
        # Tentative d'injection de fallback
        try:
            import search_service.api.routes as routes
            routes.elastic_client = None
            routes.qdrant_client = None
            routes.embedding_service = None
            routes.reranker_service = None
            routes.search_cache = None
            routes.metrics_collector = None
            logger.warning("‚ö†Ô∏è Injection de fallback (None) effectu√©e")
        except Exception as fallback_error:
            logger.error(f"üí• Impossible d'effectuer l'injection de fallback: {fallback_error}")
        
        return False

# ==================== CYCLE DE VIE DE L'APPLICATION ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestionnaire du cycle de vie de l'application."""
    global startup_time, startup_diagnostics
    
    try:
        # === PHASE DE D√âMARRAGE ===
        log_startup_banner()
        startup_time = time.time()
        
        logger.info("üöÄ D√©but de l'initialisation robuste...")
        
        # 1. V√©rification de l'environnement
        env_status = check_environment_variables()
        
        # 2. Initialisation parall√®le des clients avec timeout global
        logger.info("üîÑ Initialisation des clients en parall√®le...")
        
        try:
            # Lancer les deux initializations en parall√®le avec timeout global
            elasticsearch_task = asyncio.create_task(safe_initialize_elasticsearch())
            qdrant_task = asyncio.create_task(safe_initialize_qdrant())
            
            # Attendre les deux avec timeout global
            done, pending = await asyncio.wait_for(
                asyncio.wait([elasticsearch_task, qdrant_task], return_when=asyncio.ALL_COMPLETED),
                timeout=90.0  # Timeout global de 90 secondes
            )
            
            # R√©cup√©rer les r√©sultats
            elasticsearch_result = elasticsearch_task.result() if elasticsearch_task.done() else None
            qdrant_result = qdrant_task.result() if qdrant_task.done() else None
            
        except asyncio.TimeoutError:
            logger.error("‚ùå Timeout global (90s) lors de l'initialisation des clients")
            initialization_errors.append("Global client initialization timeout")
            elasticsearch_result = None
            qdrant_result = None
        
        # Assigner les r√©sultats aux variables globales
        global elastic_client, qdrant_client
        elastic_client = elasticsearch_result
        qdrant_client = qdrant_result
        
        # 3. V√©rifier qu'au moins un service fonctionne
        services_ready = sum([
            elastic_client is not None,
            qdrant_client is not None
        ])
        
        if services_ready == 0:
            logger.error("üö® AUCUN service de recherche disponible")
            logger.error("üí° Le service d√©marrera quand m√™me pour permettre le debugging")
        elif services_ready == 1:
            logger.warning("‚ö†Ô∏è Un seul service de recherche disponible - mode d√©grad√©")
        else:
            logger.info("üéâ Tous les services de recherche disponibles - mode optimal")
        
        # 4. Cr√©ation des collections Qdrant si disponible
        collections_ready = False
        if qdrant_client:
            collections_ready = await create_qdrant_collections()
        
        # 5. Initialisation des services optionnels
        ai_services_status = safe_initialize_ai_services()
        utilities_status = safe_initialize_utilities()
        
        # 6. Injection des d√©pendances
        injection_success = force_inject_dependencies()
        
        # 7. Calcul du temps d'initialisation
        initialization_time = time.time() - startup_time
        
        # 8. R√©sum√© final
        startup_diagnostics = {
            "startup_time": startup_time,
            "initialization_time": initialization_time,
            "environment": env_status,
            "services": {
                "elasticsearch": elastic_client is not None,
                "qdrant": qdrant_client is not None,
                "collections_ready": collections_ready,
                "total_ready": services_ready
            },
            "ai_services": ai_services_status,
            "utilities": utilities_status,
            "injection_success": injection_success,
            "initialization_errors": initialization_errors,
            "status": "SUCCESS" if services_ready > 0 and injection_success else "DEGRADED"
        }
        
        # Log du r√©sum√© final
        logger.info("=" * 60)
        logger.info("üìä R√âSUM√â DE L'INITIALISATION")
        logger.info("=" * 60)
        logger.info(f"‚è±Ô∏è Temps d'initialisation: {initialization_time:.2f}s")
        logger.info(f"üîç Elasticsearch: {'‚úÖ Pr√™t' if elastic_client else '‚ùå Indisponible'}")
        logger.info(f"üéØ Qdrant: {'‚úÖ Pr√™t' if qdrant_client else '‚ùå Indisponible'}")
        logger.info(f"üèóÔ∏è Collections: {'‚úÖ Pr√™tes' if collections_ready else '‚ö†Ô∏è Non cr√©√©es'}")
        logger.info(f"ü§ñ Services IA: {sum(ai_services_status.values())}/2")
        logger.info(f"üõ†Ô∏è Utilitaires: {sum(utilities_status.values())}/2")
        logger.info(f"üîó Injection: {'‚úÖ R√©ussie' if injection_success else '‚ùå √âchou√©e'}")
        logger.info(f"üéØ Statut global: {startup_diagnostics['status']}")
        
        if initialization_errors:
            logger.warning("‚ö†Ô∏è Erreurs d'initialisation:")
            for error in initialization_errors:
                logger.warning(f"   - {error}")
        
        logger.info("=" * 60)
        logger.info("üéâ Service de recherche Harena d√©marr√©")
        logger.info("=" * 60)
        
        # === PHASE D'EX√âCUTION ===
        yield
        
    except Exception as e:
        logger.error(f"üí• Erreur critique durant l'initialisation: {e}", exc_info=True)
        initialization_errors.append(f"Critical startup error: {e}")
        
        # Cr√©er un diagnostic d'urgence
        startup_diagnostics = {
            "status": "FAILED",
            "error": str(e),
            "initialization_time": time.time() - startup_time if startup_time else 0,
            "initialization_errors": initialization_errors
        }
        
        # Continuer le d√©marrage malgr√© l'erreur pour permettre le debugging
        yield
    
    finally:
        # === PHASE D'ARR√äT ===
        logger.info("üîÑ Arr√™t du service de recherche...")
        
        # Liste des t√¢ches de nettoyage
        cleanup_tasks = []
        
        if elastic_client and hasattr(elastic_client, 'close'):
            cleanup_tasks.append(("Elasticsearch", elastic_client.close()))
        
        if qdrant_client and hasattr(qdrant_client, 'close'):
            cleanup_tasks.append(("Qdrant", qdrant_client.close()))
        
        # Ex√©cution du nettoyage avec timeout individuel
        for service_name, cleanup_coro in cleanup_tasks:
            try:
                await asyncio.wait_for(cleanup_coro, timeout=10.0)
                logger.info(f"‚úÖ {service_name} ferm√© proprement")
            except asyncio.TimeoutError:
                logger.warning(f"‚ö†Ô∏è Timeout lors de la fermeture de {service_name}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur fermeture {service_name}: {e}")
        
        logger.info("üèÅ Service de recherche arr√™t√© proprement")

# ==================== CR√âATION DE L'APPLICATION ====================

def create_app() -> FastAPI:
    """Cr√©e l'application FastAPI avec la configuration robuste."""
    
    logger.info("üèóÔ∏è Cr√©ation de l'application FastAPI...")
    
    # Cr√©ation de l'app avec le cycle de vie robuste
    app = FastAPI(
        title="Harena Search Service",
        description="Service de recherche hybride pour Harena Finance (Version Robuste)",
        version="1.0.0",
        lifespan=lifespan
    )
    
    # Configuration CORS
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # ==================== ROUTES ESSENTIELLES ====================
    
    @app.get("/health")
    async def health_check():
        """Check de sant√© complet."""
        current_time = time.time()
        uptime = current_time - startup_time if startup_time else 0
        
        # Statut des services
        services_status = {
            "elasticsearch": elastic_client is not None and hasattr(elastic_client, '_initialized') and elastic_client._initialized,
            "qdrant": qdrant_client is not None and hasattr(qdrant_client, '_initialized') and qdrant_client._initialized,
            "embedding_service": embedding_service is not None,
            "search_cache": search_cache is not None
        }
        
        healthy_services = sum(services_status.values())
        core_services = sum([services_status["elasticsearch"], services_status["qdrant"]])
        
        overall_status = "healthy" if core_services > 0 else "degraded"
        
        return {
            "status": overall_status,
            "service": "search_service",
            "timestamp": current_time,
            "uptime_seconds": uptime,
            "services": {
                "total_healthy": healthy_services,
                "core_services": core_services,
                "details": services_status
            },
            "initialization": {
                "status": startup_diagnostics.get("status", "UNKNOWN"),
                "initialization_time": startup_diagnostics.get("initialization_time", 0),
                "errors_count": len(initialization_errors)
            }
        }
    
    @app.get("/diagnostics")
    async def full_diagnostics():
        """Diagnostics complets du service."""
        return {
            "service": "search_service",
            "timestamp": time.time(),
            "startup_diagnostics": startup_diagnostics,
            "initialization_errors": initialization_errors,
            "runtime_info": {
                "uptime_seconds": time.time() - startup_time if startup_time else 0,
                "clients_status": {
                    "elasticsearch": {
                        "available": elastic_client is not None,
                        "initialized": elastic_client is not None and hasattr(elastic_client, '_initialized') and elastic_client._initialized,
                        "type": type(elastic_client).__name__ if elastic_client else None
                    },
                    "qdrant": {
                        "available": qdrant_client is not None,
                        "initialized": qdrant_client is not None and hasattr(qdrant_client, '_initialized') and qdrant_client._initialized,
                        "type": type(qdrant_client).__name__ if qdrant_client else None
                    }
                }
            }
        }
    
    @app.get("/")
    async def root():
        """Endpoint racine avec informations de base."""
        return {
            "service": "Harena Search Service",
            "version": "1.0.0",
            "status": "online",
            "documentation": "/docs",
            "health_check": "/health",
            "diagnostics": "/diagnostics"
        }
    
    # ==================== ROUTES PRINCIPALES ====================
    
    # Tentative d'ajout des routes principales
    try:
        from search_service.api.routes import router
        app.include_router(router, prefix="/api/v1")
        logger.info("‚úÖ Routes principales ajout√©es avec succ√®s")
        
        # Note: Routes WebSocket non impl√©ment√©es pour le moment
        logger.info("‚ÑπÔ∏è Routes WebSocket non impl√©ment√©es")
        
    except Exception as e:
        logger.error(f"‚ùå Impossible d'ajouter les routes principales: {e}")
        initialization_errors.append(f"Routes loading failed: {e}")
        
        # Route de diagnostic d'urgence
        @app.get("/emergency-diagnostics")
        async def emergency_diagnostics():
            return {
                "error": "Routes principales indisponibles",
                "reason": str(e),
                "fallback_mode": True,
                "startup_diagnostics": startup_diagnostics,
                "initialization_errors": initialization_errors,
                "available_endpoints": [
                    "GET / - Informations de base",
                    "GET /health - Check de sant√©",
                    "GET /diagnostics - Diagnostics complets",
                    "GET /emergency-diagnostics - Ce diagnostic d'urgence"
                ]
            }
    
    logger.info("‚úÖ Application FastAPI cr√©√©e avec succ√®s")
    return app

# ==================== POINT D'ENTR√âE ====================

# Instance de l'application
app = create_app()

# Point d'entr√©e pour le d√©veloppement local
if __name__ == "__main__":
    import uvicorn
    
    logger.info("üöÄ D√©marrage en mode d√©veloppement local...")
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8003,
        log_level="info",
        reload=False  # D√©sactiv√© pour √©viter les conflits avec le cycle de vie
    )