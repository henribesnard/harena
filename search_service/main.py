"""
Service de recherche Harena - Point d'entr√©e principal.

Ce module configure et d√©marre le service de recherche hybride combinant
Elasticsearch (Bonsai) pour la recherche lexicale et Qdrant pour la recherche s√©mantique.
"""

import asyncio
import logging
import os
import sys
import time
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# Configuration du logging avant les autres imports
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(name)s] - %(levelname)s - %(module)s:%(lineno)d - %(message)s',
    stream=sys.stdout
)

logger = logging.getLogger("search_service.main")

# ==================== IMPORTS DES MODULES ====================

try:
    from config_service.config import settings
    from search_service.storage.elastic_client import ElasticClient
    from search_service.storage.qdrant_client import QdrantClient
    from search_service.core.embedding_service import EmbeddingService
    from search_service.core.reranker import RerankerService
    from search_service.utils.cache import SearchCache
    from search_service.monitoring.metrics_collector import MetricsCollector
    from search_service.api.routes import router
    
    logger.info("‚úÖ Imports r√©ussis")
    
except ImportError as e:
    logger.critical(f"üí• Erreur d'import critique: {e}")
    raise

# ==================== VARIABLES GLOBALES ====================

# Variables de l'application
startup_time = None
startup_diagnostics = {}

# Clients de stockage
elastic_client: Optional[ElasticClient] = None
qdrant_client: Optional[QdrantClient] = None

# Services IA
embedding_service: Optional[EmbeddingService] = None
reranker_service: Optional[RerankerService] = None

# Services utilitaires
search_cache: Optional[SearchCache] = None
metrics_collector: Optional[MetricsCollector] = None

# ==================== FONCTIONS D'INITIALISATION ====================

def log_startup_banner():
    """Affiche une banni√®re de d√©marrage."""
    logger.info("=" * 100)
    logger.info("üöÄ D√âMARRAGE DU SERVICE DE RECHERCHE HARENA")
    logger.info("=" * 100)
    logger.info("üîç Service: Recherche hybride (lexicale + s√©mantique)")
    logger.info("üìä Moteurs: Elasticsearch (Bonsai) + Qdrant")
    logger.info("ü§ñ IA: OpenAI Embeddings + Cohere Reranking")
    logger.info("=" * 100)

def check_environment_configuration() -> Dict[str, Any]:
    """V√©rifie la configuration de l'environnement."""
    logger.info("‚öôÔ∏è === V√âRIFICATION DE LA CONFIGURATION ===")
    
    config_status = {
        "critical_services": {},
        "optional_services": {},
        "summary": {}
    }
    
    # Services critiques
    critical_configs = {
        "BONSAI_URL": {
            "value": settings.BONSAI_URL,
            "description": "URL Elasticsearch (Bonsai)",
            "required": True
        },
        "QDRANT_URL": {
            "value": settings.QDRANT_URL,
            "description": "URL Qdrant",
            "required": True
        }
    }
    
    # Services optionnels
    optional_configs = {
        "OPENAI_API_KEY": {
            "value": settings.OPENAI_API_KEY,
            "description": "Cl√© OpenAI pour embeddings",
            "impact": "D√©sactivation de la recherche s√©mantique"
        },
        "COHERE_KEY": {
            "value": settings.COHERE_KEY,
            "description": "Cl√© Cohere pour reranking",
            "impact": "Pas de reranking intelligent"
        },
        "QDRANT_API_KEY": {
            "value": settings.QDRANT_API_KEY,
            "description": "Cl√© API Qdrant",
            "impact": "Connexion non s√©curis√©e √† Qdrant"
        }
    }
    
    # V√©rification des services critiques
    critical_ok_count = 0
    for key, info in critical_configs.items():
        is_configured = bool(info["value"])
        config_status["critical_services"][key] = {
            "configured": is_configured,
            "description": info["description"],
            "required": info["required"]
        }
        
        if is_configured:
            critical_ok_count += 1
            # Masquer les URLs sensibles pour l'affichage
            if "URL" in key:
                safe_value = info["value"].split('@')[-1] if '@' in info["value"] else info["value"]
                logger.info(f"‚úÖ {key}: {safe_value}")
            else:
                logger.info(f"‚úÖ {key}: Configur√©")
        else:
            logger.error(f"‚ùå {key}: NON CONFIGUR√â - {info['description']}")
    
    # V√©rification des services optionnels
    optional_ok_count = 0
    for key, info in optional_configs.items():
        is_configured = bool(info["value"])
        config_status["optional_services"][key] = {
            "configured": is_configured,
            "description": info["description"],
            "impact": info["impact"]
        }
        
        if is_configured:
            optional_ok_count += 1
            if "KEY" in key:
                masked_value = f"{info['value'][:8]}...{info['value'][-4:]}" if len(info["value"]) > 12 else "***"
                logger.info(f"‚úÖ {key}: {masked_value}")
            else:
                logger.info(f"‚úÖ {key}: Configur√©")
        else:
            logger.warning(f"‚ö†Ô∏è {key}: Non configur√© - {info['impact']}")
    
    # R√©sum√© de la configuration
    config_status["summary"] = {
        "critical_configured": critical_ok_count,
        "critical_total": len(critical_configs),
        "optional_configured": optional_ok_count,
        "optional_total": len(optional_configs),
        "critical_percentage": (critical_ok_count / len(critical_configs)) * 100,
        "optional_percentage": (optional_ok_count / len(optional_configs)) * 100
    }
    
    if critical_ok_count == len(critical_configs):
        logger.info("üéâ CONFIGURATION: Tous les services critiques sont configur√©s")
    elif critical_ok_count > 0:
        logger.warning("‚ö†Ô∏è CONFIGURATION: Services critiques PARTIELLEMENT configur√©s")
    else:
        logger.error("üö® CONFIGURATION: AUCUN service critique configur√©")
    
    return config_status

async def initialize_elasticsearch() -> tuple[bool, Optional[ElasticClient], Dict[str, Any]]:
    """Initialise et teste la connexion Elasticsearch (Bonsai)."""
    logger.info("üîç === INITIALISATION ELASTICSEARCH (BONSAI) ===")
    diagnostic = {
        "service": "elasticsearch_bonsai",
        "configured": False,
        "connected": False,
        "healthy": False,
        "error": None,
        "connection_time": None,
        "cluster_info": {},
        "indices_info": {}
    }
    
    if not settings.BONSAI_URL:
        logger.error("‚ùå BONSAI_URL non configur√©e")
        diagnostic["error"] = "BONSAI_URL not configured"
        return False, None, diagnostic
    
    diagnostic["configured"] = True
    
    # Masquer les credentials pour l'affichage
    safe_url = settings.BONSAI_URL.split('@')[-1] if '@' in settings.BONSAI_URL else settings.BONSAI_URL
    logger.info(f"üîó Connexion √† Bonsai Elasticsearch: {safe_url}")
    
    try:
        start_time = time.time()
        client = ElasticClient()
        
        logger.info("‚è±Ô∏è Test de connexion Elasticsearch...")
        # IMPORTANT: Attendre le retour de initialize()
        initialization_success = await client.initialize()
        
        connection_time = time.time() - start_time
        diagnostic["connection_time"] = round(connection_time, 3)
        
        if initialization_success and client._initialized:
            diagnostic["connected"] = True
            logger.info(f"‚úÖ Connexion √©tablie en {connection_time:.3f}s")
            
            # Test de sant√©
            logger.info("ü©∫ V√©rification de la sant√© du cluster...")
            is_healthy = await client.is_healthy()
            diagnostic["healthy"] = is_healthy
            
            if is_healthy:
                logger.info("üü¢ Cluster Elasticsearch en bonne sant√©")
                
                # R√©cup√©rer les informations du cluster
                try:
                    cluster_info = await client.get_cluster_info()
                    diagnostic["cluster_info"] = cluster_info
                    logger.info(f"üìä Cluster: {cluster_info.get('cluster_name', 'Unknown')}")
                    logger.info(f"üìä Version: {cluster_info.get('version', 'Unknown')}")
                    logger.info(f"üìä N≈ìuds: {cluster_info.get('nodes', 'Unknown')}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer les infos cluster: {e}")
                
                # V√©rifier les indices
                try:
                    indices_info = await client.get_indices_info()
                    diagnostic["indices_info"] = indices_info
                    if indices_info:
                        logger.info(f"üìÅ Indices disponibles: {len(indices_info)}")
                        for index_name, info in indices_info.items():
                            doc_count = info.get('docs', {}).get('count', 0)
                            logger.info(f"   - {index_name}: {doc_count} documents")
                    else:
                        logger.info("üìÅ Aucun indice trouv√©")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de lister les indices: {e}")
                
                return True, client, diagnostic
            else:
                logger.error("üî¥ Cluster Elasticsearch non op√©rationnel")
                diagnostic["error"] = "Cluster unhealthy"
                return False, client, diagnostic
        else:
            logger.error("üî¥ √âchec d'initialisation du client Elasticsearch")
            diagnostic["error"] = "Client initialization failed"
            return False, None, diagnostic
            
    except Exception as e:
        connection_time = time.time() - start_time
        diagnostic["connection_time"] = round(connection_time, 3)
        diagnostic["error"] = str(e)
        
        logger.error(f"üí• Erreur Elasticsearch apr√®s {connection_time:.3f}s:")
        logger.error(f"   Type: {type(e).__name__}")
        logger.error(f"   Message: {str(e)}")
        
        # Diagnostic sp√©cifique des erreurs
        error_str = str(e).lower()
        if "connection" in error_str or "timeout" in error_str:
            logger.error("üîå DIAGNOSTIC: Probl√®me de connectivit√© r√©seau")
            logger.error("   - V√©rifiez l'URL Bonsai")
            logger.error("   - V√©rifiez la connectivit√© r√©seau")
        elif "401" in str(e) or "403" in str(e) or "auth" in error_str:
            logger.error("üîë DIAGNOSTIC: Probl√®me d'authentification")
            logger.error("   - V√©rifiez les credentials dans BONSAI_URL")
        elif "ssl" in error_str or "certificate" in error_str:
            logger.error("üîí DIAGNOSTIC: Probl√®me SSL/TLS")
            logger.error("   - V√©rifiez les certificats SSL")
        
        return False, None, diagnostic

async def initialize_qdrant() -> tuple[bool, Optional[QdrantClient], Dict[str, Any]]:
    """Initialise et teste la connexion Qdrant."""
    logger.info("üéØ === INITIALISATION QDRANT ===")
    diagnostic = {
        "service": "qdrant",
        "configured": False,
        "connected": False,
        "healthy": False,
        "error": None,
        "connection_time": None,
        "collections_info": {},
        "version_info": {}
    }
    
    if not settings.QDRANT_URL:
        logger.error("‚ùå QDRANT_URL non configur√©e")
        diagnostic["error"] = "QDRANT_URL not configured"
        return False, None, diagnostic
    
    diagnostic["configured"] = True
    logger.info(f"üîó Connexion √† Qdrant: {settings.QDRANT_URL}")
    
    if settings.QDRANT_API_KEY:
        logger.info("üîë Authentification par API Key activ√©e")
    else:
        logger.info("üîì Connexion sans authentification")
    
    try:
        start_time = time.time()
        client = QdrantClient()
        
        logger.info("‚è±Ô∏è Test de connexion Qdrant...")
        initialization_success = await client.initialize()
        
        connection_time = time.time() - start_time
        diagnostic["connection_time"] = round(connection_time, 3)
        
        if initialization_success and client._initialized:
            diagnostic["connected"] = True
            logger.info(f"‚úÖ Connexion √©tablie en {connection_time:.3f}s")
            
            # Test de sant√©
            logger.info("ü©∫ V√©rification de la sant√© de Qdrant...")
            is_healthy = await client.is_healthy()
            diagnostic["healthy"] = is_healthy
            
            if is_healthy:
                logger.info("üü¢ Service Qdrant en bonne sant√©")
                
                # R√©cup√©rer les informations des collections
                try:
                    collections_info = await client.get_collections_info()
                    diagnostic["collections_info"] = collections_info
                    if collections_info:
                        logger.info(f"üìÅ Collections disponibles: {len(collections_info)}")
                        for collection_name, info in collections_info.items():
                            vectors_count = info.get('vectors_count', 0)
                            logger.info(f"   - {collection_name}: {vectors_count} vecteurs")
                    else:
                        logger.info("üìÅ Aucune collection trouv√©e")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de lister les collections: {e}")
                
                return True, client, diagnostic
            else:
                logger.error("üî¥ Service Qdrant non op√©rationnel")
                diagnostic["error"] = "Qdrant unhealthy"
                return False, client, diagnostic
        else:
            logger.error("üî¥ √âchec d'initialisation du client Qdrant")
            diagnostic["error"] = "Client initialization failed"
            return False, None, diagnostic
            
    except Exception as e:
        connection_time = time.time() - start_time
        diagnostic["connection_time"] = round(connection_time, 3)
        diagnostic["error"] = str(e)
        
        logger.error(f"üí• Erreur Qdrant apr√®s {connection_time:.3f}s:")
        logger.error(f"   Type: {type(e).__name__}")
        logger.error(f"   Message: {str(e)}")
        
        return False, None, diagnostic

async def initialize_ai_services() -> Dict[str, Any]:
    """Initialise les services IA (embeddings et reranking)."""
    global embedding_service, reranker_service
    
    logger.info("ü§ñ === INITIALISATION DES SERVICES IA ===")
    diagnostics = {
        "embeddings": {"initialized": False, "error": None},
        "reranking": {"initialized": False, "error": None}
    }
    
    # Service d'embeddings (OpenAI)
    if settings.OPENAI_API_KEY:
        try:
            logger.info("üß† Initialisation du service d'embeddings OpenAI...")
            embedding_service = EmbeddingService()
            await embedding_service.initialize()
            diagnostics["embeddings"]["initialized"] = True
            logger.info("‚úÖ Service d'embeddings initialis√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation embeddings: {e}")
            diagnostics["embeddings"]["error"] = str(e)
            embedding_service = None
    else:
        logger.warning("‚ö†Ô∏è OPENAI_API_KEY non configur√©e - embeddings d√©sactiv√©s")
    
    # Service de reranking (Cohere)
    if settings.COHERE_KEY:
        try:
            logger.info("üéØ Initialisation du service de reranking Cohere...")
            reranker_service = RerankerService()
            await reranker_service.initialize()
            diagnostics["reranking"]["initialized"] = True
            logger.info("‚úÖ Service de reranking initialis√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation reranking: {e}")
            diagnostics["reranking"]["error"] = str(e)
            reranker_service = None
    else:
        logger.warning("‚ö†Ô∏è COHERE_KEY non configur√©e - reranking d√©sactiv√©")
    
    return diagnostics

def initialize_cache_and_metrics() -> Dict[str, Any]:
    """Initialise le cache et le collecteur de m√©triques."""
    global search_cache, metrics_collector
    
    logger.info("‚ö° === INITIALISATION CACHE ET M√âTRIQUES ===")
    diagnostics = {
        "cache": {"initialized": False, "error": None},
        "metrics": {"initialized": False, "error": None}
    }
    
    # Cache de recherche
    try:
        logger.info("üíæ Initialisation du cache de recherche...")
        search_cache = SearchCache()
        diagnostics["cache"]["initialized"] = True
        logger.info("‚úÖ Cache de recherche initialis√©")
    except Exception as e:
        logger.error(f"‚ùå Erreur initialisation cache: {e}")
        diagnostics["cache"]["error"] = str(e)
        search_cache = None
    
    # Collecteur de m√©triques
    try:
        logger.info("üìä Initialisation du collecteur de m√©triques...")
        metrics_collector = MetricsCollector()
        diagnostics["metrics"]["initialized"] = True
        logger.info("‚úÖ Collecteur de m√©triques initialis√©")
    except Exception as e:
        logger.error(f"‚ùå Erreur initialisation m√©triques: {e}")
        diagnostics["metrics"]["error"] = str(e)
        metrics_collector = None
    
    return diagnostics

def inject_dependencies():
    """Injecte les clients dans les modules qui en ont besoin - APR√àS initialisation compl√®te."""
    logger.info("üîó === INJECTION DES D√âPENDANCES ===")
    
    try:
        import search_service.api.routes as routes
        
        # Injecter seulement les clients qui ont √©t√© initialis√©s avec succ√®s
        if elastic_client and hasattr(elastic_client, '_initialized') and elastic_client._initialized:
            routes.elastic_client = elastic_client
            logger.info("‚úÖ ElasticClient inject√© dans routes")
        else:
            routes.elastic_client = None
            logger.warning("‚ö†Ô∏è ElasticClient non disponible - non inject√©")
        
        if qdrant_client and hasattr(qdrant_client, '_initialized') and qdrant_client._initialized:
            routes.qdrant_client = qdrant_client
            logger.info("‚úÖ QdrantClient inject√© dans routes")
        else:
            routes.qdrant_client = None
            logger.warning("‚ö†Ô∏è QdrantClient non disponible - non inject√©")
        
        # Injecter les services IA
        routes.embedding_service = embedding_service
        routes.reranker_service = reranker_service
        
        # Injecter les services utilitaires
        routes.search_cache = search_cache
        routes.metrics_collector = metrics_collector
        
        logger.info("‚úÖ Injection des d√©pendances termin√©e")
        
        # Log du statut final des clients
        clients_status = {
            "elasticsearch": elastic_client is not None and getattr(elastic_client, '_initialized', False),
            "qdrant": qdrant_client is not None and getattr(qdrant_client, '_initialized', False),
            "embeddings": embedding_service is not None,
            "reranking": reranker_service is not None,
            "cache": search_cache is not None,
            "metrics": metrics_collector is not None
        }
        
        active_clients = sum(clients_status.values())
        logger.info(f"üìä Services actifs: {active_clients}/6")
        
        for service_name, is_active in clients_status.items():
            status_icon = "‚úÖ" if is_active else "‚ùå"
            logger.info(f"   {status_icon} {service_name}: {'Actif' if is_active else 'Inactif'}")
            
    except Exception as e:
        logger.error(f"üí• Erreur lors de l'injection des d√©pendances: {e}")
        # En cas d'erreur, injecter au moins None pour √©viter les erreurs d'import
        try:
            import search_service.api.routes as routes
            routes.elastic_client = None
            routes.qdrant_client = None
            routes.embedding_service = None
            routes.reranker_service = None
            routes.search_cache = None
            routes.metrics_collector = None
            logger.warning("‚ö†Ô∏è Services par d√©faut (None) inject√©s suite √† l'erreur")
        except Exception as fallback_error:
            logger.error(f"üí• Impossible d'injecter m√™me les valeurs par d√©faut: {fallback_error}")

def generate_startup_summary() -> Dict[str, Any]:
    """G√©n√®re un r√©sum√© complet du d√©marrage."""
    global startup_diagnostics
    
    startup_duration = time.time() - startup_time
    
    # Compter les services op√©rationnels
    operational_services = []
    failed_services = []
    
    # Services critiques
    if elastic_client and getattr(elastic_client, '_initialized', False):
        operational_services.append("Elasticsearch (Bonsai)")
    else:
        failed_services.append("Elasticsearch (Bonsai)")
    
    if qdrant_client and getattr(qdrant_client, '_initialized', False):
        operational_services.append("Qdrant")
    else:
        failed_services.append("Qdrant")
    
    # Services IA
    ai_diag = startup_diagnostics.get("ai_services", {})
    if ai_diag.get("embeddings", {}).get("initialized"):
        operational_services.append("OpenAI Embeddings")
    else:
        failed_services.append("OpenAI Embeddings")
    
    if ai_diag.get("reranking", {}).get("initialized"):
        operational_services.append("Cohere Reranking")
    else:
        failed_services.append("Cohere Reranking")
    
    # Services utilitaires
    if search_cache:
        operational_services.append("Cache")
    if metrics_collector:
        operational_services.append("M√©triques")
    
    # D√©terminer l'√©tat global du service
    critical_services_ok = (elastic_client and getattr(elastic_client, '_initialized', False) and 
                           qdrant_client and getattr(qdrant_client, '_initialized', False))
    
    if critical_services_ok:
        if len(operational_services) >= 4:  # Elasticsearch + Qdrant + au moins 2 autres
            status = "FULLY_OPERATIONAL"
            status_icon = "üéâ"
            status_msg = "COMPL√àTEMENT OP√âRATIONNEL"
        else:
            status = "OPERATIONAL"
            status_icon = "‚úÖ"
            status_msg = "OP√âRATIONNEL"
    elif (elastic_client and getattr(elastic_client, '_initialized', False)) or \
         (qdrant_client and getattr(qdrant_client, '_initialized', False)):
        status = "DEGRADED"
        status_icon = "‚ö†Ô∏è"
        status_msg = "D√âGRAD√â"
    else:
        status = "FAILED"
        status_icon = "üö®"
        status_msg = "D√âFAILLANT"
    
    # Capacit√©s de recherche
    search_capabilities = {
        "lexical_search": elastic_client is not None and getattr(elastic_client, '_initialized', False),
        "semantic_search": (qdrant_client is not None and getattr(qdrant_client, '_initialized', False) and 
                           embedding_service is not None),
        "hybrid_search": (elastic_client is not None and getattr(elastic_client, '_initialized', False) and 
                         qdrant_client is not None and getattr(qdrant_client, '_initialized', False) and 
                         embedding_service is not None),
        "intelligent_reranking": reranker_service is not None,
        "caching": search_cache is not None,
        "metrics": metrics_collector is not None
    }
    
    summary = {
        "status": status,
        "status_message": status_msg,
        "startup_duration": round(startup_duration, 2),
        "operational_count": len(operational_services),
        "failed_count": len(failed_services),
        "total_services": len(operational_services) + len(failed_services),
        "operational_services": operational_services,
        "failed_services": failed_services,
        "search_capabilities": search_capabilities,
        "timestamp": datetime.now().isoformat()
    }
    
    # Affichage du r√©sum√©
    logger.info("=" * 100)
    logger.info(f"{status_icon} R√âSUM√â DU D√âMARRAGE - {status_msg}")
    logger.info("=" * 100)
    logger.info(f"‚è±Ô∏è Dur√©e: {startup_duration:.2f}s")
    logger.info(f"üìä Services: {len(operational_services)}/{len(operational_services) + len(failed_services)} op√©rationnels")
    
    if operational_services:
        logger.info("‚úÖ Services op√©rationnels:")
        for service in operational_services:
            logger.info(f"   ‚úì {service}")
    
    if failed_services:
        logger.info("‚ùå Services d√©faillants:")
        for service in failed_services:
            logger.info(f"   ‚úó {service}")
    
    # Affichage des capacit√©s
    if status == "FULLY_OPERATIONAL":
        logger.info("üéâ CAPACIT√âS COMPL√àTES DISPONIBLES:")
        logger.info("   ‚úì Recherche lexicale avanc√©e (Elasticsearch/Bonsai)")
        logger.info("   ‚úì Recherche s√©mantique (Qdrant)")
        logger.info("   ‚úì Recherche hybride avec fusion des scores")
        logger.info("   ‚úì Reranking intelligent des r√©sultats")
    elif status == "OPERATIONAL":
        logger.info("‚úÖ Fonctionnalit√©s de recherche de base disponibles")
        logger.info("   ‚úì Recherche lexicale ET s√©mantique")
        logger.warning("   ‚ö†Ô∏è Certaines fonctionnalit√©s avanc√©es peuvent √™tre limit√©es")
    elif status == "DEGRADED":
        logger.warning("‚ö†Ô∏è Service de recherche en mode d√©grad√©")
        if elastic_client and getattr(elastic_client, '_initialized', False) and not (qdrant_client and getattr(qdrant_client, '_initialized', False)):
            logger.warning("   ‚úì Recherche lexicale disponible")
            logger.warning("   ‚ùå Recherche s√©mantique indisponible")
        elif qdrant_client and getattr(qdrant_client, '_initialized', False) and not (elastic_client and getattr(elastic_client, '_initialized', False)):
            logger.warning("   ‚ùå Recherche lexicale indisponible")
            logger.warning("   ‚úì Recherche s√©mantique disponible")
    else:
        logger.error("üö® Service de recherche indisponible")
        logger.error("   ‚ùå V√©rifiez la configuration BONSAI_URL et QDRANT_URL")
        logger.error("   ‚ùå V√©rifiez la connectivit√© r√©seau")
    
    logger.info("üìä Endpoints disponibles:")
    logger.info("   GET  /health - V√©rification de sant√© d√©taill√©e")
    logger.info("   POST /api/v1/search - Recherche de transactions")
    logger.info("   GET  /api/v1/search/suggest - Suggestions de recherche")
    logger.info("=" * 100)
    
    return summary

# ==================== CYCLE DE VIE DE L'APPLICATION ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestionnaire du cycle de vie de l'application avec diagnostics complets."""
    global startup_time, startup_diagnostics, elastic_client, qdrant_client
    
    try:
        # === PHASE DE D√âMARRAGE ===
        log_startup_banner()
        startup_time = time.time()
        
        # 1. V√©rification de la configuration
        config_status = check_environment_configuration()
        startup_diagnostics["configuration"] = config_status
        
        # 2. Initialisation d'Elasticsearch (Bonsai)
        elastic_success, elastic_client, elastic_diag = await initialize_elasticsearch()
        startup_diagnostics["elasticsearch"] = elastic_diag
        
        # 3. Initialisation de Qdrant
        qdrant_success, qdrant_client, qdrant_diag = await initialize_qdrant()
        startup_diagnostics["qdrant"] = qdrant_diag
        
        # 4. Initialisation des services IA
        ai_diagnostics = await initialize_ai_services()
        startup_diagnostics["ai_services"] = ai_diagnostics
        
        # 5. Initialisation du cache et des m√©triques
        utils_diagnostics = initialize_cache_and_metrics()
        startup_diagnostics["utilities"] = utils_diagnostics
        
        # 6. Injection des d√©pendances APR√àS initialisation
        inject_dependencies()
        
        # 7. G√©n√©ration du r√©sum√© de d√©marrage
        startup_summary = generate_startup_summary()
        startup_diagnostics["summary"] = startup_summary
        
        # Application pr√™te
        yield
        
    except Exception as e:
        logger.critical(f"üí• ERREUR CRITIQUE au d√©marrage: {type(e).__name__}: {str(e)}")
        import traceback
        logger.critical(f"Stack trace:\n{traceback.format_exc()}")
        raise
    
    finally:
        # === PHASE D'ARR√äT ===
        logger.info("‚èπÔ∏è Arr√™t du service de recherche...")
        
        # Fermeture des clients de stockage
        try:
            if elastic_client:
                await elastic_client.close()
                logger.info("‚úÖ Client Elasticsearch ferm√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture Elasticsearch: {e}")
        
        try:
            if qdrant_client:
                await qdrant_client.close()
                logger.info("‚úÖ Client Qdrant ferm√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture Qdrant: {e}")
        
        # Fermeture des services IA
        try:
            if embedding_service and hasattr(embedding_service, 'close'):
                await embedding_service.close()
                logger.info("‚úÖ Service d'embeddings ferm√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture embeddings: {e}")
        
        try:
            if reranker_service and hasattr(reranker_service, 'close'):
                await reranker_service.close()
                logger.info("‚úÖ Service de reranking ferm√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture reranking: {e}")
        
        logger.info("üîö Service de recherche arr√™t√© proprement")

# ==================== APPLICATION FASTAPI ====================

def create_app() -> FastAPI:
    """Cr√©e et configure l'application FastAPI."""
    app = FastAPI(
        title="Harena Search Service",
        description="Service de recherche hybride combinant recherche lexicale (Bonsai) et s√©mantique (Qdrant)",
        version="1.0.0",
        docs_url="/docs",
        redoc_url="/redoc",
        lifespan=lifespan
    )
    
    # Configuration CORS
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # √Ä restreindre en production
        allow_credentials=True,
        allow_methods=["GET", "POST", "PUT", "DELETE"],
        allow_headers=["*"],
    )
    
    # Endpoints de sant√© √©tendus
    @app.get("/health")
    async def health_check():
        """Endpoint de sant√© d√©taill√© avec diagnostics complets."""
        try:
            uptime_seconds = time.time() - startup_time if startup_time else 0
            
            # Statut des services
            services_status = {
                "elasticsearch": {
                    "healthy": elastic_client is not None and getattr(elastic_client, '_initialized', False) and await elastic_client.is_healthy() if elastic_client else False,
                    "initialized": elastic_client is not None and getattr(elastic_client, '_initialized', False)
                },
                "qdrant": {
                    "healthy": qdrant_client is not None and getattr(qdrant_client, '_initialized', False) and await qdrant_client.is_healthy() if qdrant_client else False,
                    "initialized": qdrant_client is not None and getattr(qdrant_client, '_initialized', False)
                },
                "embeddings": {
                    "available": embedding_service is not None
                },
                "reranking": {
                    "available": reranker_service is not None
                },
                "cache": {
                    "available": search_cache is not None
                },
                "metrics": {
                    "available": metrics_collector is not None
                }
            }
            
            # Capacit√©s de recherche
            search_capabilities = {
                "lexical_search": services_status["elasticsearch"]["healthy"],
                "semantic_search": services_status["qdrant"]["healthy"] and services_status["embeddings"]["available"],
                "hybrid_search": services_status["elasticsearch"]["healthy"] and services_status["qdrant"]["healthy"] and services_status["embeddings"]["available"],
                "intelligent_reranking": services_status["reranking"]["available"]
            }
            
            # D√©terminer le statut global
            if services_status["elasticsearch"]["healthy"] and services_status["qdrant"]["healthy"]:
                overall_status = "healthy"
            elif services_status["elasticsearch"]["healthy"] or services_status["qdrant"]["healthy"]:
                overall_status = "degraded"
            else:
                overall_status = "unhealthy"
            
            return {
                "service": "search_service",
                "version": "1.0.0",
                "status": overall_status,
                "timestamp": datetime.now().isoformat(),
                "uptime": {
                    "seconds": round(uptime_seconds, 2),
                    "human": str(timedelta(seconds=int(uptime_seconds)))
                },
                "services": services_status,
                "search_capabilities": search_capabilities,
                "startup_diagnostics": startup_diagnostics.get("summary", {}),
                "performance": {
                    "startup_time": startup_diagnostics.get("summary", {}).get("startup_duration"),
                    "operational_services": startup_diagnostics.get("summary", {}).get("operational_count", 0),
                    "total_services": startup_diagnostics.get("summary", {}).get("total_services", 0)
                },
                "clients_injected": {
                    "elasticsearch": elastic_client is not None,
                    "qdrant": qdrant_client is not None,
                    "cache": search_cache is not None,
                    "metrics": metrics_collector is not None
                }
            }
            
        except Exception as e:
            logger.error(f"Erreur lors du health check: {e}")
            return {
                "service": "search_service",
                "version": "1.0.0",
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "clients_injected": {
                    "elasticsearch": elastic_client is not None,
                    "qdrant": qdrant_client is not None,
                    "cache": search_cache is not None,
                    "metrics": metrics_collector is not None
                }
            }
    
    @app.get("/")
    async def root():
        """Point d'entr√©e racine du service."""
        uptime_seconds = time.time() - startup_time if startup_time else 0
        summary = startup_diagnostics.get("summary", {})
        
        return {
            "service": "Harena Search Service",
            "description": "Service de recherche hybride (lexicale + s√©mantique)",
            "version": "1.0.0",
            "status": summary.get("status", "unknown"),
            "uptime_seconds": round(uptime_seconds, 2),
            "search_engines": {
                "elasticsearch": "Bonsai (recherche lexicale)",
                "qdrant": "Stockage vectoriel (recherche s√©mantique)"
            },
            "capabilities": summary.get("search_capabilities", {}),
            "endpoints": {
                "health": "GET /health",
                "search": "POST /api/v1/search",
                "suggestions": "GET /api/v1/search/suggest"
            },
            "clients_status": {
                "elasticsearch_injected": elastic_client is not None,
                "qdrant_injected": qdrant_client is not None,
                "cache_injected": search_cache is not None,
                "metrics_injected": metrics_collector is not None
            },
            "timestamp": datetime.now().isoformat()
        }
    
    @app.get("/startup-diagnostics")
    async def get_startup_diagnostics():
        """Retourne les diagnostics de d√©marrage complets."""
        return {
            "timestamp": datetime.now().isoformat(),
            "startup_time": startup_time,
            "diagnostics": startup_diagnostics,
            "current_clients_status": {
                "elasticsearch": {
                    "injected": elastic_client is not None,
                    "type": type(elastic_client).__name__ if elastic_client else None
                },
                "qdrant": {
                    "injected": qdrant_client is not None,
                    "type": type(qdrant_client).__name__ if qdrant_client else None
                },
                "cache": {
                    "injected": search_cache is not None,
                    "type": type(search_cache).__name__ if search_cache else None
                },
                "metrics": {
                    "injected": metrics_collector is not None,
                    "type": type(metrics_collector).__name__ if metrics_collector else None
                }
            }
        }
    
    @app.get("/clients-debug")
    async def debug_clients():
        """Debug d√©taill√© des clients pour diagnostic."""
        try:
            # Import du module routes pour v√©rifier l'injection
            import search_service.api.routes as routes_module
            
            return {
                "timestamp": datetime.now().isoformat(),
                "global_clients": {
                    "elastic_client": {
                        "exists": elastic_client is not None,
                        "type": type(elastic_client).__name__ if elastic_client else None,
                        "id": id(elastic_client) if elastic_client else None,
                        "initialized": getattr(elastic_client, '_initialized', False) if elastic_client else False
                    },
                    "qdrant_client": {
                        "exists": qdrant_client is not None,
                        "type": type(qdrant_client).__name__ if qdrant_client else None,
                        "id": id(qdrant_client) if qdrant_client else None,
                        "initialized": getattr(qdrant_client, '_initialized', False) if qdrant_client else False
                    },
                    "search_cache": {
                        "exists": search_cache is not None,
                        "type": type(search_cache).__name__ if search_cache else None,
                        "id": id(search_cache) if search_cache else None
                    },
                    "metrics_collector": {
                        "exists": metrics_collector is not None,
                        "type": type(metrics_collector).__name__ if metrics_collector else None,
                        "id": id(metrics_collector) if metrics_collector else None
                    }
                },
                "routes_module_clients": {
                    "elastic_client": {
                        "exists": hasattr(routes_module, 'elastic_client') and routes_module.elastic_client is not None,
                        "type": type(getattr(routes_module, 'elastic_client', None)).__name__ if hasattr(routes_module, 'elastic_client') and routes_module.elastic_client else None,
                        "id": id(getattr(routes_module, 'elastic_client', None)) if hasattr(routes_module, 'elastic_client') and routes_module.elastic_client else None,
                        "same_as_global": (hasattr(routes_module, 'elastic_client') and 
                                         routes_module.elastic_client is elastic_client)
                    },
                    "qdrant_client": {
                        "exists": hasattr(routes_module, 'qdrant_client') and routes_module.qdrant_client is not None,
                        "type": type(getattr(routes_module, 'qdrant_client', None)).__name__ if hasattr(routes_module, 'qdrant_client') and routes_module.qdrant_client else None,
                        "id": id(getattr(routes_module, 'qdrant_client', None)) if hasattr(routes_module, 'qdrant_client') and routes_module.qdrant_client else None,
                        "same_as_global": (hasattr(routes_module, 'qdrant_client') and 
                                         routes_module.qdrant_client is qdrant_client)
                    },
                    "search_cache": {
                        "exists": hasattr(routes_module, 'search_cache') and routes_module.search_cache is not None,
                        "type": type(getattr(routes_module, 'search_cache', None)).__name__ if hasattr(routes_module, 'search_cache') and routes_module.search_cache else None,
                        "id": id(getattr(routes_module, 'search_cache', None)) if hasattr(routes_module, 'search_cache') and routes_module.search_cache else None,
                        "same_as_global": (hasattr(routes_module, 'search_cache') and 
                                         routes_module.search_cache is search_cache)
                    },
                    "metrics_collector": {
                        "exists": hasattr(routes_module, 'metrics_collector') and routes_module.metrics_collector is not None,
                        "type": type(getattr(routes_module, 'metrics_collector', None)).__name__ if hasattr(routes_module, 'metrics_collector') and routes_module.metrics_collector else None,
                        "id": id(getattr(routes_module, 'metrics_collector', None)) if hasattr(routes_module, 'metrics_collector') and routes_module.metrics_collector else None,
                        "same_as_global": (hasattr(routes_module, 'metrics_collector') and 
                                         routes_module.metrics_collector is metrics_collector)
                    }
                },
                "injection_summary": {
                    "elasticsearch_injected_correctly": (
                        hasattr(routes_module, 'elastic_client') and 
                        routes_module.elastic_client is elastic_client and
                        elastic_client is not None and
                        getattr(elastic_client, '_initialized', False)
                    ),
                    "qdrant_injected_correctly": (
                        hasattr(routes_module, 'qdrant_client') and 
                        routes_module.qdrant_client is qdrant_client and
                        qdrant_client is not None and
                        getattr(qdrant_client, '_initialized', False)
                    )
                }
            }
            
        except Exception as e:
            return {
                "error": f"Erreur lors du debug des clients: {e}",
                "timestamp": datetime.now().isoformat()
            }
    
    # Inclure les routes de recherche
    app.include_router(router, prefix="/api/v1/search", tags=["search"])
    
    return app

# ==================== CR√âATION DE L'APPLICATION ====================

app = create_app()

# ==================== POINT D'ENTR√âE ====================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("üîß D√©marrage en mode d√©veloppement local")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )