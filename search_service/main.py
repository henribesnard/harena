"""
Service de recherche Harena - Point d'entr√©e principal.

Ce module configure et d√©marre le service de recherche hybride combinant
Elasticsearch (Bonsai) pour la recherche lexicale et Qdrant pour la recherche s√©mantique.
"""

import asyncio
import logging
import os
import sys
import time
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# Configuration du logging avant les autres imports
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(name)s] - %(levelname)s - %(module)s:%(lineno)d - %(message)s',
    stream=sys.stdout
)

logger = logging.getLogger("search_service.main")

# ==================== IMPORTS DES MODULES ====================

try:
    from config_service.config import settings
    from search_service.storage.elastic_client_hybrid import HybridElasticClient
    from search_service.storage.qdrant_client import QdrantClient
    from search_service.utils.initialization import (
        initialize_search_clients,
        log_initialization_summary,
        run_startup_diagnostics,
        log_diagnostic_summary,
        create_collections_if_needed,
        validate_clients_functionality
    )
    
    logger.info("‚úÖ Imports r√©ussis")
    
except ImportError as e:
    logger.critical(f"üí• Erreur d'import critique: {e}")
    raise

# Imports optionnels pour les services IA et utilitaires
try:
    from search_service.core.embeddings import EmbeddingService
    EMBEDDING_SERVICE_AVAILABLE = True
except ImportError:
    logger.warning("‚ö†Ô∏è EmbeddingService non disponible")
    EMBEDDING_SERVICE_AVAILABLE = False
    EmbeddingService = None

try:
    from search_service.core.reranker import RerankerService
    RERANKER_SERVICE_AVAILABLE = True
except ImportError:
    logger.warning("‚ö†Ô∏è RerankerService non disponible")
    RERANKER_SERVICE_AVAILABLE = False
    RerankerService = None

try:
    from search_service.utils.cache import SearchCache
    CACHE_SERVICE_AVAILABLE = True
except ImportError:
    logger.warning("‚ö†Ô∏è SearchCache non disponible")
    CACHE_SERVICE_AVAILABLE = False
    SearchCache = None

# Le module MetricsCollector n'existe pas encore
METRICS_SERVICE_AVAILABLE = False
MetricsCollector = None
logger.info("‚ÑπÔ∏è MetricsCollector non impl√©ment√© - d√©sactiv√©")

try:
    from search_service.api.routes import router
    ROUTES_AVAILABLE = True
except ImportError:
    logger.warning("‚ö†Ô∏è Routes API non disponibles")
    ROUTES_AVAILABLE = False
    router = None

# ==================== VARIABLES GLOBALES ====================

# Variables de l'application
startup_time = None
startup_diagnostics = {}
full_diagnostic_report = {}

# Clients de stockage
elastic_client: Optional[HybridElasticClient] = None
qdrant_client: Optional[QdrantClient] = None

# Services IA
embedding_service: Optional[Any] = None
reranker_service: Optional[Any] = None

# Services utilitaires
search_cache: Optional[Any] = None
metrics_collector: Optional[Any] = None

# ==================== FONCTIONS D'INITIALISATION ====================

def log_startup_banner():
    """Affiche une banni√®re de d√©marrage."""
    logger.info("=" * 100)
    logger.info("üöÄ D√âMARRAGE DU SERVICE DE RECHERCHE HARENA")
    logger.info("=" * 100)
    logger.info("üîç Service: Recherche hybride (lexicale + s√©mantique)")
    logger.info("üìä Moteurs: Elasticsearch (Bonsai) + Qdrant")
    logger.info("ü§ñ IA: OpenAI Embeddings + Cohere Reranking")
    logger.info("üîß Mode: Client hybride avec fallback Bonsai HTTP")
    logger.info("üìã Version: 2.0.0")
    logger.info("=" * 100)


async def initialize_ai_services() -> Dict[str, Any]:
    """Initialise les services IA (embeddings et reranking)."""
    global embedding_service, reranker_service
    
    logger.info("ü§ñ === INITIALISATION DES SERVICES IA ===")
    ai_diagnostics = {
        "embeddings": {"initialized": False, "available": EMBEDDING_SERVICE_AVAILABLE, "error": None},
        "reranking": {"initialized": False, "available": RERANKER_SERVICE_AVAILABLE, "error": None}
    }
    
    # Initialisation du service d'embeddings
    if EMBEDDING_SERVICE_AVAILABLE:
        try:
            if settings.OPENAI_API_KEY:
                embedding_service = EmbeddingService()
                await embedding_service.initialize()
                ai_diagnostics["embeddings"]["initialized"] = True
                logger.info("‚úÖ Service d'embeddings OpenAI initialis√©")
            else:
                logger.warning("‚ö†Ô∏è OPENAI_API_KEY non configur√©e - service d'embeddings d√©sactiv√©")
                ai_diagnostics["embeddings"]["error"] = "OPENAI_API_KEY not configured"
                
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation embeddings: {e}")
            ai_diagnostics["embeddings"]["error"] = str(e)
    else:
        ai_diagnostics["embeddings"]["error"] = "Service not available"
    
    # Initialisation du service de reranking
    if RERANKER_SERVICE_AVAILABLE:
        try:
            if getattr(settings, 'COHERE_KEY', None):
                reranker_service = RerankerService()
                await reranker_service.initialize()
                ai_diagnostics["reranking"]["initialized"] = True
                logger.info("‚úÖ Service de reranking Cohere initialis√©")
            else:
                logger.warning("‚ö†Ô∏è COHERE_KEY non configur√©e - service de reranking d√©sactiv√©")
                ai_diagnostics["reranking"]["error"] = "COHERE_KEY not configured"
                
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation reranking: {e}")
            ai_diagnostics["reranking"]["error"] = str(e)
    else:
        ai_diagnostics["reranking"]["error"] = "Service not available"
    
    return ai_diagnostics


def initialize_cache_and_metrics() -> Dict[str, Any]:
    """Initialise le cache et le collecteur de m√©triques."""
    global search_cache, metrics_collector
    
    logger.info("üõ†Ô∏è === INITIALISATION CACHE ET M√âTRIQUES ===")
    utils_diagnostics = {
        "cache": {"initialized": False, "available": CACHE_SERVICE_AVAILABLE, "error": None},
        "metrics": {"initialized": False, "available": METRICS_SERVICE_AVAILABLE, "error": None}
    }
    
    # Initialisation du cache
    if CACHE_SERVICE_AVAILABLE:
        try:
            search_cache = SearchCache()
            utils_diagnostics["cache"]["initialized"] = True
            logger.info("‚úÖ Cache de recherche initialis√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation cache: {e}")
            utils_diagnostics["cache"]["error"] = str(e)
    else:
        utils_diagnostics["cache"]["error"] = "Service not available"
    
    # Initialisation du collecteur de m√©triques
    if METRICS_SERVICE_AVAILABLE:
        try:
            metrics_collector = MetricsCollector()
            utils_diagnostics["metrics"]["initialized"] = True
            logger.info("‚úÖ Collecteur de m√©triques initialis√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation m√©triques: {e}")
            utils_diagnostics["metrics"]["error"] = str(e)
    else:
        utils_diagnostics["metrics"]["error"] = "Service not implemented yet"
        logger.info("‚ÑπÔ∏è Collecteur de m√©triques d√©sactiv√© (non impl√©ment√©)")
    
    return utils_diagnostics


def inject_dependencies():
    """Injecte les d√©pendances dans les modules qui en ont besoin."""
    logger.info("üîó === INJECTION DES D√âPENDANCES ===")
    
    if not ROUTES_AVAILABLE:
        logger.warning("‚ö†Ô∏è Routes non disponibles - injection ignor√©e")
        return
    
    try:
        import search_service.api.routes as routes
        
        # Injecter seulement les clients qui ont √©t√© initialis√©s avec succ√®s
        if elastic_client and hasattr(elastic_client, '_initialized') and elastic_client._initialized:
            routes.elastic_client = elastic_client
            logger.info("‚úÖ HybridElasticClient inject√© dans routes")
        else:
            routes.elastic_client = None
            logger.warning("‚ö†Ô∏è HybridElasticClient non disponible - non inject√©")
        
        if qdrant_client and hasattr(qdrant_client, '_initialized') and qdrant_client._initialized:
            routes.qdrant_client = qdrant_client
            logger.info("‚úÖ QdrantClient inject√© dans routes")
        else:
            routes.qdrant_client = None
            logger.warning("‚ö†Ô∏è QdrantClient non disponible - non inject√©")
        
        # Injecter les services IA
        routes.embedding_service = embedding_service
        routes.reranker_service = reranker_service
        
        # Injecter les services utilitaires
        routes.search_cache = search_cache
        routes.metrics_collector = metrics_collector
        
        logger.info("‚úÖ Injection des d√©pendances termin√©e")
        
        # Log du statut final des services
        services_status = {
            "elasticsearch": elastic_client is not None and getattr(elastic_client, '_initialized', False),
            "qdrant": qdrant_client is not None and getattr(qdrant_client, '_initialized', False),
            "embeddings": embedding_service is not None,
            "reranking": reranker_service is not None,
            "cache": search_cache is not None,
            "metrics": metrics_collector is not None
        }
        
        active_services = sum(services_status.values())
        logger.info(f"üìä Services actifs: {active_services}/6")
        
        for service_name, is_active in services_status.items():
            status_icon = "‚úÖ" if is_active else "‚ùå"
            logger.info(f"   {status_icon} {service_name}: {'Actif' if is_active else 'Inactif'}")
            
    except Exception as e:
        logger.error(f"üí• Erreur lors de l'injection des d√©pendances: {e}")
        # En cas d'erreur, injecter au moins None pour √©viter les erreurs d'import
        try:
            import search_service.api.routes as routes
            routes.elastic_client = None
            routes.qdrant_client = None
            routes.embedding_service = None
            routes.reranker_service = None
            routes.search_cache = None
            routes.metrics_collector = None
            logger.warning("‚ö†Ô∏è Services par d√©faut (None) inject√©s suite √† l'erreur")
        except Exception as fallback_error:
            logger.error(f"üí• Impossible d'injecter m√™me les valeurs par d√©faut: {fallback_error}")


def generate_startup_summary() -> Dict[str, Any]:
    """G√©n√®re un r√©sum√© complet du d√©marrage."""
    global startup_diagnostics, elastic_client, qdrant_client, full_diagnostic_report
    
    startup_duration = time.time() - startup_time
    
    # Compter les services op√©rationnels
    operational_services = []
    failed_services = []
    
    # Services critiques
    if elastic_client and getattr(elastic_client, '_initialized', False):
        client_type = getattr(elastic_client, 'client_type', 'unknown')
        operational_services.append(f"Elasticsearch ({client_type})")
    else:
        failed_services.append("Elasticsearch")
    
    if qdrant_client and getattr(qdrant_client, '_initialized', False):
        operational_services.append("Qdrant")
    else:
        failed_services.append("Qdrant")
    
    # Services IA
    ai_diag = startup_diagnostics.get("ai_services", {})
    if ai_diag.get("embeddings", {}).get("initialized"):
        operational_services.append("OpenAI Embeddings")
    else:
        failed_services.append("OpenAI Embeddings")
    
    if ai_diag.get("reranking", {}).get("initialized"):
        operational_services.append("Cohere Reranking")
    else:
        failed_services.append("Cohere Reranking")
    
    # Services utilitaires
    if search_cache:
        operational_services.append("Cache")
    if metrics_collector:
        operational_services.append("M√©triques")
    
    # D√©terminer l'√©tat global du service
    critical_services_ok = (elastic_client and getattr(elastic_client, '_initialized', False) and 
                           qdrant_client and getattr(qdrant_client, '_initialized', False))
    
    if critical_services_ok:
        if len(operational_services) >= 4:  # Elasticsearch + Qdrant + au moins 2 autres
            status = "OPTIMAL"
        else:
            status = "DEGRADED"
    else:
        if len(operational_services) >= 1:
            status = "DEGRADED"
        else:
            status = "FAILED"
    
    summary = {
        "startup_duration": round(startup_duration, 2),
        "status": status,
        "operational_services": operational_services,
        "failed_services": failed_services,
        "total_services": len(operational_services) + len(failed_services),
        "success_rate": len(operational_services) / (len(operational_services) + len(failed_services)) * 100,
        "diagnostics": startup_diagnostics,
        "full_diagnostic": full_diagnostic_report
    }
    
    # Log du r√©sum√©
    logger.info("üéä === R√âSUM√â DU D√âMARRAGE ===")
    logger.info(f"‚è±Ô∏è Dur√©e totale: {startup_duration:.2f}s")
    logger.info(f"üìä Statut: {status}")
    logger.info(f"‚úÖ Services op√©rationnels ({len(operational_services)}):")
    for service in operational_services:
        logger.info(f"   ‚úì {service}")
    
    if failed_services:
        logger.info(f"‚ùå Services en √©chec ({len(failed_services)}):")
        for service in failed_services:
            logger.info(f"   ‚úó {service}")
    
    # Messages selon le statut
    if status == "OPTIMAL":
        logger.info("üéâ Service de recherche OPTIMAL")
        logger.info("   ‚úì Recherche lexicale ET s√©mantique")
        logger.info("   ‚úì Toutes les fonctionnalit√©s disponibles")
    elif status == "DEGRADED":
        logger.warning("‚ö†Ô∏è Service de recherche en mode d√©grad√©")
        if elastic_client and getattr(elastic_client, '_initialized', False) and not (qdrant_client and getattr(qdrant_client, '_initialized', False)):
            logger.warning("   ‚úì Recherche lexicale disponible")
            logger.warning("   ‚ùå Recherche s√©mantique indisponible")
        elif qdrant_client and getattr(qdrant_client, '_initialized', False) and not (elastic_client and getattr(elastic_client, '_initialized', False)):
            logger.warning("   ‚ùå Recherche lexicale indisponible")
            logger.warning("   ‚úì Recherche s√©mantique disponible")
    else:
        logger.error("üö® Service de recherche indisponible")
        logger.error("   ‚ùå V√©rifiez la configuration BONSAI_URL et QDRANT_URL")
        logger.error("   ‚ùå V√©rifiez la connectivit√© r√©seau")
    
    logger.info("üìä Endpoints disponibles:")
    if ROUTES_AVAILABLE:
        logger.info("   GET  /health - V√©rification de sant√©")
        logger.info("   GET  /diagnostics - Diagnostics d√©taill√©s")
        logger.info("   POST /api/v1/search - Recherche de transactions")
        logger.info("   GET  /api/v1/search/suggest - Suggestions de recherche")
    else:
        logger.info("   GET  /health - V√©rification de sant√© (basique)")
        logger.info("   GET  /diagnostics - Diagnostics d√©taill√©s")
    logger.info("=" * 100)
    
    return summary

# ==================== CYCLE DE VIE DE L'APPLICATION ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestionnaire du cycle de vie de l'application avec diagnostics complets."""
    global startup_time, startup_diagnostics, elastic_client, qdrant_client, full_diagnostic_report
    
    try:
        # === PHASE DE D√âMARRAGE ===
        log_startup_banner()
        startup_time = time.time()
        
        # 1. Diagnostic complet de d√©marrage
        logger.info("üî¨ Lancement du diagnostic complet...")
        full_diagnostic_report = await run_startup_diagnostics()
        log_diagnostic_summary(full_diagnostic_report)
        
        # 2. Utilisation du syst√®me d'initialisation
        logger.info("üöÄ Utilisation du syst√®me d'initialisation hybride...")
        initialization_report = await initialize_search_clients()
        startup_diagnostics.update(initialization_report)
        
        # R√©cup√©rer les clients initialis√©s
        elastic_client = initialization_report.get("clients", {}).get("elasticsearch")
        qdrant_client = initialization_report.get("clients", {}).get("qdrant")
        
        # Log du rapport d'initialisation
        log_initialization_summary(initialization_report)
        
        # 3. Cr√©ation des collections Qdrant si n√©cessaire
        if qdrant_client and qdrant_client._initialized:
            logger.info("üèóÔ∏è V√©rification des collections Qdrant...")
            collections_created = await create_collections_if_needed(qdrant_client)
            if collections_created:
                logger.info("‚úÖ Collections Qdrant pr√™tes")
            else:
                logger.warning("‚ö†Ô∏è Probl√®me avec les collections Qdrant")
        
        # 4. Initialisation des services IA
        ai_diagnostics = await initialize_ai_services()
        startup_diagnostics["ai_services"] = ai_diagnostics
        
        # 5. Initialisation du cache et des m√©triques
        utils_diagnostics = initialize_cache_and_metrics()
        startup_diagnostics["utilities"] = utils_diagnostics
        
        # 6. Injection des d√©pendances APR√àS initialisation
        inject_dependencies()
        
        # 7. Validation finale de la fonctionnalit√©
        logger.info("üß™ Validation finale de la fonctionnalit√©...")
        functionality_validation = await validate_clients_functionality(elastic_client, qdrant_client)
        startup_diagnostics["functionality_validation"] = functionality_validation
        
        # 8. G√©n√©ration du r√©sum√© final
        summary = generate_startup_summary()
        
        # Point de contr√¥le pour la sant√© g√©n√©rale
        if summary["status"] == "FAILED":
            logger.error("üö® ATTENTION: Aucun service critique disponible")
            logger.error("üí° Le service d√©marre quand m√™me pour permettre le debugging")
        
        logger.info("üéØ Service de recherche Harena d√©marr√© et pr√™t")
        
        # === PHASE D'EX√âCUTION ===
        yield
        
    except Exception as e:
        logger.error(f"üí• Erreur critique lors du d√©marrage: {e}", exc_info=True)
        raise
    
    finally:
        # === PHASE D'ARR√äT ===
        logger.info("üîÑ Arr√™t du service de recherche...")
        
        # Fermeture des clients
        if elastic_client:
            try:
                await elastic_client.close()
                logger.info("‚úÖ Client Elasticsearch ferm√©")
            except Exception as e:
                logger.error(f"‚ùå Erreur fermeture Elasticsearch: {e}")
        
        if qdrant_client:
            try:
                await qdrant_client.close()
                logger.info("‚úÖ Client Qdrant ferm√©")
            except Exception as e:
                logger.error(f"‚ùå Erreur fermeture Qdrant: {e}")
        
        # Fermeture des services IA
        if embedding_service:
            try:
                if hasattr(embedding_service, 'close'):
                    await embedding_service.close()
                logger.info("‚úÖ Service embeddings ferm√©")
            except Exception as e:
                logger.error(f"‚ùå Erreur fermeture embeddings: {e}")
        
        if reranker_service:
            try:
                if hasattr(reranker_service, 'close'):
                    await reranker_service.close()
                logger.info("‚úÖ Service reranking ferm√©")
            except Exception as e:
                logger.error(f"‚ùå Erreur fermeture reranking: {e}")
        
        logger.info("üèÅ Service de recherche arr√™t√©")

# ==================== CR√âATION DE L'APPLICATION ====================

def create_app() -> FastAPI:
    """Cr√©e et configure l'application FastAPI."""
    
    app = FastAPI(
        title="Harena Search Service",
        description="Service de recherche hybride pour transactions financi√®res",
        version="2.0.0",
        docs_url="/docs" if ROUTES_AVAILABLE else None,
        redoc_url="/redoc" if ROUTES_AVAILABLE else None,
        lifespan=lifespan
    )
    
    # Configuration CORS
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # √Ä restreindre en production
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # Inclusion des routes si disponibles
    if ROUTES_AVAILABLE and router:
        app.include_router(router, prefix="/api/v1")
        logger.info("‚úÖ Routes API incluses")
    else:
        logger.warning("‚ö†Ô∏è Routes API non disponibles - endpoints de base uniquement")
    
    # Route de sant√© simple
    @app.get("/health")
    async def health_check():
        """Check de sant√© simple du service."""
        global elastic_client, qdrant_client
        
        health_status = {
            "service": "search_service",
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "version": "2.0.0",
            "uptime_seconds": (time.time() - startup_time) if startup_time else 0,
            "components": {
                "elasticsearch": {
                    "available": elastic_client is not None and getattr(elastic_client, '_initialized', False),
                    "client_type": getattr(elastic_client, 'client_type', None) if elastic_client else None
                },
                "qdrant": {
                    "available": qdrant_client is not None and getattr(qdrant_client, '_initialized', False)
                },
                "ai_services": {
                    "embeddings": embedding_service is not None,
                    "reranking": reranker_service is not None
                },
                "utilities": {
                    "cache": search_cache is not None,
                    "metrics": metrics_collector is not None
                }
            }
        }
        
        # D√©terminer le statut global
        critical_ok = (health_status["components"]["elasticsearch"]["available"] and 
                      health_status["components"]["qdrant"]["available"])
        
        if critical_ok:
            health_status["status"] = "healthy"
        elif (health_status["components"]["elasticsearch"]["available"] or 
              health_status["components"]["qdrant"]["available"]):
            health_status["status"] = "degraded"
        else:
            health_status["status"] = "unhealthy"
        
        return health_status
    
    # Route de diagnostics d√©taill√©s
    @app.get("/diagnostics")
    async def get_diagnostics():
        """Retourne les diagnostics d√©taill√©s du d√©marrage."""
        global startup_diagnostics, full_diagnostic_report
        
        return {
            "service": "search_service",
            "timestamp": datetime.now().isoformat(),
            "startup_diagnostics": startup_diagnostics,
            "full_diagnostic_report": full_diagnostic_report,
            "current_status": {
                "elasticsearch_initialized": elastic_client is not None and getattr(elastic_client, '_initialized', False),
                "qdrant_initialized": qdrant_client is not None and getattr(qdrant_client, '_initialized', False),
                "elasticsearch_type": getattr(elastic_client, 'client_type', None) if elastic_client else None,
                "uptime_seconds": (time.time() - startup_time) if startup_time else 0,
                "services_available": {
                    "routes": ROUTES_AVAILABLE,
                    "embedding_service": EMBEDDING_SERVICE_AVAILABLE,
                    "reranker_service": RERANKER_SERVICE_AVAILABLE,
                    "cache_service": CACHE_SERVICE_AVAILABLE,
                    "metrics_service": METRICS_SERVICE_AVAILABLE
                }
            }
        }
    
    # Route de test de connectivit√©
    @app.get("/connectivity")
    async def test_connectivity():
        """Teste la connectivit√© des services en temps r√©el."""
        test_results = {
            "timestamp": datetime.now().isoformat(),
            "elasticsearch": {"available": False, "healthy": False, "error": None},
            "qdrant": {"available": False, "healthy": False, "error": None}
        }
        
        # Test Elasticsearch
        if elastic_client and elastic_client._initialized:
            try:
                test_results["elasticsearch"]["available"] = True
                test_results["elasticsearch"]["healthy"] = await elastic_client.is_healthy()
            except Exception as e:
                test_results["elasticsearch"]["error"] = str(e)
        else:
            test_results["elasticsearch"]["error"] = "Client not initialized"
        
        # Test Qdrant
        if qdrant_client and qdrant_client._initialized:
            try:
                test_results["qdrant"]["available"] = True
                test_results["qdrant"]["healthy"] = await qdrant_client.is_healthy()
            except Exception as e:
                test_results["qdrant"]["error"] = str(e)
        else:
            test_results["qdrant"]["error"] = "Client not initialized"
        
        return test_results
    
    # Route d'informations syst√®me
    @app.get("/info")
    async def get_system_info():
        """Retourne les informations syst√®me du service."""
        import platform
        
        return {
            "service": "harena_search_service",
            "version": "2.0.0",
            "timestamp": datetime.now().isoformat(),
            "uptime_seconds": (time.time() - startup_time) if startup_time else 0,
            "system": {
                "platform": platform.platform(),
                "python_version": platform.python_version(),
                "architecture": platform.architecture()
            },
            "configuration": {
                "bonsai_configured": bool(settings.BONSAI_URL),
                "qdrant_configured": bool(settings.QDRANT_URL),
                "openai_configured": bool(settings.OPENAI_API_KEY),
                "cohere_configured": bool(getattr(settings, 'COHERE_KEY', None))
            },
            "features": {
                "lexical_search": elastic_client is not None and getattr(elastic_client, '_initialized', False),
                "semantic_search": qdrant_client is not None and getattr(qdrant_client, '_initialized', False),
                "hybrid_search": (elastic_client is not None and getattr(elastic_client, '_initialized', False) and
                                qdrant_client is not None and getattr(qdrant_client, '_initialized', False)),
                "api_routes": ROUTES_AVAILABLE,
                "ai_embeddings": embedding_service is not None,
                "ai_reranking": reranker_service is not None
            }
        }
    
    # Gestionnaire d'erreur global
    @app.exception_handler(Exception)
    async def global_exception_handler(request, exc):
        """Gestionnaire d'erreur global pour toutes les exceptions."""
        logger.error(f"Erreur non g√©r√©e: {exc}", exc_info=True)
        
        return JSONResponse(
            status_code=500,
            content={
                "error": "Internal server error",
                "message": "Une erreur inattendue s'est produite",
                "timestamp": datetime.now().isoformat(),
                "service": "search_service"
            }
        )
    
    return app

# ==================== POINT D'ENTR√âE ====================

# Cr√©er l'application
app = create_app()

if __name__ == "__main__":
    import uvicorn
    
    # Configuration du serveur
    port = int(os.environ.get("PORT", 8000))
    host = os.environ.get("HOST", "0.0.0.0")
    
    logger.info(f"üöÄ D√©marrage du serveur sur {host}:{port}")
    
    # D√©marrer le serveur
    uvicorn.run(
        "search_service.main:app",
        host=host,
        port=port,
        reload=False,  # D√©sactiv√© en production
        access_log=True,
        log_level="info"
    )