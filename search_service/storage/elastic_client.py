"""
Client Elasticsearch avec logging amÃ©liorÃ© pour le monitoring et le debugging.
"""
import logging
import time
from typing import List, Dict, Any, Optional
from elasticsearch import AsyncElasticsearch
from elasticsearch.exceptions import ConnectionError, NotFoundError, RequestError, TransportError

from config_service.config import settings

# Configuration du logger spÃ©cifique Ã  Elasticsearch
logger = logging.getLogger("search_service.elasticsearch")
# Logger sÃ©parÃ© pour les mÃ©triques
metrics_logger = logging.getLogger("search_service.metrics.elasticsearch")


class ElasticClient:
    """Client pour interagir avec Elasticsearch avec logging amÃ©liorÃ©."""
    
    def __init__(self):
        self.client = None
        self.index_name = "harena_transactions"
        self._initialized = False
        self._connection_attempts = 0
        self._last_health_check = None
        
    async def initialize(self):
        """Initialise la connexion Elasticsearch avec logging dÃ©taillÃ©."""
        logger.info("ğŸ”„ Initialisation du client Elasticsearch...")
        start_time = time.time()
        
        # Log des configurations
        if settings.SEARCHBOX_URL:
            es_url = settings.SEARCHBOX_URL
            logger.info("ğŸ“¡ Configuration: SearchBox Elasticsearch")
        elif settings.BONSAI_URL:
            es_url = settings.BONSAI_URL
            logger.info("ğŸ“¡ Configuration: Bonsai Elasticsearch")
        else:
            logger.error("âŒ Aucune URL Elasticsearch configurÃ©e (SEARCHBOX_URL/BONSAI_URL)")
            return
        
        # Masquer les credentials dans les logs
        safe_url = self._mask_credentials(es_url)
        logger.info(f"ğŸ”— Connexion Ã : {safe_url}")
        
        try:
            self._connection_attempts += 1
            logger.info(f"ğŸ”„ Tentative de connexion #{self._connection_attempts}")
            
            # CrÃ©er le client avec configuration dÃ©taillÃ©e
            self.client = AsyncElasticsearch(
                [es_url],
                verify_certs=True,
                ssl_show_warn=False,
                max_retries=3,
                retry_on_timeout=True,
                timeout=30,
                headers={
                    "Accept": "application/json",
                    "Content-Type": "application/json"
                }
            )
            
            # Test de connexion avec timeout
            logger.info("â±ï¸ Test de connexion...")
            connection_start = time.time()
            
            info = await self.client.info()
            connection_time = time.time() - connection_start
            
            # Logs dÃ©taillÃ©s de la connexion
            logger.info(f"âœ… Connexion rÃ©ussie en {connection_time:.2f}s")
            logger.info(f"ğŸ“Š Elasticsearch version: {info['version']['number']}")
            logger.info(f"ğŸ·ï¸ Cluster name: {info['cluster_name']}")
            logger.info(f"ğŸ†” Cluster UUID: {info['cluster_uuid']}")
            
            # MÃ©triques de connexion
            metrics_logger.info(f"elasticsearch.connection.success,time={connection_time:.3f},attempt={self._connection_attempts}")
            
            # VÃ©rifier la santÃ© du cluster
            await self._check_cluster_health()
            
            # CrÃ©er l'index si nÃ©cessaire
            await self._setup_index()
            
            self._initialized = True
            total_time = time.time() - start_time
            logger.info(f"ğŸ‰ Client Elasticsearch initialisÃ© avec succÃ¨s en {total_time:.2f}s")
            
        except ConnectionError as e:
            logger.error(f"ğŸ”Œ Erreur de connexion Elasticsearch: {e}")
            metrics_logger.error(f"elasticsearch.connection.failed,type=connection,attempt={self._connection_attempts}")
            self._handle_connection_error(e)
            
        except TransportError as e:
            logger.error(f"ğŸš« Erreur de transport Elasticsearch: {e}")
            logger.error(f"ğŸ“ Status code: {e.status_code if hasattr(e, 'status_code') else 'N/A'}")
            metrics_logger.error(f"elasticsearch.connection.failed,type=transport,status={getattr(e, 'status_code', 'unknown')}")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ Erreur inattendue lors de l'initialisation Elasticsearch: {type(e).__name__}: {e}")
            logger.error(f"ğŸ“ DÃ©tails: {str(e)}", exc_info=True)
            metrics_logger.error(f"elasticsearch.connection.failed,type=unexpected,error={type(e).__name__}")
            
        finally:
            if not self._initialized:
                self.client = None
                logger.warning("âš ï¸ Client Elasticsearch non initialisÃ© - recherche lexicale indisponible")
    
    async def _check_cluster_health(self):
        """VÃ©rifie la santÃ© du cluster Elasticsearch."""
        try:
            logger.info("ğŸ©º VÃ©rification de la santÃ© du cluster...")
            health = await self.client.cluster.health()
            
            status = health.get('status', 'unknown')
            logger.info(f"ğŸ’š SantÃ© cluster: {status}")
            logger.info(f"ğŸ“Š NÅ“uds: {health.get('number_of_nodes', 'unknown')}")
            logger.info(f"ğŸ“Š NÅ“uds data: {health.get('number_of_data_nodes', 'unknown')}")
            logger.info(f"ğŸ“Š Shards actifs: {health.get('active_shards', 'unknown')}")
            
            if status == 'red':
                logger.error("ğŸš¨ CLUSTER EN Ã‰TAT CRITIQUE (red)")
            elif status == 'yellow':
                logger.warning("âš ï¸ Cluster en Ã©tat dÃ©gradÃ© (yellow)")
            else:
                logger.info("âœ… Cluster en bonne santÃ© (green)")
                
            metrics_logger.info(f"elasticsearch.cluster.health,status={status},nodes={health.get('number_of_nodes', 0)}")
            
        except Exception as e:
            logger.error(f"âŒ Impossible de vÃ©rifier la santÃ© du cluster: {e}")
    
    async def search(
        self,
        user_id: int,
        query: Dict[str, Any],
        limit: int = 20,
        filters: Optional[Dict[str, Any]] = None,
        include_highlights: bool = False
    ) -> List[Dict[str, Any]]:
        """Effectue une recherche avec logging dÃ©taillÃ©."""
        if not self.client:
            logger.error("âŒ Client Elasticsearch non initialisÃ©")
            return []
        
        search_id = f"search_{int(time.time()*1000)}"
        logger.info(f"ğŸ” [{search_id}] DÃ©but recherche pour user_id={user_id}")
        
        start_time = time.time()
        
        try:
            # Log des paramÃ¨tres de recherche
            logger.debug(f"ğŸ” [{search_id}] ParamÃ¨tres: limit={limit}, highlights={include_highlights}")
            logger.debug(f"ğŸ” [{search_id}] Filtres: {filters}")
            logger.debug(f"ğŸ” [{search_id}] RequÃªte: {query}")
            
            # Construire la requÃªte
            search_body = {
                "query": query,
                "size": limit,
                "sort": [
                    {"_score": {"order": "desc"}},
                    {"date": {"order": "desc"}}
                ]
            }
            
            # Ajouter les filtres
            if filters:
                logger.debug(f"ğŸ” [{search_id}] Application des filtres")
                # Logique de filtrage...
            
            # Ajouter le highlighting
            if include_highlights:
                logger.debug(f"ğŸ” [{search_id}] Highlighting activÃ©")
                search_body["highlight"] = {
                    "fields": {
                        "searchable_text": {},
                        "primary_description": {},
                        "merchant_name": {},
                        "category_name": {}
                    },
                    "pre_tags": ["<em>"],
                    "post_tags": ["</em>"],
                    "fragment_size": 150
                }
            
            # ExÃ©cuter la recherche
            logger.info(f"ğŸ” [{search_id}] ExÃ©cution de la requÃªte...")
            query_start = time.time()
            
            response = await self.client.search(
                index=self.index_name,
                body=search_body
            )
            
            query_time = time.time() - query_start
            total_time = time.time() - start_time
            
            # Analyser les rÃ©sultats
            hits = response.get("hits", {})
            total_hits = hits.get("total", {})
            
            if isinstance(total_hits, dict):
                total_count = total_hits.get("value", 0)
                relation = total_hits.get("relation", "eq")
            else:
                total_count = total_hits
                relation = "eq"
            
            results = hits.get("hits", [])
            
            # Logs de rÃ©sultats
            logger.info(f"âœ… [{search_id}] Recherche terminÃ©e en {total_time:.3f}s")
            logger.info(f"ğŸ“Š [{search_id}] RÃ©sultats: {len(results)}/{total_count} ({relation})")
            logger.info(f"â±ï¸ [{search_id}] Temps requÃªte: {query_time:.3f}s")
            
            # MÃ©triques dÃ©taillÃ©es
            metrics_logger.info(
                f"elasticsearch.search.success,"
                f"user_id={user_id},"
                f"query_time={query_time:.3f},"
                f"total_time={total_time:.3f},"
                f"results={len(results)},"
                f"total_available={total_count}"
            )
            
            # Log des scores si en mode debug
            if logger.isEnabledFor(logging.DEBUG):
                for i, hit in enumerate(results[:5]):  # Top 5 seulement
                    score = hit.get("_score", 0)
                    source = hit.get("_source", {})
                    description = source.get("primary_description", "N/A")[:50]
                    logger.debug(f"ğŸ“Š [{search_id}] #{i+1}: score={score:.3f}, desc='{description}...'")
            
            return results
            
        except NotFoundError as e:
            logger.error(f"âŒ [{search_id}] Index non trouvÃ©: {self.index_name}")
            metrics_logger.error(f"elasticsearch.search.failed,type=not_found,user_id={user_id}")
            return []
            
        except RequestError as e:
            logger.error(f"âŒ [{search_id}] Erreur de requÃªte: {e}")
            logger.error(f"ğŸ“ [{search_id}] DÃ©tails: {e.info if hasattr(e, 'info') else 'N/A'}")
            metrics_logger.error(f"elasticsearch.search.failed,type=request_error,user_id={user_id}")
            return []
            
        except TransportError as e:
            logger.error(f"ğŸš« [{search_id}] Erreur de transport: {e}")
            self._handle_transport_error(e, search_id)
            metrics_logger.error(f"elasticsearch.search.failed,type=transport,user_id={user_id}")
            return []
            
        except Exception as e:
            search_time = time.time() - start_time
            logger.error(f"ğŸ’¥ [{search_id}] Erreur inattendue aprÃ¨s {search_time:.3f}s: {type(e).__name__}: {e}")
            logger.error(f"ğŸ“ [{search_id}] DÃ©tails", exc_info=True)
            metrics_logger.error(f"elasticsearch.search.failed,type=unexpected,user_id={user_id},error={type(e).__name__}")
            return []
    
    async def is_healthy(self) -> bool:
        """VÃ©rifie l'Ã©tat de santÃ© avec logging dÃ©taillÃ©."""
        if not self.client:
            logger.debug("âŒ Client non initialisÃ©")
            return False
        
        try:
            logger.debug("ğŸ©º VÃ©rification santÃ© client...")
            start_time = time.time()
            
            # Ping simple
            ping_result = await self.client.ping()
            ping_time = time.time() - start_time
            
            if ping_result:
                logger.debug(f"âœ… Ping rÃ©ussi en {ping_time:.3f}s")
                metrics_logger.info(f"elasticsearch.health.ping.success,time={ping_time:.3f}")
                
                # VÃ©rification plus approfondie
                if time.time() - (self._last_health_check or 0) > 60:  # Chaque minute
                    await self._detailed_health_check()
                    self._last_health_check = time.time()
                
                return True
            else:
                logger.warning(f"âš ï¸ Ping Ã©chouÃ© en {ping_time:.3f}s")
                metrics_logger.warning(f"elasticsearch.health.ping.failed,time={ping_time:.3f}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erreur lors du health check: {type(e).__name__}: {e}")
            metrics_logger.error(f"elasticsearch.health.check.failed,error={type(e).__name__}")
            return False
    
    async def _detailed_health_check(self):
        """Effectue une vÃ©rification de santÃ© approfondie."""
        try:
            logger.debug("ğŸ” VÃ©rification santÃ© dÃ©taillÃ©e...")
            
            # VÃ©rifier l'index
            exists = await self.client.indices.exists(index=self.index_name)
            if not exists:
                logger.error(f"âŒ Index {self.index_name} n'existe pas")
                metrics_logger.error("elasticsearch.health.index.missing")
                return
            
            # Statistiques de l'index
            stats = await self.client.indices.stats(index=self.index_name)
            index_stats = stats.get("indices", {}).get(self.index_name, {})
            
            total_docs = index_stats.get("total", {}).get("docs", {}).get("count", 0)
            store_size = index_stats.get("total", {}).get("store", {}).get("size_in_bytes", 0)
            
            logger.info(f"ğŸ“Š Index stats: {total_docs} documents, {store_size} bytes")
            metrics_logger.info(f"elasticsearch.index.stats,docs={total_docs},size={store_size}")
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la vÃ©rification dÃ©taillÃ©e: {e}")
    
    def _mask_credentials(self, url: str) -> str:
        """Masque les credentials dans l'URL pour les logs."""
        if "@" in url:
            # Format: https://user:pass@host:port/path
            parts = url.split("@")
            if len(parts) == 2:
                protocol_and_creds = parts[0]
                host_and_path = parts[1]
                
                if "://" in protocol_and_creds:
                    protocol = protocol_and_creds.split("://")[0]
                    return f"{protocol}://***:***@{host_and_path}"
        
        return url
    
    def _handle_connection_error(self, error):
        """GÃ¨re les erreurs de connexion avec logging dÃ©taillÃ©."""
        logger.error("ğŸ”Œ Diagnostic de l'erreur de connexion:")
        logger.error(f"   - Type: {type(error).__name__}")
        logger.error(f"   - Message: {str(error)}")
        
        # Suggestions de diagnostic
        logger.error("ğŸ”§ Actions de diagnostic suggÃ©rÃ©es:")
        logger.error("   - VÃ©rifier la connectivitÃ© rÃ©seau")
        logger.error("   - Valider les credentials Elasticsearch")
        logger.error("   - ContrÃ´ler les variables d'environnement")
        logger.error("   - Tester la connection depuis un autre client")
    
    def _handle_transport_error(self, error, search_id):
        """GÃ¨re les erreurs de transport avec contexte."""
        status_code = getattr(error, 'status_code', 'unknown')
        logger.error(f"ğŸš« [{search_id}] Erreur transport - Status: {status_code}")
        
        if status_code == 429:
            logger.error(f"ğŸš« [{search_id}] Rate limiting dÃ©tectÃ©")
        elif status_code >= 500:
            logger.error(f"ğŸš« [{search_id}] Erreur serveur Elasticsearch")
        elif status_code >= 400:
            logger.error(f"ğŸš« [{search_id}] Erreur client - vÃ©rifier la requÃªte")
    
    async def close(self):
        """Ferme la connexion avec logging."""
        if self.client:
            logger.info("ğŸ”’ Fermeture connexion Elasticsearch...")
            await self.client.close()
            self._initialized = False
            logger.info("âœ… Connexion Elasticsearch fermÃ©e")
        else:
            logger.debug("ğŸ”’ Aucun client Ã  fermer")