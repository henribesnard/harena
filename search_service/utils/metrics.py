"""
MÃ©triques spÃ©cialisÃ©es pour le Search Service
===========================================

Module de collecte, agrÃ©gation et analyse des mÃ©triques de performance
pour tous les composants du Search Service :
- MÃ©triques Elasticsearch (latence, throughput, erreurs)
- MÃ©triques lexicales (pertinence, qualitÃ©, cache)
- MÃ©triques d'exÃ©cution (requÃªtes, optimisations)
- MÃ©triques de traitement (formatage, enrichissement)
- MÃ©triques systÃ¨me (mÃ©moire, CPU, I/O)

Architecture :
    Component â†’ MetricsCollector â†’ MetricsAggregator â†’ MetricsReporter â†’ Dashboard/Alerts
"""

import logging
import time
import threading
from typing import Dict, List, Optional, Any, Union, Callable, Set
from enum import Enum
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from collections import defaultdict, deque
import statistics
import json
import hashlib
from contextlib import contextmanager
import psutil

from config import settings


logger = logging.getLogger(__name__)


class MetricType(str, Enum):
    """Types de mÃ©triques collectÃ©es"""
    COUNTER = "counter"           # Compteur incrÃ©mental (requÃªtes totales)
    GAUGE = "gauge"              # Valeur instantanÃ©e (requÃªtes actives)
    HISTOGRAM = "histogram"      # Distribution de valeurs (temps de rÃ©ponse)
    TIMER = "timer"              # DurÃ©e d'opÃ©rations
    RATE = "rate"                # Taux par seconde
    PERCENTAGE = "percentage"    # Pourcentage (0-100)
    BYTES = "bytes"              # Tailles en octets
    THROUGHPUT = "throughput"    # DÃ©bit (ops/sec)


class MetricCategory(str, Enum):
    """CatÃ©gories de mÃ©triques"""
    ELASTICSEARCH = "elasticsearch"     # MÃ©triques ES
    LEXICAL_SEARCH = "lexical_search"  # MÃ©triques recherche lexicale
    QUERY_EXECUTION = "query_execution" # MÃ©triques exÃ©cution
    RESULT_PROCESSING = "result_processing" # MÃ©triques traitement rÃ©sultats
    CACHE = "cache"                    # MÃ©triques cache
    PERFORMANCE = "performance"        # MÃ©triques performance globale
    SYSTEM = "system"                  # MÃ©triques systÃ¨me
    API = "api"                        # MÃ©triques API REST
    BUSINESS = "business"              # MÃ©triques mÃ©tier


class AlertLevel(str, Enum):
    """Niveaux d'alerte"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class MetricDefinition:
    """DÃ©finition d'une mÃ©trique"""
    name: str
    type: MetricType
    category: MetricCategory
    description: str
    unit: str = ""
    tags: Set[str] = field(default_factory=set)
    warning_threshold: Optional[float] = None
    error_threshold: Optional[float] = None
    critical_threshold: Optional[float] = None
    retention_hours: int = 24
    aggregation_functions: List[str] = field(default_factory=lambda: ["avg", "count"])


@dataclass
class MetricValue:
    """Valeur d'une mÃ©trique avec mÃ©tadonnÃ©es"""
    name: str
    value: Union[int, float]
    timestamp: datetime
    tags: Dict[str, str] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class MetricSample:
    """Ã‰chantillon de mÃ©trique pour agrÃ©gation"""
    timestamp: datetime
    value: Union[int, float]
    tags: Dict[str, str] = field(default_factory=dict)


class MetricAlert:
    """Alerte basÃ©e sur une mÃ©trique"""
    
    def __init__(self, metric_name: str, level: AlertLevel, 
                 threshold: float, current_value: float, message: str):
        self.metric_name = metric_name
        self.level = level
        self.threshold = threshold
        self.current_value = current_value
        self.message = message
        self.timestamp = datetime.now()
        self.alert_id = self._generate_alert_id()
    
    def _generate_alert_id(self) -> str:
        """GÃ©nÃ¨re un ID unique pour l'alerte"""
        content = f"{self.metric_name}_{self.level}_{self.timestamp.isoformat()}"
        return hashlib.md5(content.encode()).hexdigest()[:8]
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit l'alerte en dictionnaire"""
        return {
            "alert_id": self.alert_id,
            "metric_name": self.metric_name,
            "level": self.level.value,
            "threshold": self.threshold,
            "current_value": self.current_value,
            "message": self.message,
            "timestamp": self.timestamp.isoformat()
        }


class MetricsCollector:
    """Collecteur de mÃ©triques thread-safe"""
    
    def __init__(self, max_samples_per_metric: int = 10000):
        self._metrics: Dict[str, deque] = defaultdict(lambda: deque(maxlen=max_samples_per_metric))
        self._definitions: Dict[str, MetricDefinition] = {}
        self._lock = threading.RLock()
        self._start_time = datetime.now()
        
        # MÃ©triques systÃ¨me automatiques
        self._system_metrics_enabled = True
        self._system_metrics_interval = 30  # secondes
        
        self._register_default_metrics()
        self._start_system_metrics_collection()
    
    def register_metric(self, definition: MetricDefinition):
        """Enregistre une nouvelle mÃ©trique"""
        with self._lock:
            self._definitions[definition.name] = definition
            logger.debug(f"MÃ©trique enregistrÃ©e: {definition.name}")
    
    def record(self, name: str, value: Union[int, float], 
               tags: Optional[Dict[str, str]] = None):
        """Enregistre une valeur de mÃ©trique"""
        
        if name not in self._definitions:
            logger.warning(f"MÃ©trique non dÃ©finie: {name}")
            return
        
        sample = MetricSample(
            timestamp=datetime.now(),
            value=value,
            tags=tags or {}
        )
        
        with self._lock:
            self._metrics[name].append(sample)
    
    def increment(self, name: str, amount: Union[int, float] = 1,
                  tags: Optional[Dict[str, str]] = None):
        """IncrÃ©mente un compteur"""
        
        # RÃ©cupÃ©rer la valeur actuelle et l'incrÃ©menter
        current = self.get_current_value(name, default=0)
        self.record(name, current + amount, tags)
    
    def set_gauge(self, name: str, value: Union[int, float],
                  tags: Optional[Dict[str, str]] = None):
        """DÃ©finit la valeur d'une gauge"""
        self.record(name, value, tags)
    
    @contextmanager
    def timer(self, name: str, tags: Optional[Dict[str, str]] = None):
        """Context manager pour mesurer la durÃ©e"""
        start_time = time.time()
        try:
            yield
        finally:
            duration_ms = (time.time() - start_time) * 1000
            self.record(name, duration_ms, tags)
    
    def get_current_value(self, name: str, default: Any = None) -> Any:
        """RÃ©cupÃ¨re la valeur actuelle d'une mÃ©trique"""
        with self._lock:
            samples = self._metrics.get(name)
            if samples:
                return samples[-1].value
            return default
    
    def get_samples(self, name: str, since: Optional[datetime] = None,
                   limit: Optional[int] = None) -> List[MetricSample]:
        """RÃ©cupÃ¨re les Ã©chantillons d'une mÃ©trique"""
        
        with self._lock:
            samples = list(self._metrics.get(name, []))
        
        # Filtrer par date si spÃ©cifiÃ©e
        if since:
            samples = [s for s in samples if s.timestamp >= since]
        
        # Limiter le nombre de rÃ©sultats
        if limit:
            samples = samples[-limit:]
        
        return samples
    
    def get_metric_stats(self, name: str, since: Optional[datetime] = None) -> Dict[str, Any]:
        """Calcule les statistiques d'une mÃ©trique"""
        
        samples = self.get_samples(name, since)
        if not samples:
            return {"count": 0}
        
        values = [s.value for s in samples]
        
        stats = {
            "count": len(values),
            "min": min(values),
            "max": max(values),
            "avg": statistics.mean(values),
            "sum": sum(values),
            "first": values[0],
            "last": values[-1]
        }
        
        if len(values) > 1:
            stats["median"] = statistics.median(values)
            stats["std_dev"] = statistics.stdev(values)
            
            # Percentiles
            if len(values) >= 10:
                sorted_values = sorted(values)
                stats["p50"] = statistics.median(sorted_values)
                stats["p90"] = sorted_values[int(0.9 * len(sorted_values))]
                stats["p95"] = sorted_values[int(0.95 * len(sorted_values))]
                stats["p99"] = sorted_values[int(0.99 * len(sorted_values))]
        
        return stats
    
    def _register_default_metrics(self):
        """Enregistre les mÃ©triques par dÃ©faut"""
        
        default_metrics = [
            # MÃ©triques Elasticsearch
            MetricDefinition(
                "elasticsearch_search_duration_ms",
                MetricType.HISTOGRAM,
                MetricCategory.ELASTICSEARCH,
                "DurÃ©e des requÃªtes Elasticsearch en millisecondes",
                "ms",
                warning_threshold=100,
                error_threshold=500,
                critical_threshold=2000
            ),
            MetricDefinition(
                "elasticsearch_search_count",
                MetricType.COUNTER,
                MetricCategory.ELASTICSEARCH,
                "Nombre total de requÃªtes Elasticsearch"
            ),
            MetricDefinition(
                "elasticsearch_error_count",
                MetricType.COUNTER,
                MetricCategory.ELASTICSEARCH,
                "Nombre d'erreurs Elasticsearch"
            ),
            MetricDefinition(
                "elasticsearch_cache_hit_rate",
                MetricType.PERCENTAGE,
                MetricCategory.ELASTICSEARCH,
                "Taux de cache hit Elasticsearch",
                "%"
            ),
            
            # MÃ©triques recherche lexicale
            MetricDefinition(
                "lexical_search_duration_ms",
                MetricType.HISTOGRAM,
                MetricCategory.LEXICAL_SEARCH,
                "DurÃ©e totale recherche lexicale",
                "ms",
                warning_threshold=50,
                error_threshold=200,
                critical_threshold=1000
            ),
            MetricDefinition(
                "lexical_search_quality_score",
                MetricType.HISTOGRAM,
                MetricCategory.LEXICAL_SEARCH,
                "Score de qualitÃ© des rÃ©sultats de recherche"
            ),
            MetricDefinition(
                "lexical_cache_hit_rate",
                MetricType.PERCENTAGE,
                MetricCategory.CACHE,
                "Taux de cache hit du moteur lexical",
                "%"
            ),
            
            # MÃ©triques exÃ©cution de requÃªtes
            MetricDefinition(
                "query_execution_duration_ms",
                MetricType.HISTOGRAM,
                MetricCategory.QUERY_EXECUTION,
                "DurÃ©e d'exÃ©cution des requÃªtes",
                "ms"
            ),
            MetricDefinition(
                "query_optimization_count",
                MetricType.COUNTER,
                MetricCategory.QUERY_EXECUTION,
                "Nombre d'optimisations appliquÃ©es"
            ),
            
            # MÃ©triques traitement rÃ©sultats
            MetricDefinition(
                "result_processing_duration_ms",
                MetricType.HISTOGRAM,
                MetricCategory.RESULT_PROCESSING,
                "DurÃ©e de traitement des rÃ©sultats",
                "ms"
            ),
            MetricDefinition(
                "results_processed_count",
                MetricType.COUNTER,
                MetricCategory.RESULT_PROCESSING,
                "Nombre de rÃ©sultats traitÃ©s"
            ),
            
            # MÃ©triques API
            MetricDefinition(
                "api_request_duration_ms",
                MetricType.HISTOGRAM,
                MetricCategory.API,
                "DurÃ©e des requÃªtes API",
                "ms"
            ),
            MetricDefinition(
                "api_request_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre de requÃªtes API"
            ),
            MetricDefinition(
                "api_error_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'erreurs API"
            ),
            
            # MÃ©triques systÃ¨me
            MetricDefinition(
                "system_memory_usage_bytes",
                MetricType.GAUGE,
                MetricCategory.SYSTEM,
                "Usage mÃ©moire du processus",
                "bytes",
                warning_threshold=512*1024*1024,  # 512MB
                error_threshold=1024*1024*1024,   # 1GB
                critical_threshold=2048*1024*1024  # 2GB
            ),
            MetricDefinition(
                "system_cpu_usage_percent",
                MetricType.GAUGE,
                MetricCategory.SYSTEM,
                "Usage CPU du processus",
                "%",
                warning_threshold=70,
                error_threshold=85,
                critical_threshold=95
            ),
            
            # MÃ©triques mÃ©tier
            MetricDefinition(
                "search_intent_success_rate",
                MetricType.PERCENTAGE,
                MetricCategory.BUSINESS,
                "Taux de succÃ¨s de dÃ©tection d'intention",
                "%"
            ),
            MetricDefinition(
                "user_satisfaction_score",
                MetricType.HISTOGRAM,
                MetricCategory.BUSINESS,
                "Score de satisfaction utilisateur (1-5)"
            ),
            MetricDefinition(
                "api_search_duration_ms",
                MetricType.HISTOGRAM,
                MetricCategory.API,
                "DurÃ©e des appels API de recherche",
                "ms",
                warning_threshold=200,
                error_threshold=1000,
                critical_threshold=5000
            ),
            MetricDefinition(
                "api_search_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'appels API de recherche"
            ),
            MetricDefinition(
                "api_search_success_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'appels API de recherche rÃ©ussis"
            ),
            MetricDefinition(
                "api_search_error_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'erreurs API de recherche"
            ),
            MetricDefinition(
                "api_search_results_count",
                MetricType.HISTOGRAM,
                MetricCategory.API,
                "Nombre de rÃ©sultats retournÃ©s par recherche"
            ),
            MetricDefinition(
                "api_validation_duration_ms",
                MetricType.HISTOGRAM,
                MetricCategory.API,
                "DurÃ©e des appels API de validation",
                "ms"
            ),
            MetricDefinition(
                "api_validation_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'appels API de validation"
            ),
            MetricDefinition(
                "api_validation_success_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre de validations rÃ©ussies"
            ),
            MetricDefinition(
                "api_validation_error_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'erreurs de validation"
            ),
            MetricDefinition(
                "api_health_percentage",
                MetricType.GAUGE,
                MetricCategory.API,
                "Pourcentage de santÃ© globale de l'API",
                "%",
                warning_threshold=90,
                error_threshold=75,
                critical_threshold=50
            ),
            MetricDefinition(
                "api_rate_limit_exceeded",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre de dÃ©passements de limite de taux"
            ),
            MetricDefinition(
                "api_auth_attempts",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre de tentatives d'authentification"
            ),
            MetricDefinition(
                "api_auth_success_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'authentifications rÃ©ussies"
            ),
            MetricDefinition(
                "api_auth_failure_count",
                MetricType.COUNTER,
                MetricCategory.API,
                "Nombre d'Ã©checs d'authentification"
            )
        ]
        
        for metric in default_metrics:
            self.register_metric(metric)
    
    def _start_system_metrics_collection(self):
        """DÃ©marre la collecte automatique des mÃ©triques systÃ¨me"""
        
        if not self._system_metrics_enabled:
            return
        
        def collect_system_metrics():
            """Collecte les mÃ©triques systÃ¨me pÃ©riodiquement"""
            
            while self._system_metrics_enabled:
                try:
                    # MÃ©triques mÃ©moire
                    process = psutil.Process()
                    memory_info = process.memory_info()
                    self.set_gauge("system_memory_usage_bytes", memory_info.rss)
                    
                    # MÃ©triques CPU
                    cpu_percent = process.cpu_percent()
                    self.set_gauge("system_cpu_usage_percent", cpu_percent)
                    
                    # MÃ©triques disque I/O
                    io_counters = process.io_counters()
                    self.set_gauge("system_disk_read_bytes", io_counters.read_bytes)
                    self.set_gauge("system_disk_write_bytes", io_counters.write_bytes)
                    
                    time.sleep(self._system_metrics_interval)
                    
                except Exception as e:
                    logger.error(f"Erreur lors de la collecte des mÃ©triques systÃ¨me: {e}")
                    time.sleep(self._system_metrics_interval)
        
        # DÃ©marrer le thread de collecte
        thread = threading.Thread(target=collect_system_metrics, daemon=True)
        thread.start()
        logger.info("Collecte automatique des mÃ©triques systÃ¨me dÃ©marrÃ©e")
    
    def cleanup_old_samples(self, hours: int = 24):
        """Nettoie les Ã©chantillons anciens"""
        
        cutoff_time = datetime.now() - timedelta(hours=hours)
        cleaned_count = 0
        
        with self._lock:
            for metric_name, samples in self._metrics.items():
                original_count = len(samples)
                
                # Filtrer les Ã©chantillons rÃ©cents
                recent_samples = deque([
                    sample for sample in samples 
                    if sample.timestamp > cutoff_time
                ], maxlen=samples.maxlen)
                
                self._metrics[metric_name] = recent_samples
                cleaned_count += original_count - len(recent_samples)
        
        if cleaned_count > 0:
            logger.info(f"Nettoyage des mÃ©triques: {cleaned_count} Ã©chantillons supprimÃ©s")
    
    def export_metrics(self, format: str = "json") -> str:
        """Exporte les mÃ©triques dans diffÃ©rents formats"""
        
        if format == "json":
            return self._export_json()
        elif format == "prometheus":
            return self._export_prometheus()
        else:
            raise ValueError(f"Format d'export non supportÃ©: {format}")
    
    def _export_json(self) -> str:
        """Exporte les mÃ©triques au format JSON"""
        
        export_data = {
            "timestamp": datetime.now().isoformat(),
            "uptime_seconds": (datetime.now() - self._start_time).total_seconds(),
            "metrics": {}
        }
        
        for name, definition in self._definitions.items():
            stats = self.get_metric_stats(name)
            export_data["metrics"][name] = {
                "definition": {
                    "type": definition.type.value,
                    "category": definition.category.value,
                    "description": definition.description,
                    "unit": definition.unit
                },
                "stats": stats,
                "current_value": self.get_current_value(name)
            }
        
        return json.dumps(export_data, indent=2, default=str)
    
    def _export_prometheus(self) -> str:
        """Exporte les mÃ©triques au format Prometheus"""
        
        lines = []
        
        for name, definition in self._definitions.items():
            # Nom de mÃ©trique compatible Prometheus
            prom_name = f"{settings.metrics_prefix}_{name}".replace("-", "_")
            
            # Commentaire de description
            lines.append(f"# HELP {prom_name} {definition.description}")
            lines.append(f"# TYPE {prom_name} {self._prometheus_type(definition.type)}")
            
            # Valeur actuelle
            current_value = self.get_current_value(name, 0)
            lines.append(f"{prom_name} {current_value}")
        
        return "\n".join(lines)
    
    def _prometheus_type(self, metric_type: MetricType) -> str:
        """Convertit le type de mÃ©trique vers Prometheus"""
        
        mapping = {
            MetricType.COUNTER: "counter",
            MetricType.GAUGE: "gauge",
            MetricType.HISTOGRAM: "histogram",
            MetricType.TIMER: "histogram"
        }
        
        return mapping.get(metric_type, "gauge")


class AlertManager:
    """Gestionnaire d'alertes basÃ©es sur les mÃ©triques"""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.active_alerts: Dict[str, MetricAlert] = {}
        self.alert_history: deque = deque(maxlen=1000)
        self.alert_callbacks: Dict[AlertLevel, List[Callable]] = defaultdict(list)
        self.check_interval = 60  # secondes
        
        self._start_alert_monitoring()
    
    def add_alert_callback(self, level: AlertLevel, callback: Callable[[MetricAlert], None]):
        """Ajoute un callback pour un niveau d'alerte"""
        self.alert_callbacks[level].append(callback)
    
    def check_alerts(self):
        """VÃ©rifie toutes les mÃ©triques pour les seuils d'alerte"""
        
        for name, definition in self.metrics_collector._definitions.items():
            current_value = self.metrics_collector.get_current_value(name)
            
            if current_value is None:
                continue
            
            # VÃ©rifier les seuils dans l'ordre de gravitÃ©
            alert_level = None
            threshold = None
            
            if (definition.critical_threshold is not None and 
                current_value >= definition.critical_threshold):
                alert_level = AlertLevel.CRITICAL
                threshold = definition.critical_threshold
                
            elif (definition.error_threshold is not None and 
                  current_value >= definition.error_threshold):
                alert_level = AlertLevel.ERROR
                threshold = definition.error_threshold
                
            elif (definition.warning_threshold is not None and 
                  current_value >= definition.warning_threshold):
                alert_level = AlertLevel.WARNING
                threshold = definition.warning_threshold
            
            # CrÃ©er ou mettre Ã  jour l'alerte
            if alert_level:
                self._trigger_alert(name, alert_level, threshold, current_value)
            else:
                # RÃ©soudre l'alerte si elle existait
                self._resolve_alert(name)
    
    def _trigger_alert(self, metric_name: str, level: AlertLevel, 
                      threshold: float, current_value: float):
        """DÃ©clenche une alerte"""
        
        alert_key = f"{metric_name}_{level.value}"
        
        # Ã‰viter les alertes en double
        if alert_key in self.active_alerts:
            return
        
        message = (f"MÃ©trique '{metric_name}' au niveau {level.value}: "
                  f"{current_value} >= {threshold}")
        
        alert = MetricAlert(metric_name, level, threshold, current_value, message)
        
        self.active_alerts[alert_key] = alert
        self.alert_history.append(alert)
        
        # ExÃ©cuter les callbacks
        for callback in self.alert_callbacks[level]:
            try:
                callback(alert)
            except Exception as e:
                logger.error(f"Erreur dans callback d'alerte: {e}")
        
        logger.warning(f"ðŸš¨ ALERTE {level.value.upper()}: {message}")
    
    def _resolve_alert(self, metric_name: str):
        """RÃ©sout une alerte"""
        
        resolved_keys = []
        for alert_key in self.active_alerts:
            if alert_key.startswith(metric_name):
                resolved_keys.append(alert_key)
        
        for key in resolved_keys:
            alert = self.active_alerts.pop(key)
            logger.info(f"âœ… Alerte rÃ©solue: {alert.metric_name}")
    
    def _start_alert_monitoring(self):
        """DÃ©marre la surveillance automatique des alertes"""
        
        def monitor_alerts():
            while True:
                try:
                    self.check_alerts()
                    time.sleep(self.check_interval)
                except Exception as e:
                    logger.error(f"Erreur lors de la vÃ©rification des alertes: {e}")
                    time.sleep(self.check_interval)
        
        thread = threading.Thread(target=monitor_alerts, daemon=True)
        thread.start()
        logger.info("Surveillance automatique des alertes dÃ©marrÃ©e")
    
    def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Retourne les alertes actives"""
        return [alert.to_dict() for alert in self.active_alerts.values()]
    
    def get_alert_history(self, limit: int = 100) -> List[Dict[str, Any]]:
        """Retourne l'historique des alertes"""
        recent_alerts = list(self.alert_history)[-limit:]
        return [alert.to_dict() for alert in recent_alerts]


class SearchMetrics:
    """MÃ©triques spÃ©cialisÃ©es pour la recherche"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_search_request(self, user_id: int, intent_type: str, 
                            query_complexity: str):
        """Enregistre une demande de recherche"""
        
        tags = {
            "user_id": str(user_id),
            "intent_type": intent_type,
            "complexity": query_complexity
        }
        
        self.collector.increment("api_request_count", tags=tags)
        self.collector.increment("lexical_search_count", tags=tags)
    
    def record_search_execution(self, duration_ms: float, cache_hit: bool,
                              results_count: int, quality_score: float):
        """Enregistre l'exÃ©cution d'une recherche"""
        
        tags = {
            "cache_hit": str(cache_hit),
            "has_results": str(results_count > 0)
        }
        
        self.collector.record("lexical_search_duration_ms", duration_ms, tags)
        self.collector.record("lexical_search_quality_score", quality_score, tags)
        self.collector.record("results_processed_count", results_count, tags)
        
        # Mettre Ã  jour le taux de cache hit
        if cache_hit:
            self.collector.increment("lexical_cache_hits")
        self.collector.increment("lexical_cache_requests")
        
        # Calculer le taux
        hits = self.collector.get_current_value("lexical_cache_hits", 0)
        requests = self.collector.get_current_value("lexical_cache_requests", 1)
        hit_rate = (hits / requests) * 100
        self.collector.set_gauge("lexical_cache_hit_rate", hit_rate)
    
    def record_elasticsearch_execution(self, duration_ms: float, 
                                     success: bool, error_type: str = None):
        """Enregistre l'exÃ©cution Elasticsearch"""
        
        tags = {
            "success": str(success),
            "error_type": error_type or "none"
        }
        
        self.collector.record("elasticsearch_search_duration_ms", duration_ms, tags)
        
        if success:
            self.collector.increment("elasticsearch_search_count", tags=tags)
        else:
            self.collector.increment("elasticsearch_error_count", tags=tags)
    
    def record_optimization_applied(self, optimization_type: str, 
                                  improvement_percent: float):
        """Enregistre une optimisation appliquÃ©e"""
        
        tags = {"optimization_type": optimization_type}
        
        self.collector.increment("query_optimization_count", tags=tags)
        self.collector.record("optimization_improvement_percent", 
                            improvement_percent, tags)


class PerformanceProfiler:
    """Profileur de performance pour opÃ©rations critiques"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
        self.active_profiles: Dict[str, datetime] = {}
    
    @contextmanager
    def profile_operation(self, operation_name: str, 
                         tags: Optional[Dict[str, str]] = None):
        """Profile une opÃ©ration avec mÃ©triques dÃ©taillÃ©es"""
        
        profile_id = f"{operation_name}_{time.time()}"
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss
        
        self.active_profiles[profile_id] = datetime.now()
        
        try:
            yield profile_id
            
        finally:
            # Calculer les mÃ©triques
            duration_ms = (time.time() - start_time) * 1000
            end_memory = psutil.Process().memory_info().rss
            memory_delta = end_memory - start_memory
            
            # Enregistrer les mÃ©triques
            metric_tags = tags or {}
            metric_tags["operation"] = operation_name
            
            self.collector.record(f"{operation_name}_duration_ms", 
                                duration_ms, metric_tags)
            self.collector.record(f"{operation_name}_memory_delta_bytes", 
                                memory_delta, metric_tags)
            
            # Nettoyer
            self.active_profiles.pop(profile_id, None)


# === INSTANCES GLOBALES ===

# Collecteur principal de mÃ©triques
metrics_collector = MetricsCollector()

# Gestionnaire d'alertes
alert_manager = AlertManager(metrics_collector)

# MÃ©triques spÃ©cialisÃ©es pour la recherche
search_metrics = SearchMetrics(metrics_collector)

# Profileur de performance
performance_profiler = PerformanceProfiler(metrics_collector)


# === FONCTIONS UTILITAIRES ===

def get_system_metrics() -> Dict[str, Any]:
    """Retourne un rÃ©sumÃ© des mÃ©triques systÃ¨me"""
    
    return {
        "uptime_seconds": (datetime.now() - metrics_collector._start_time).total_seconds(),
        "total_metrics": len(metrics_collector._definitions),
        "active_alerts": len(alert_manager.active_alerts),
        "memory_usage_mb": psutil.Process().memory_info().rss / (1024 * 1024),
        "cpu_usage_percent": psutil.Process().cpu_percent()
    }


def get_performance_summary(hours: int = 1) -> Dict[str, Any]:
    """GÃ©nÃ¨re un rÃ©sumÃ© de performance sur une pÃ©riode"""
    
    since = datetime.now() - timedelta(hours=hours)
    
    # MÃ©triques clÃ©s de performance
    key_metrics = [
        "lexical_search_duration_ms",
        "elasticsearch_search_duration_ms", 
        "api_request_duration_ms",
        "lexical_cache_hit_rate",
        "lexical_search_quality_score"
    ]
    
    summary = {
        "period_hours": hours,
        "generated_at": datetime.now().isoformat(),
        "metrics": {}
    }
    
    for metric_name in key_metrics:
        stats = metrics_collector.get_metric_stats(metric_name, since)
        summary["metrics"][metric_name] = stats
    
    return summary


def export_metrics_to_file(filepath: str, format: str = "json"):
    """Exporte les mÃ©triques vers un fichier"""
    
    try:
        data = metrics_collector.export_metrics(format)
        
        with open(filepath, 'w') as f:
            f.write(data)
        
        logger.info(f"MÃ©triques exportÃ©es vers {filepath}")
        
    except Exception as e:
        logger.error(f"Erreur lors de l'export des mÃ©triques: {e}")
        raise


def cleanup_old_metrics(hours: int = 24):
    """Nettoie les anciennes mÃ©triques"""
    metrics_collector.cleanup_old_samples(hours)


def reset_all_counters():
    """Remet Ã  zÃ©ro tous les compteurs"""
    
    counter_metrics = [
        name for name, definition in metrics_collector._definitions.items()
        if definition.type == MetricType.COUNTER
    ]
    
    for metric_name in counter_metrics:
        metrics_collector.record(metric_name, 0)
    
    logger.info(f"Remise Ã  zÃ©ro de {len(counter_metrics)} compteurs")


def get_top_slow_operations(limit: int = 10, hours: int = 1) -> List[Dict[str, Any]]:
    """Retourne les opÃ©rations les plus lentes"""
    
    since = datetime.now() - timedelta(hours=hours)
    
    duration_metrics = [
        name for name, definition in metrics_collector._definitions.items()
        if "duration_ms" in name
    ]
    
    slow_operations = []
    
    for metric_name in duration_metrics:
        samples = metrics_collector.get_samples(metric_name, since)
        if not samples:
            continue
        
        # Trouver les Ã©chantillons les plus lents
        sorted_samples = sorted(samples, key=lambda x: x.value, reverse=True)
        
        for sample in sorted_samples[:limit]:
            slow_operations.append({
                "operation": metric_name.replace("_duration_ms", ""),
                "duration_ms": sample.value,
                "timestamp": sample.timestamp.isoformat(),
                "tags": sample.tags
            })
    
    # Trier par durÃ©e globale
    slow_operations.sort(key=lambda x: x["duration_ms"], reverse=True)
    
    return slow_operations[:limit]


def get_error_metrics_summary(hours: int = 24) -> Dict[str, Any]:
    """RÃ©sumÃ© des mÃ©triques d'erreurs"""
    
    since = datetime.now() - timedelta(hours=hours)
    
    error_metrics = [
        name for name, definition in metrics_collector._definitions.items()
        if "error" in name.lower()
    ]
    
    summary = {
        "period_hours": hours,
        "total_errors": 0,
        "error_breakdown": {}
    }
    
    for metric_name in error_metrics:
        stats = metrics_collector.get_metric_stats(metric_name, since)
        error_count = stats.get("sum", 0)
        
        summary["total_errors"] += error_count
        summary["error_breakdown"][metric_name] = {
            "count": error_count,
            "rate_per_hour": error_count / hours if hours > 0 else 0
        }
    
    return summary


# === MÃ‰TRIQUES SPÃ‰CIALISÃ‰ES SEARCH SERVICE ===

class QueryMetrics:
    """MÃ©triques pour le query_executor - Alias pour compatibilitÃ©"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
        self.elasticsearch_metrics = ElasticsearchMetrics(collector)
    
    def record_execution_result(self, query_type: str, execution_time_ms: float,
                              success: bool, cache_hit: bool = False):
        """Enregistre le rÃ©sultat d'une exÃ©cution de requÃªte"""
        
        tags = {
            "query_type": query_type,
            "success": str(success),
            "cache_hit": str(cache_hit)
        }
        
        self.collector.record("query_execution_duration_ms", execution_time_ms, tags)
        
        if success:
            self.collector.increment("query_execution_success_count", tags=tags)
        else:
            self.collector.increment("query_execution_error_count", tags=tags)
    
    def get_summary(self) -> Dict[str, Any]:
        """Retourne un rÃ©sumÃ© des mÃ©triques d'exÃ©cution"""
        
        success_count = self.collector.get_current_value("query_execution_success_count", 0)
        error_count = self.collector.get_current_value("query_execution_error_count", 0)
        total_count = success_count + error_count
        
        success_rate = (success_count / total_count * 100) if total_count > 0 else 0
        
        return {
            "total_executions": total_count,
            "success_count": success_count,
            "error_count": error_count,
            "success_rate_percent": success_rate,
            "avg_duration_ms": self.collector.get_metric_stats("query_execution_duration_ms").get("avg", 0)
        }


class ResultMetrics:
    """MÃ©triques pour le result_processor"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_processing_result(self, processing_type: str, duration_ms: float,
                               input_count: int, output_count: int, success: bool):
        """Enregistre le rÃ©sultat d'un traitement de rÃ©sultats"""
        
        tags = {
            "processing_type": processing_type,
            "success": str(success)
        }
        
        self.collector.record("result_processing_duration_ms", duration_ms, tags)
        self.collector.record("result_input_count", input_count, tags)
        self.collector.record("result_output_count", output_count, tags)
        
        if success:
            self.collector.increment("result_processing_success_count", tags=tags)
        else:
            self.collector.increment("result_processing_error_count", tags=tags)
        
        # Calculer l'efficacitÃ©
        efficiency = (output_count / input_count * 100) if input_count > 0 else 0
        self.collector.record("result_processing_efficiency_percent", efficiency, tags)
    
    def record_enrichment_applied(self, enrichment_type: str, duration_ms: float):
        """Enregistre l'application d'un enrichissement"""
        
        tags = {"enrichment_type": enrichment_type}
        
        self.collector.record("result_enrichment_duration_ms", duration_ms, tags)
        self.collector.increment("result_enrichment_count", tags=tags)
    
    def get_summary(self) -> Dict[str, Any]:
        """Retourne un rÃ©sumÃ© des mÃ©triques de traitement"""
        
        success_count = self.collector.get_current_value("result_processing_success_count", 0)
        error_count = self.collector.get_current_value("result_processing_error_count", 0)
        total_count = success_count + error_count
        
        success_rate = (success_count / total_count * 100) if total_count > 0 else 0
        
        return {
            "total_processing": total_count,
            "success_count": success_count,
            "error_count": error_count,
            "success_rate_percent": success_rate,
            "avg_duration_ms": self.collector.get_metric_stats("result_processing_duration_ms").get("avg", 0),
            "avg_efficiency_percent": self.collector.get_metric_stats("result_processing_efficiency_percent").get("avg", 0)
        }


class SearchMetrics:
    """MÃ©triques spÃ©cialisÃ©es pour la recherche"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_search_request(self, user_id: int, intent_type: str, 
                            query_complexity: str):
        """Enregistre une demande de recherche"""
        
        tags = {
            "user_id": str(user_id),
            "intent_type": intent_type,
            "complexity": query_complexity
        }
        
        self.collector.increment("api_request_count", tags=tags)
        self.collector.increment("lexical_search_count", tags=tags)
    
    def record_search_execution(self, duration_ms: float, cache_hit: bool,
                              results_count: int, quality_score: float):
        """Enregistre l'exÃ©cution d'une recherche"""
        
        tags = {
            "cache_hit": str(cache_hit),
            "has_results": str(results_count > 0)
        }
        
        self.collector.record("lexical_search_duration_ms", duration_ms, tags)
        self.collector.record("lexical_search_quality_score", quality_score, tags)
        self.collector.record("results_processed_count", results_count, tags)
        
        # Mettre Ã  jour le taux de cache hit
        if cache_hit:
            self.collector.increment("lexical_cache_hits")
        self.collector.increment("lexical_cache_requests")
        
        # Calculer le taux
        hits = self.collector.get_current_value("lexical_cache_hits", 0)
        requests = self.collector.get_current_value("lexical_cache_requests", 1)
        hit_rate = (hits / requests) * 100
        self.collector.set_gauge("lexical_cache_hit_rate", hit_rate)
    
    def record_elasticsearch_execution(self, duration_ms: float, 
                                     success: bool, error_type: str = None):
        """Enregistre l'exÃ©cution Elasticsearch"""
        
        tags = {
            "success": str(success),
            "error_type": error_type or "none"
        }
        
        self.collector.record("elasticsearch_search_duration_ms", duration_ms, tags)
        
        if success:
            self.collector.increment("elasticsearch_search_count", tags=tags)
        else:
            self.collector.increment("elasticsearch_error_count", tags=tags)
    
    def record_optimization_applied(self, optimization_type: str, 
                                  improvement_percent: float):
        """Enregistre une optimisation appliquÃ©e"""
        
        tags = {"optimization_type": optimization_type}
        
        self.collector.increment("query_optimization_count", tags=tags)
        self.collector.record("optimization_improvement_percent", 
                            improvement_percent, tags)


class ElasticsearchMetrics:
    """MÃ©triques spÃ©cialisÃ©es Elasticsearch"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_query_execution(self, query_type: str, duration_ms: float,
                              success: bool, cache_hit: bool = False,
                              shard_count: int = 1, result_count: int = 0):
        """Enregistre l'exÃ©cution d'une requÃªte Elasticsearch"""
        
        tags = {
            "query_type": query_type,
            "success": str(success),
            "cache_hit": str(cache_hit),
            "shard_count": str(shard_count)
        }
        
        self.collector.record("elasticsearch_search_duration_ms", duration_ms, tags)
        
        if success:
            self.collector.increment("elasticsearch_search_count", tags=tags)
            self.collector.record("elasticsearch_result_count", result_count, tags)
        else:
            self.collector.increment("elasticsearch_error_count", tags=tags)
        
        # MÃ©triques de cache
        if cache_hit:
            self.collector.increment("elasticsearch_cache_hits")
        self.collector.increment("elasticsearch_cache_requests")
        
        # Calculer le taux de cache hit
        hits = self.collector.get_current_value("elasticsearch_cache_hits", 0)
        requests = self.collector.get_current_value("elasticsearch_cache_requests", 1)
        hit_rate = (hits / requests) * 100
        self.collector.set_gauge("elasticsearch_cache_hit_rate", hit_rate)
    
    def record_aggregation_execution(self, agg_type: str, duration_ms: float,
                                   bucket_count: int):
        """Enregistre l'exÃ©cution d'une agrÃ©gation"""
        
        tags = {"aggregation_type": agg_type}
        
        self.collector.record("elasticsearch_aggregation_duration_ms", 
                            duration_ms, tags)
        self.collector.record("elasticsearch_aggregation_buckets", 
                            bucket_count, tags)
        self.collector.increment("elasticsearch_aggregation_count", tags=tags)
    
    def record_connection_event(self, event_type: str, node_count: int = 1):
        """Enregistre un Ã©vÃ©nement de connexion"""
        
        tags = {"event_type": event_type}
        
        self.collector.increment("elasticsearch_connection_events", tags=tags)
        self.collector.set_gauge("elasticsearch_active_nodes", node_count)


class LexicalSearchMetrics:
    """MÃ©triques spÃ©cialisÃ©es pour la recherche lexicale"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_search_analysis(self, query_text: str, complexity: str,
                             field_count: int, filter_count: int):
        """Enregistre l'analyse d'une requÃªte de recherche"""
        
        tags = {
            "complexity": complexity,
            "has_text": str(bool(query_text.strip())),
            "field_count": str(field_count)
        }
        
        self.collector.record("lexical_query_complexity_score", 
                            self._calculate_complexity_score(complexity), tags)
        self.collector.record("lexical_filter_count", filter_count, tags)
        self.collector.record("lexical_search_field_count", field_count, tags)
        self.collector.increment("lexical_query_analyzed", tags=tags)
    
    def record_result_processing(self, processing_duration_ms: float,
                               input_count: int, output_count: int,
                               enrichment_applied: List[str]):
        """Enregistre le traitement des rÃ©sultats"""
        
        tags = {
            "enrichment_count": str(len(enrichment_applied)),
            "has_highlights": str("highlights" in enrichment_applied)
        }
        
        self.collector.record("result_processing_duration_ms", 
                            processing_duration_ms, tags)
        self.collector.record("result_input_count", input_count, tags)
        self.collector.record("result_output_count", output_count, tags)
        
        # EfficacitÃ© du traitement
        if input_count > 0:
            efficiency = output_count / input_count
            self.collector.record("result_processing_efficiency", efficiency, tags)
    
    def record_optimization_impact(self, optimization_type: str,
                                 before_duration_ms: float,
                                 after_duration_ms: float):
        """Enregistre l'impact d'une optimisation"""
        
        improvement_percent = 0
        if before_duration_ms > 0:
            improvement_percent = ((before_duration_ms - after_duration_ms) / 
                                 before_duration_ms) * 100
        
        tags = {"optimization_type": optimization_type}
        
        self.collector.record("optimization_improvement_percent", 
                            improvement_percent, tags)
        self.collector.record("optimization_before_duration_ms", 
                            before_duration_ms, tags)
        self.collector.record("optimization_after_duration_ms", 
                            after_duration_ms, tags)
        self.collector.increment("optimization_applied_count", tags=tags)
    
    def _calculate_complexity_score(self, complexity: str) -> int:
        """Convertit la complexitÃ© en score numÃ©rique"""
        mapping = {
            "simple": 1,
            "moderate": 2,
            "complex": 3,
            "very_complex": 4
        }
        return mapping.get(complexity, 2)


class BusinessMetrics:
    """MÃ©triques mÃ©tier pour le Search Service"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_user_interaction(self, user_id: int, intent_type: str,
                              satisfaction_score: Optional[float] = None,
                              session_duration_ms: Optional[float] = None):
        """Enregistre une interaction utilisateur"""
        
        tags = {
            "user_id": str(user_id),
            "intent_type": intent_type
        }
        
        self.collector.increment("user_interaction_count", tags=tags)
        
        if satisfaction_score is not None:
            self.collector.record("user_satisfaction_score", 
                                satisfaction_score, tags)
        
        if session_duration_ms is not None:
            self.collector.record("user_session_duration_ms", 
                                session_duration_ms, tags)
    
    def record_search_success(self, intent_type: str, successful: bool,
                            results_found: int, user_clicked: bool = False):
        """Enregistre le succÃ¨s d'une recherche"""
        
        tags = {
            "intent_type": intent_type,
            "successful": str(successful),
            "has_results": str(results_found > 0),
            "user_clicked": str(user_clicked)
        }
        
        self.collector.increment("search_attempt_count", tags=tags)
        
        if successful:
            self.collector.increment("search_success_count", tags=tags)
            self.collector.record("search_results_count", results_found, tags)
        
        # Calculer le taux de succÃ¨s
        success_count = self.collector.get_current_value("search_success_count", 0)
        attempt_count = self.collector.get_current_value("search_attempt_count", 1)
        success_rate = (success_count / attempt_count) * 100
        self.collector.set_gauge("search_intent_success_rate", success_rate)
    
    def record_financial_query_patterns(self, category: str, amount_range: str,
                                      time_period: str, complexity: str):
        """Enregistre les patterns de requÃªtes financiÃ¨res"""
        
        tags = {
            "category": category,
            "amount_range": amount_range,
            "time_period": time_period,
            "complexity": complexity
        }
        
        self.collector.increment("financial_query_pattern_count", tags=tags)
        
        # MÃ©triques spÃ©cifiques par catÃ©gorie
        category_tags = {"category": category}
        self.collector.increment(f"financial_category_{category.lower()}_count", 
                               tags=category_tags)

class ApiMetrics:
    """MÃ©triques spÃ©cialisÃ©es pour l'API REST"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_search_api_call(self, endpoint: str, duration_ms: float,
                              success: bool, user_id: Optional[int] = None,
                              results_count: int = 0, cache_hit: bool = False):
        """Enregistre un appel API de recherche"""
        
        tags = {
            "endpoint": endpoint,
            "success": str(success),
            "cache_hit": str(cache_hit),
            "has_results": str(results_count > 0)
        }
        
        if user_id:
            tags["user_id"] = str(user_id)
        
        self.collector.record("api_search_duration_ms", duration_ms, tags)
        self.collector.record("api_search_results_count", results_count, tags)
        self.collector.increment("api_search_count", tags=tags)
        
        if success:
            self.collector.increment("api_search_success_count", tags=tags)
        else:
            self.collector.increment("api_search_error_count", tags=tags)
    
    def record_validation_api_call(self, duration_ms: float, success: bool,
                                  user_id: Optional[int] = None,
                                  validation_errors: int = 0):
        """Enregistre un appel API de validation"""
        
        tags = {
            "success": str(success),
            "has_errors": str(validation_errors > 0)
        }
        
        if user_id:
            tags["user_id"] = str(user_id)
        
        self.collector.record("api_validation_duration_ms", duration_ms, tags)
        self.collector.record("api_validation_errors_count", validation_errors, tags)
        self.collector.increment("api_validation_count", tags=tags)
        
        if success:
            self.collector.increment("api_validation_success_count", tags=tags)
        else:
            self.collector.increment("api_validation_error_count", tags=tags)
    
    def record_health_check(self, duration_ms: float, overall_status: str,
                           components_healthy: int, components_total: int):
        """Enregistre un check de santÃ©"""
        
        tags = {
            "status": overall_status,
            "all_healthy": str(components_healthy == components_total)
        }
        
        self.collector.record("api_health_check_duration_ms", duration_ms, tags)
        self.collector.record("api_health_components_healthy", components_healthy, tags)
        self.collector.record("api_health_components_total", components_total, tags)
        self.collector.increment("api_health_check_count", tags=tags)
        
        # Calculer le pourcentage de santÃ©
        health_percentage = (components_healthy / components_total * 100) if components_total > 0 else 0
        self.collector.set_gauge("api_health_percentage", health_percentage)
    
    def record_admin_operation(self, operation: str, duration_ms: float,
                              success: bool, user_id: Optional[int] = None):
        """Enregistre une opÃ©ration d'administration"""
        
        tags = {
            "operation": operation,
            "success": str(success)
        }
        
        if user_id:
            tags["user_id"] = str(user_id)
        
        self.collector.record("api_admin_duration_ms", duration_ms, tags)
        self.collector.increment("api_admin_count", tags=tags)
        
        if success:
            self.collector.increment("api_admin_success_count", tags=tags)
        else:
            self.collector.increment("api_admin_error_count", tags=tags)
    
    def record_rate_limit_event(self, endpoint: str, user_id: Optional[int],
                               limit_exceeded: bool, current_rate: float):
        """Enregistre un Ã©vÃ©nement de limitation de taux"""
        
        tags = {
            "endpoint": endpoint,
            "limit_exceeded": str(limit_exceeded)
        }
        
        if user_id:
            tags["user_id"] = str(user_id)
        
        self.collector.record("api_rate_limit_current", current_rate, tags)
        self.collector.increment("api_rate_limit_checks", tags=tags)
        
        if limit_exceeded:
            self.collector.increment("api_rate_limit_exceeded", tags=tags)
    
    def record_authentication_event(self, auth_method: str, success: bool,
                                   duration_ms: float, user_id: Optional[int] = None):
        """Enregistre un Ã©vÃ©nement d'authentification"""
        
        tags = {
            "auth_method": auth_method,
            "success": str(success)
        }
        
        if user_id:
            tags["user_id"] = str(user_id)
        
        self.collector.record("api_auth_duration_ms", duration_ms, tags)
        self.collector.increment("api_auth_attempts", tags=tags)
        
        if success:
            self.collector.increment("api_auth_success_count", tags=tags)
        else:
            self.collector.increment("api_auth_failure_count", tags=tags)
    
    def record_error_event(self, error_type: str, endpoint: str, 
                          status_code: int, user_id: Optional[int] = None):
        """Enregistre un Ã©vÃ©nement d'erreur"""
        
        tags = {
            "error_type": error_type,
            "endpoint": endpoint,
            "status_code": str(status_code)
        }
        
        if user_id:
            tags["user_id"] = str(user_id)
        
        self.collector.increment("api_error_events", tags=tags)
        
        # MÃ©triques spÃ©cifiques par type d'erreur
        if status_code >= 500:
            self.collector.increment("api_server_errors", tags=tags)
        elif status_code >= 400:
            self.collector.increment("api_client_errors", tags=tags)
    
    def get_api_summary(self, hours: int = 1) -> Dict[str, Any]:
        """Retourne un rÃ©sumÃ© des mÃ©triques API"""
        
        since = datetime.now() - timedelta(hours=hours)
        
        # MÃ©triques de base
        total_requests = self.collector.get_metric_stats("api_request_count", since).get("sum", 0)
        total_errors = self.collector.get_metric_stats("api_error_count", since).get("sum", 0)
        
        # Calcul du taux d'erreur
        error_rate = (total_errors / total_requests * 100) if total_requests > 0 else 0
        
        # DurÃ©es moyennes
        avg_duration = self.collector.get_metric_stats("api_request_duration_ms", since).get("avg", 0)
        
        # MÃ©triques de recherche spÃ©cifiques
        search_requests = self.collector.get_metric_stats("api_search_count", since).get("sum", 0)
        search_success = self.collector.get_metric_stats("api_search_success_count", since).get("sum", 0)
        search_success_rate = (search_success / search_requests * 100) if search_requests > 0 else 0
        
        return {
            "period_hours": hours,
            "timestamp": datetime.now().isoformat(),
            "total_requests": total_requests,
            "total_errors": total_errors,
            "error_rate_percent": error_rate,
            "avg_duration_ms": avg_duration,
            "search": {
                "requests": search_requests,
                "success_rate_percent": search_success_rate
            },
            "health": {
                "current_percentage": self.collector.get_current_value("api_health_percentage", 100)
            }
        }
# === DASHBOARD ET REPORTING ===

class MetricsDashboard:
    """GÃ©nÃ©rateur de dashboard pour les mÃ©triques"""
    
    def __init__(self, collector: MetricsCollector, alert_manager: AlertManager):
        self.collector = collector
        self.alert_manager = alert_manager
    
    def generate_health_report(self) -> Dict[str, Any]:
        """GÃ©nÃ¨re un rapport de santÃ© complet"""
        
        current_time = datetime.now()
        
        # Statut global
        active_alerts = self.alert_manager.get_active_alerts()
        critical_alerts = [a for a in active_alerts if a["level"] == "critical"]
        error_alerts = [a for a in active_alerts if a["level"] == "error"]
        
        if critical_alerts:
            overall_status = "critical"
        elif error_alerts:
            overall_status = "degraded"
        elif active_alerts:
            overall_status = "warning"
        else:
            overall_status = "healthy"
        
        # MÃ©triques de performance clÃ©s
        key_performance = {}
        performance_metrics = [
            "lexical_search_duration_ms",
            "elasticsearch_search_duration_ms",
            "api_request_duration_ms"
        ]
        
        for metric in performance_metrics:
            stats = self.collector.get_metric_stats(metric, 
                                                   since=current_time - timedelta(hours=1))
            key_performance[metric] = {
                "avg_ms": stats.get("avg", 0),
                "p95_ms": stats.get("p95", 0),
                "count": stats.get("count", 0)
            }
        
        # Taux d'erreur
        error_count = self.collector.get_current_value("elasticsearch_error_count", 0)
        total_requests = self.collector.get_current_value("elasticsearch_search_count", 1)
        error_rate = (error_count / total_requests) * 100 if total_requests > 0 else 0
        
        return {
            "timestamp": current_time.isoformat(),
            "overall_status": overall_status,
            "alerts": {
                "active_count": len(active_alerts),
                "critical_count": len(critical_alerts),
                "error_count": len(error_alerts),
                "details": active_alerts
            },
            "performance": key_performance,
            "reliability": {
                "error_rate_percent": error_rate,
                "cache_hit_rate_percent": self.collector.get_current_value(
                    "elasticsearch_cache_hit_rate", 0
                ),
                "uptime_hours": (current_time - self.collector._start_time).total_seconds() / 3600
            },
            "system_resources": {
                "memory_usage_mb": psutil.Process().memory_info().rss / (1024 * 1024),
                "cpu_usage_percent": psutil.Process().cpu_percent()
            }
        }
    
    def generate_performance_trends(self, hours: int = 24) -> Dict[str, Any]:
        """GÃ©nÃ¨re les tendances de performance"""
        
        since = datetime.now() - timedelta(hours=hours)
        
        trends = {
            "period_hours": hours,
            "generated_at": datetime.now().isoformat(),
            "metrics": {}
        }
        
        # MÃ©triques Ã  analyser pour les tendances
        trend_metrics = [
            "lexical_search_duration_ms",
            "elasticsearch_search_duration_ms",
            "lexical_cache_hit_rate",
            "search_intent_success_rate"
        ]
        
        for metric_name in trend_metrics:
            samples = self.collector.get_samples(metric_name, since)
            
            if len(samples) < 2:
                trends["metrics"][metric_name] = {"trend": "insufficient_data"}
                continue
            
            values = [s.value for s in samples]
            
            # Calculer la tendance (simple rÃ©gression linÃ©aire)
            n = len(values)
            x_values = list(range(n))
            
            # Calculs pour la rÃ©gression linÃ©aire
            x_mean = sum(x_values) / n
            y_mean = sum(values) / n
            
            numerator = sum((x - x_mean) * (y - y_mean) for x, y in zip(x_values, values))
            denominator = sum((x - x_mean) ** 2 for x in x_values)
            
            if denominator != 0:
                slope = numerator / denominator
                
                # DÃ©terminer la direction de la tendance
                if abs(slope) < 0.1:
                    trend_direction = "stable"
                elif slope > 0:
                    trend_direction = "increasing"
                else:
                    trend_direction = "decreasing"
                
                trends["metrics"][metric_name] = {
                    "trend": trend_direction,
                    "slope": slope,
                    "current_value": values[-1],
                    "avg_value": y_mean,
                    "sample_count": n
                }
            else:
                trends["metrics"][metric_name] = {"trend": "stable"}
        
        return trends


# === INSTANCES SPÃ‰CIALISÃ‰ES ===

# MÃ©triques principales compatibles avec les imports existants
query_metrics = QueryMetrics(metrics_collector)
result_metrics = ResultMetrics(metrics_collector)

# MÃ©triques spÃ©cialisÃ©es avec instances
search_metrics = SearchMetrics(metrics_collector)
elasticsearch_metrics = ElasticsearchMetrics(metrics_collector)
lexical_search_metrics = LexicalSearchMetrics(metrics_collector)
business_metrics = BusinessMetrics(metrics_collector)
api_metrics = ApiMetrics(metrics_collector)

# Dashboard
metrics_dashboard = MetricsDashboard(metrics_collector, alert_manager)


# === CALLBACKS D'ALERTE PAR DÃ‰FAUT ===

def log_alert_callback(alert: MetricAlert):
    """Callback pour logger les alertes"""
    level_mapping = {
        AlertLevel.INFO: logger.info,
        AlertLevel.WARNING: logger.warning,
        AlertLevel.ERROR: logger.error,
        AlertLevel.CRITICAL: logger.critical
    }
    
    log_func = level_mapping.get(alert.level, logger.info)
    log_func(f"ALERTE MÃ‰TRIQUE: {alert.message}")


def system_alert_callback(alert: MetricAlert):
    """Callback pour les alertes systÃ¨me critiques"""
    if alert.level == AlertLevel.CRITICAL:
        # Ici on pourrait intÃ©grer avec des systÃ¨mes externes
        # comme PagerDuty, Slack, etc.
        logger.critical(f"ðŸš¨ ALERTE CRITIQUE SYSTÃˆME: {alert.message}")
        
        # Exemple d'action automatique
        if "memory" in alert.metric_name.lower():
            logger.info("ðŸ§¹ DÃ©clenchement du nettoyage automatique de cache")
            cleanup_old_metrics(hours=1)


# Enregistrer les callbacks par dÃ©faut
alert_manager.add_alert_callback(AlertLevel.WARNING, log_alert_callback)
alert_manager.add_alert_callback(AlertLevel.ERROR, log_alert_callback)
alert_manager.add_alert_callback(AlertLevel.CRITICAL, log_alert_callback)
alert_manager.add_alert_callback(AlertLevel.CRITICAL, system_alert_callback)


# === FONCTIONS D'INITIALISATION ===

def initialize_metrics_system():
    """Initialise le systÃ¨me de mÃ©triques"""
    
    logger.info("ðŸš€ Initialisation du systÃ¨me de mÃ©triques Search Service")
    
    # Nettoyer les anciennes mÃ©triques au dÃ©marrage
    cleanup_old_metrics(hours=settings.metrics_retention_hours if hasattr(settings, 'metrics_retention_hours') else 24)
    
    # Enregistrer les mÃ©triques personnalisÃ©es si nÃ©cessaire
    # (Elles sont dÃ©jÃ  enregistrÃ©es via _register_default_metrics)
    
    logger.info("âœ… SystÃ¨me de mÃ©triques initialisÃ© avec succÃ¨s")


def shutdown_metrics_system():
    """ArrÃªt propre du systÃ¨me de mÃ©triques"""
    
    logger.info("ðŸ›‘ ArrÃªt du systÃ¨me de mÃ©triques")
    
    # Exporter les mÃ©triques finales si configurÃ©
    if hasattr(settings, 'export_metrics_on_shutdown') and settings.export_metrics_on_shutdown:
        try:
            export_metrics_to_file("/tmp/search_service_final_metrics.json")
        except Exception as e:
            logger.error(f"Erreur lors de l'export final des mÃ©triques: {e}")
    
    # DÃ©sactiver la collecte systÃ¨me
    metrics_collector._system_metrics_enabled = False
    
    logger.info("âœ… SystÃ¨me de mÃ©triques arrÃªtÃ©")


# === EXPORTS PRINCIPAUX ===

__all__ = [
    # === CLASSES PRINCIPALES ===
    "MetricsCollector",
    "AlertManager", 
    "MetricsDashboard",
    
    # === MÃ‰TRIQUES PRINCIPALES (compatibilitÃ©) ===
    "QueryMetrics",
    "ResultMetrics", 
    "query_metrics",
    "result_metrics",
    
    # === MÃ‰TRIQUES SPÃ‰CIALISÃ‰ES ===
    "SearchMetrics",
    "ElasticsearchMetrics",
    "LexicalSearchMetrics",
    "BusinessMetrics",
    "PerformanceProfiler",
    
    # === TYPES ET ENUMS ===
    "MetricType",
    "MetricCategory",
    "AlertLevel",
    "MetricDefinition",
    "MetricValue",
    "MetricSample",
    "MetricAlert",
    
    # === INSTANCES GLOBALES ===
    "metrics_collector",
    "alert_manager",
    "query_metrics",
    "result_metrics", 
    "search_metrics",
    "elasticsearch_metrics",
    "lexical_search_metrics",
    "business_metrics",
    "performance_profiler",
    "metrics_dashboard",
    "ApiMetrics",
    "api_metrics",
    
    # === FONCTIONS UTILITAIRES ===
    "get_system_metrics",
    "get_performance_summary",
    "export_metrics_to_file",
    "cleanup_old_metrics",
    "reset_all_counters",
    "get_top_slow_operations",
    "get_error_metrics_summary",
    "initialize_metrics_system",
    "shutdown_metrics_system",

    
    # === CALLBACKS ===
    "log_alert_callback",
    "system_alert_callback"
]


# === INFORMATIONS DU MODULE ===

__version__ = "1.0.0"
__author__ = "Search Service Team"
__description__ = "SystÃ¨me de mÃ©triques spÃ©cialisÃ©es pour le Search Service"

# Auto-initialisation au chargement du module
try:
    initialize_metrics_system()
except Exception as e:
    logger.error(f"Erreur lors de l'auto-initialisation des mÃ©triques: {e}")

logger.info(f"Module utils.metrics chargÃ© - version {__version__}")